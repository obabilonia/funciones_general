{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "filename_ANN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obabilonia/test1/blob/master/filename_ANN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "aw7i7RN0RWDH",
        "colab_type": "code",
        "outputId": "090068b6-3827-412f-864e-c95bf4779afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2247
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"preparando ambiente\")\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install unidecode\n",
        "!pip install lxml\n",
        "!wget https://github.com/denadai2/google_street_view_deep_neural/archive/master.zip\n",
        "!unzip master.zip\n",
        "!mv google_street_view_deep_neural-master/* .\n",
        "!wget https://ndownloader.figshare.com/files/11086517\n",
        "!mv 11086517 generated_files/pytorch_state.npy\n",
        "!pip install torchvision\n",
        "!pip install Pillow==4.0.0\n",
        "!pip install image\n",
        "!mkdir images\n",
        "!wget http://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.txt.bz2\n",
        "!bzip2 -d SBW-vectors-300-min5.txt.bz2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preparando ambiente\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/39/37/f285403a09cc261c56b6574baace1bdcf4b8c7428c8a7239cbba137bc0eb/PyVirtualDisplay-0.2.1.tar.gz\n",
            "Collecting EasyProcess (from pyvirtualdisplay)\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/f1/d2de7591e7dfc164d286fa16f051e6c0cf3141825586c3b04ae7cda7ac0f/EasyProcess-0.2.3.tar.gz\n",
            "Building wheels for collected packages: pyvirtualdisplay, EasyProcess\n",
            "  Running setup.py bdist_wheel for pyvirtualdisplay ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d1/8c/16/1c64227974ae29c687e4cc30fd691d5c0fd40f54446dde99da\n",
            "  Running setup.py bdist_wheel for EasyProcess ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b4/c6/e3/c163b04029d8fccfd54b809802640c1af587a01be8d7a04e1a\n",
            "Successfully built pyvirtualdisplay EasyProcess\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.2.3 pyvirtualdisplay-0.2.1\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n",
            "\u001b[K    100% |████████████████████████████████| 245kB 7.0MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.0.23\n",
            "Collecting lxml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/14/f4343239f955442da9da1919a99f7311bc5627522741bada61b2349c8def/lxml-4.2.5-cp27-cp27mu-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.8MB 4.1MB/s \n",
            "\u001b[?25hInstalling collected packages: lxml\n",
            "Successfully installed lxml-4.2.5\n",
            "--2018-11-27 18:37:12--  https://github.com/denadai2/google_street_view_deep_neural/archive/master.zip\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/denadai2/google_street_view_deep_neural/zip/master [following]\n",
            "--2018-11-27 18:37:12--  https://codeload.github.com/denadai2/google_street_view_deep_neural/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.253.121, 192.30.253.120\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.253.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [  <=>               ]   4.31M  8.49MB/s    in 0.5s    \n",
            "\n",
            "2018-11-27 18:37:12 (8.49 MB/s) - ‘master.zip’ saved [4517871]\n",
            "\n",
            "Archive:  master.zip\n",
            "384cdb3531c56bdb6754f67075cbefb27ffeee29\n",
            "   creating: google_street_view_deep_neural-master/\n",
            "  inflating: google_street_view_deep_neural-master/.gitignore  \n",
            "  inflating: google_street_view_deep_neural-master/ACMMM.ipynb  \n",
            "  inflating: google_street_view_deep_neural-master/LICENSE  \n",
            "  inflating: google_street_view_deep_neural-master/README.md  \n",
            "   creating: google_street_view_deep_neural-master/caffe/\n",
            "  inflating: google_street_view_deep_neural-master/caffe/deploy_gpu.prototxt  \n",
            "  inflating: google_street_view_deep_neural-master/caffe/places205CNN_finetune.prototxt  \n",
            "  inflating: google_street_view_deep_neural-master/caffe/solver.prototxt  \n",
            "   creating: google_street_view_deep_neural-master/data/\n",
            "  inflating: google_street_view_deep_neural-master/data/list_files.csv  \n",
            "   creating: google_street_view_deep_neural-master/figures/\n",
            "  inflating: google_street_view_deep_neural-master/figures/fit.pdf  \n",
            "  inflating: google_street_view_deep_neural-master/figures/prediction.pdf  \n",
            "  inflating: google_street_view_deep_neural-master/figures/prediction_wnames.pdf  \n",
            "  inflating: google_street_view_deep_neural-master/figures/safety_prediction.pdf  \n",
            "  inflating: google_street_view_deep_neural-master/figures/women.pdf  \n",
            "   creating: google_street_view_deep_neural-master/generated_files/\n",
            "  inflating: google_street_view_deep_neural-master/generated_files/places205CNN_mean_filtered.npy  \n",
            "  inflating: google_street_view_deep_neural-master/security_perception_prediction.png  \n",
            "  inflating: google_street_view_deep_neural-master/streetview_image.jpg  \n",
            "--2018-11-27 18:37:24--  https://ndownloader.figshare.com/files/11086517\n",
            "Resolving ndownloader.figshare.com (ndownloader.figshare.com)... 52.213.114.32, 18.203.143.159, 54.194.37.96, ...\n",
            "Connecting to ndownloader.figshare.com (ndownloader.figshare.com)|52.213.114.32|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/11086517/pytorch_state.npy [following]\n",
            "--2018-11-27 18:37:24--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/11086517/pytorch_state.npy\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.53.26\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.53.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 227491170 (217M) [binary/octet-stream]\n",
            "Saving to: ‘11086517’\n",
            "\n",
            "11086517            100%[===================>] 216.95M  3.38MB/s    in 90s     \n",
            "\n",
            "2018-11-27 18:38:55 (2.41 MB/s) - ‘11086517’ saved [227491170/227491170]\n",
            "\n",
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from torchvision) (1.14.6)\n",
            "Collecting torch (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/a7/6a173738dd6be014ebf9ba6f0b441d91b113b1506a98e10da4ff60994b54/torch-0.4.1-cp27-cp27mu-manylinux1_x86_64.whl (519.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 519.5MB 23kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5579d4c2c000 @  0x7f75b5f372a4 0x55797ac63f18 0x55797ad57a85 0x55797ac774ca 0x55797ac7c232 0x55797ac74d0a 0x55797ac7c5fe 0x55797ac74d0a 0x55797ac7c5fe 0x55797ac74d0a 0x55797ac7c5fe 0x55797ac74d0a 0x55797ac7cc38 0x55797ac74d0a 0x55797ac7c5fe 0x55797ac74d0a 0x55797ac7c5fe 0x55797ac7c232 0x55797ac7c232 0x55797ac74d0a 0x55797ac7cc38 0x55797ac7c232 0x55797ac74d0a 0x55797ac7cc38 0x55797ac74d0a 0x55797ac7cc38 0x55797ac74d0a 0x55797ac7c5fe 0x55797ac74d0a 0x55797ac74629 0x55797aca561f\n",
            "\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/f6/3b3c82c5c75cae471e02fb584136168d732e17ae9db2d21c5dc82f9790f8/Pillow-5.3.0-cp27-cp27mu-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 3.1MB/s \n",
            "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torch-0.4.1 torchvision-0.2.1\n",
            "Collecting Pillow==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/99/0e3522a9764fe371bf9f7729404b1ef7d9c4fc49cbe5f1761c6e07812345/Pillow-4.0.0-cp27-cp27mu-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.6MB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n",
            "Collecting image\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/ec/51969468a8b87f631cc0e60a6bf1e5f6eec8ef3fd2ee45dc760d5a93b82a/image-1.5.27-py2.py3-none-any.whl\n",
            "Collecting django (from image)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/e7/872bbf76aa16b7a061698d75325dac023285db33db4bda8ba8fe5d3bb356/Django-1.11.16-py2.py3-none-any.whl (7.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 7.0MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python2.7/dist-packages (from image) (4.0.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python2.7/dist-packages (from django->image) (2018.7)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python2.7/dist-packages (from pillow->image) (0.46)\n",
            "Installing collected packages: django, image\n",
            "Successfully installed django-1.11.16 image-1.5.27\n",
            "--2018-11-27 18:41:02--  http://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.txt.bz2\n",
            "Resolving cs.famaf.unc.edu.ar (cs.famaf.unc.edu.ar)... 200.16.17.55\n",
            "Connecting to cs.famaf.unc.edu.ar (cs.famaf.unc.edu.ar)|200.16.17.55|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.txt.bz2 [following]\n",
            "--2018-11-27 18:41:02--  https://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.txt.bz2\n",
            "Connecting to cs.famaf.unc.edu.ar (cs.famaf.unc.edu.ar)|200.16.17.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 818175453 (780M) [application/x-bzip2]\n",
            "Saving to: ‘SBW-vectors-300-min5.txt.bz2’\n",
            "\n",
            "SBW-vectors-300-min 100%[===================>] 780.27M  17.7MB/s    in 57s     \n",
            "\n",
            "2018-11-27 18:42:00 (13.7 MB/s) - ‘SBW-vectors-300-min5.txt.bz2’ saved [818175453/818175453]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i8iPJsAFRWDN",
        "colab_type": "code",
        "outputId": "3ae06dd3-d328-4bcd-d926-eaf1adc35603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"comandos auxiliares\")\n",
        "#%save -f test.ipynb\n",
        "#%%writefile ./filename2.ipynb\n",
        "#hola\n",
        "#%lsmagic\n",
        "#page = requests.get(\"https://www.dataquest.io/blog/web-scraping-tutorial-python/\")\n",
        "#page.content\n",
        "#!zip -r images.zip images"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comandos auxiliares\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TWHW3M3kRWDR",
        "colab_type": "code",
        "outputId": "36cf543d-4c0d-4376-f552-68a7c6d922a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!rm Oscar.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'Oscar.py': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v0CNT51cRWDU",
        "colab_type": "code",
        "outputId": "688d7f5f-2c82-4de4-a964-14da81f03bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!wget -O Oscar3.py https://raw.githubusercontent.com/obabilonia/test1/master/Oscar.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-27 18:52:26--  https://raw.githubusercontent.com/obabilonia/test1/master/Oscar.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5175 (5.1K) [text/plain]\n",
            "Saving to: ‘Oscar3.py’\n",
            "\n",
            "\rOscar3.py             0%[                    ]       0  --.-KB/s               \rOscar3.py           100%[===================>]   5.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-11-27 18:52:26 (55.7 MB/s) - ‘Oscar3.py’ saved [5175/5175]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7vevW_rNRWDX",
        "colab_type": "code",
        "outputId": "07a52cac-1735-443e-aa11-51a52cba26db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "!head Oscar3.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import re\n",
            "import nltk\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "from unidecode import unidecode\n",
            "\n",
            "def O_print_full(x):\n",
            "    pd.set_option('display.max_rows', len(x))\n",
            "    pd.set_option('display.max_columns', None)\n",
            "    pd.set_option('display.width', 2000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_lXxLPO_RWDa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import Oscar3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dz63ssF7RWDd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import lxml\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "#from selenium import webdriver\n",
        "#from selenium.webdriver.support.ui import Select\n",
        "import time\n",
        "from PIL import Image\n",
        "import subprocess\n",
        "#import commands\n",
        "import pickle\n",
        "#from selenium.webdriver.chrome.options import Options\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from unidecode import unidecode\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FEmm2D-ERWDs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from matplotlib.pyplot import imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w0ahufOVRWDh",
        "colab_type": "code",
        "outputId": "84d79b9f-c09e-4389-c547-2ac5a4b346ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Get Descripcion\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get Descripcion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "utG4x7k2RWDk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try: \n",
        "    from BeautifulSoup import BeautifulSoup\n",
        "except ImportError:\n",
        "    from bs4 import BeautifulSoup\n",
        "\n",
        "def get_description(fuente):\n",
        "  soup = BeautifulSoup(fuente)\n",
        "  dic = {}\n",
        "  try:\n",
        "    dic[\"ubicacion\"] = unidecode(soup.find('div', attrs={'class':'section-map-title'}).get_text()).replace(\"\\n\",\" \").replace(\"\\t\",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \")\n",
        "  except:\n",
        "    dic[\"ubicacion\"] = 0\n",
        "  try:\n",
        "    dic[\"main_descripcion\"] = unidecode(soup.find('div', attrs={'class':'description-content-main-group attribute-content'}).get_text()).replace(\"\\n\",\" \").replace(\"\\t\",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \")\n",
        "  except:\n",
        "    dic[\"main_descripcion\"] = 0\n",
        "  try:\n",
        "    dic[\"sec_descripcion\"] = unidecode(soup.find('div', attrs={'class':'description-content-secondary-group attribute-content'}).get_text()).replace(\"\\n\",\" \").replace(\"\\t\",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \")\n",
        "  except:\n",
        "    dic[\"sec_descripcion\"] = 0\n",
        "  try:\n",
        "    dic[\"vendedor\"] = unidecode(soup.find('span', attrs={'class':'profile-info-data profile-info-name-data'}).get_text()).replace(\"\\n\",\" \").replace(\"\\t\",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \")\n",
        "  except:\n",
        "    dic[\"vendedor\"] = 0\n",
        "  try:\n",
        "    dic[\"title\"] = unidecode(soup.find('p', attrs={'class':'description-content-title'}).get_text()).replace(\"\\n\",\" \").replace(\"\\t\",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \")\n",
        "  except:\n",
        "    dic[\"title\"] = 0\n",
        "  try:\n",
        "    dic[\"texto\"] = unidecode(soup.find('pre', attrs={'class':'preformated-text'}).get_text()).replace(\"\\n\",\" \").replace(\"\\t\",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \").replace(\"  \",\" \")\n",
        "  except:\n",
        "    dic[\"texto\"]=0\n",
        "  return dic\n",
        "#get_description(fuente)\n",
        "#soup = BeautifulSoup(fuente)\n",
        "#soup.find('div', attrs={'class':'description-content-secondary-group attribute-content'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VGvyM1HBRWDp",
        "colab_type": "code",
        "outputId": "389688c5-721e-40b0-f718-610df299490a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Safety Feature\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Safety Feature\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jHksVpw9RWDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class KitModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(KitModel, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 96, (11, 11), stride=4, padding=0)\n",
        "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, groups=2, padding=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, groups=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, groups=2, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, groups=2, padding=1)\n",
        "        self.fc6_1 = nn.Linear(in_features = 9216, out_features = 4096)\n",
        "        self.fc7_1 = nn.Linear(in_features = 4096, out_features = 4096)\n",
        "        self.ip_1 = nn.Linear(in_features = 4096, out_features = 1)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.drop = nn.Dropout()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1           = self.conv1(x)\n",
        "        relu1           = self.relu(conv1)\n",
        "        pool1           = self.maxpool(relu1)\n",
        "        norm1           = self.LRN(size = 5, alpha=0.0001, beta=0.75)(pool1)\n",
        "        \n",
        "        conv2           = self.conv2(norm1)\n",
        "        relu2           = self.relu(conv2)\n",
        "        pool2           = self.maxpool(relu2)\n",
        "        norm2           = self.LRN(size = 5, alpha=0.0001, beta=0.75)(pool2)\n",
        "        \n",
        "        conv3           = self.conv3(norm2)\n",
        "        relu3           = self.relu(conv3)\n",
        "        conv4           = self.conv4(relu3)\n",
        "        relu4           = self.relu(conv4)\n",
        "        conv5           = self.conv5(relu4)\n",
        "        relu5           = self.relu(conv5)\n",
        "        pool5           = self.maxpool(relu5)\n",
        "        \n",
        "        fc6_0           = pool5.view(pool5.size(0), -1)\n",
        "        \n",
        "        fc6_1           = self.fc6_1(fc6_0)\n",
        "        relu6           = self.relu(fc6_1)\n",
        "        drop6           = self.drop(relu6)\n",
        "        fc7_1           = self.fc7_1(drop6)\n",
        "        relu7           = self.relu(fc7_1)\n",
        "        ip_0            = self.drop(relu7)\n",
        "        ip_1            = self.ip_1(ip_0)\n",
        "        \n",
        "        return ip_1\n",
        "    \n",
        "    class LRN(nn.Module):\n",
        "        def __init__(self, size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=True):\n",
        "            super(KitModel.LRN, self).__init__()\n",
        "            self.ACROSS_CHANNELS = ACROSS_CHANNELS\n",
        "            if self.ACROSS_CHANNELS:\n",
        "                self.average=nn.AvgPool3d(kernel_size=(size, 1, 1),\n",
        "                        stride=1,\n",
        "                        padding=(int((size-1.0)/2), 0, 0))\n",
        "            else:\n",
        "                self.average=nn.AvgPool2d(kernel_size=size,\n",
        "                        stride=1,\n",
        "                        padding=int((size-1.0)/2))\n",
        "            self.alpha = alpha\n",
        "            self.beta = beta\n",
        "\n",
        "        def forward(self, x):\n",
        "            if self.ACROSS_CHANNELS:\n",
        "                div = x.pow(2).unsqueeze(1)\n",
        "                div = self.average(div).squeeze(1)\n",
        "                div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
        "            else:\n",
        "                div = x.pow(2)\n",
        "                div = self.average(div)\n",
        "                div = div.mul(self.alpha).add(1.0).pow(self.beta)\n",
        "            x = x.div(div)\n",
        "            return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SGb3J8xhRWDy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class PandasDataset(Dataset):\n",
        "    def __init__(self, list_images, list_targets, transform=None):\n",
        "        self.list_images = list_images\n",
        "        self.list_targets = list_targets\n",
        "        # add transforms as well\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        image = Image.open(self.list_images[idx]).convert('RGB')\n",
        "        image = image.resize((227,227), Image.BILINEAR) \n",
        "        image = np.array(image, dtype='f4')\n",
        "        # Convert RGB to BGR \n",
        "        image = image[:, :, ::-1]\n",
        "        \n",
        "        image = image.astype('float32')\n",
        "        \n",
        "        # add transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, self.list_targets[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C3KstLmRRWD1",
        "colab_type": "code",
        "outputId": "c55ea483-28f4-4af7-9e9b-abf52b9d830c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "model = KitModel()\n",
        "\n",
        "model.load_state_dict(torch.load('generated_files/pytorch_state.npy'))\n",
        "model.train(False)\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KitModel(\n",
              "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
              "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n",
              "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
              "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
              "  (fc6_1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "  (fc7_1): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (ip_1): Linear(in_features=4096, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (drop): Dropout(p=0.5)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "p-9bWUU0RWD3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 30\n",
        "\n",
        "file_list = [\n",
        "    'streetview_image.jpg',\n",
        "]\n",
        "# I'm interested only in testing the predictions, so label=0\n",
        "labels = [\n",
        "    0\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1AsChDarRWD6",
        "colab_type": "code",
        "outputId": "f909aa7e-f4c1-4eef-9489-6e35d3f9d835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "image = Image.open(file_list[0]).convert('RGB')\n",
        "imshow(np.array(image))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f162f877ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAD8CAYAAAAhQfz4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCPH/ADb+lJAaMG/4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f162f8fef90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mWE-MCxrRWD9",
        "colab_type": "code",
        "outputId": "7c3df762-d361-4dc3-f3ef-b5cba2655b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = model.double()\n",
        "\n",
        "means = np.load('generated_files/places205CNN_mean_filtered.npy')\n",
        "\n",
        "transformations = transforms.Compose([lambda x: x - means, # Subtracts image means\n",
        "                                      transforms.ToTensor(), \n",
        "                                      lambda x: x*255] # Restore the input range to [0, 255]\n",
        "                                    )\n",
        "\n",
        "\n",
        "dataset = PandasDataset(file_list, labels, transformations)\n",
        "\n",
        "\n",
        "load = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=10)\n",
        "\n",
        "preds = np.zeros((len(file_list), 1))\n",
        "\n",
        "for i, data in enumerate(load):\n",
        "    inputs, labels = data\n",
        "    \n",
        "    n = len(inputs)\n",
        "    ifrom = i*batch_size\n",
        "    ito = i*batch_size+n\n",
        "    \n",
        "    inputs, labels = Variable(inputs), Variable(labels)\n",
        "    \n",
        "    outputs = model(inputs)\n",
        "    preds[ifrom:ito] = outputs.data.numpy()\n",
        "    \n",
        "print(\"Predicted:\", preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Predicted:', array([[4.96546034]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NvCgJ7SXRWEB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_fuente(url):\n",
        "  try:\n",
        "    return requests.get(url).content\n",
        "  except:\n",
        "    get_fuente(url)\n",
        "    \n",
        "def get_Image(url):\n",
        "  try:\n",
        "    image = Image.open(BytesIO(get_fuente(url)))\n",
        "    image.save(\"test.png\")\n",
        "    return image\n",
        "  except:\n",
        "    get_Image(url)\n",
        "\n",
        "def persection(lng = 6.1870028, lat = -75.6496416, heading= 0):\n",
        "  url = \"http://maps.googleapis.com/maps/api/streetview?size=400x300&location=\"+str(lng)+\",%20\"+str(lat)+\"&heading=\"+str(heading)+\"&sensor=false&key=AIzaSyA4XFoQFphSaUrcGmvT06NUcexvxbpBc2Y\"\n",
        "  #response = requests.get(url)\n",
        "  image = get_Image(url)\n",
        "  #image.save(\"test.png\")\n",
        "  \n",
        "  file_list = ['test.png',]\n",
        "# I'm interested only in testing the predictions, so label=0\n",
        "  labels = [0]\n",
        "\n",
        "\n",
        "  dataset = PandasDataset(file_list, labels, transformations)\n",
        "\n",
        "\n",
        "  load = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=10)\n",
        "\n",
        "  preds = np.zeros((len(file_list), 1))\n",
        "\n",
        "  for i, data in enumerate(load):\n",
        "      inputs, labels = data\n",
        "\n",
        "      n = len(inputs)\n",
        "      ifrom = i*batch_size\n",
        "      ito = i*batch_size+n\n",
        "\n",
        "      inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      preds[ifrom:ito] = outputs.data.numpy()\n",
        "\n",
        "  return preds[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LR56jmTDRWEI",
        "colab_type": "code",
        "outputId": "2db5ee2d-c40b-4a29-d7e4-afae4c2aa76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "persection(6.2738166,-75.58028)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9719990748805465"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "5jEw9XEkRWEO",
        "colab_type": "code",
        "outputId": "1b6a557f-0800-45a6-9bb9-9eff386d1325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Adquisicion\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adquisicion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YJqz9jEpRWER",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(\n",
        "      {   \"link\": [0],\n",
        "          \"precio\": [1],\n",
        "      })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W8lwB5WVRWEU",
        "colab_type": "code",
        "outputId": "fd298f82-9053-42e2-85e8-4eded4979815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "df[\"link\"][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "04Mem440RWEX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def filtros(df):\n",
        "  print(df[\"lat\"][0], df[\"lng\"][0], df[\"percepcion_0\"][0])\n",
        "  print(float(df[\"lat\"][0]) <= 6.1 or float(df[\"lat\"][0]) > 8. )\n",
        "  \n",
        "  if df[\"lat\"][0] == 0 or \\\n",
        "     df[\"lng\"][0] == 0 or \\\n",
        "     (df[\"percepcion_0\"][0] == 2.0001800290571454 and \\\n",
        "      df[\"percepcion_90\"][0] == 2.0001800290571454 and \\\n",
        "      df[\"percepcion_180\"][0] == 2.0001800290571454 and \\\n",
        "      df[\"percepcion_270\"][0] == 2.0001800290571454) or \\\n",
        "      float(df[\"lat\"][0]) <= 6.1 or \\\n",
        "      float(df[\"lat\"][0]) > 8. or \\\n",
        "      float(df[\"lng\"][0]) > -75.52 or \\\n",
        "      float(df[\"lng\"][0]) < -75.68:   \n",
        "    return df.drop(0)\n",
        "  else:\n",
        "    return df\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E3ehgrYXRWEa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df.iloc[[11]].reset_index()[\"percepcion_0\"][0] == 2.0001800290571454"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oRyrfePJRWEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#filtros(df.iloc[[11]].reset_index())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jZPghPaHRWEh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YF2WuL2RRWEk",
        "colab_type": "code",
        "outputId": "6b3d35e2-48e7-4f85-f7b5-c7738b6b0bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "links = []\n",
        "precios = []\n",
        "df = pd.DataFrame(\n",
        "      {   \"link\": [],\n",
        "          \"precio\": [],\n",
        "          \"area\": [],\n",
        "          \"habitaciones\": [],\n",
        "          \"banos\": [],\n",
        "          \"mapa\": [],\n",
        "          \"lat\":[],\n",
        "          \"lng\":[],\n",
        "          \"descripcion\": [],\n",
        "          \"desc_texto\": [],\n",
        "          \"desc_title\": [],\n",
        "          \"desc_vend\": [],\n",
        "          \"desc_sec\": [],\n",
        "          \"desc_main\": [],\n",
        "          \"desc_ubica\": [],\n",
        "          \"imagens\":[],\n",
        "          \"percepcion_0\":[],\n",
        "          \"percepcion_90\":[],\n",
        "          \"percepcion_180\":[],\n",
        "          \"percepcion_270\":[],\n",
        "      })\n",
        "\n",
        "os.system(\"rm -r images/*\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "MPSoRfXkRWEo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_feature(url, precios):\n",
        "    #br2.get(url)\n",
        "    print(url)\n",
        "    #requests.get(\"https://apartamento.mercadolibre.com.co/MCO-437779427-apartamento-en-venta-_JM\").content[0:50]\n",
        "#    page2 = requests.get(url)\n",
        "#    time.sleep(10)\n",
        "    #fuente = br2.page_source.encode('utf-8')\n",
        "    fuente = str(get_fuente(url))\n",
        "    try:\n",
        "        atrivutos = str(fuente).split(\"vip-product-info__attributes-list\")[1].split(\"</section>\")[0]\n",
        "    except:\n",
        "        #br2.get(url)\n",
        "        page2 = requests.get(url)\n",
        "        time.sleep(10)\n",
        "        #fuente = br2.page_source.encode('utf-8')\n",
        "        fuente = str(page2.content)\n",
        "        try:\n",
        "            atrivutos = str(fuente).split(\"vip-product-info__attributes-list\")[1].split(\"</section>\")[0]\n",
        "        except:\n",
        "            atrivutos = 0\n",
        "    try:\n",
        "        area = atrivutos.split('vip-product-info__attribute-value\">')[1].split(\" \")[0]\n",
        "    except:\n",
        "        area = 0\n",
        "    try:\n",
        "        habitaciones = atrivutos.split('vip-product-info__attribute-value\">')[2].split(\"<\")[0]\n",
        "    except:\n",
        "        habitaciones = 0\n",
        "    try:\n",
        "        banos = atrivutos.split('vip-product-info__attribute-value\">')[3].split(\"<\")[0]\n",
        "    except:\n",
        "        banos = 0\n",
        "    try:\n",
        "        mapa = str(fuente).split('https://maps.googleapis.com/maps/api/staticmap?center=')[1].split(\"&\")[0].split(\"%2C\")\n",
        "    except:\n",
        "        mapa = ['0', '0']\n",
        "    try:\n",
        "        #descripcion = fuente.split('vip-section-description container\">')[1].split(\"</section>\")[0]\n",
        "        descripcion = get_description(fuente)\n",
        "    except:\n",
        "        descripcion = 0\n",
        "    try:\n",
        "        imagens0 = str(fuente).split(\"playedVideoTime = 0\")[1].split(\"items =\")[1].split(\"]\")[0].split(\"[\")[1]\n",
        "        imagens = [i[\"src\"] for i in eval(imagens0)]\n",
        "    except:\n",
        "        imagens = 0\n",
        "    percepcion_0 = persection(mapa[0],mapa[1], 0)\n",
        "    percepcion_90 = persection(mapa[0],mapa[1], 90)\n",
        "    percepcion_180 = persection(mapa[0],mapa[1], 180)\n",
        "    percepcion_270 = persection(mapa[0],mapa[1], 270)\n",
        "    \n",
        "    #print(area, habitaciones, banos, mapa)\n",
        "    #print(descripcion)\n",
        "    df = pd.DataFrame(\n",
        "      {   \"link\": url,\n",
        "          \"precio\": precios,\n",
        "          \"area\": area,\n",
        "          \"habitaciones\": habitaciones,\n",
        "          \"banos\": banos,\n",
        "          \"mapa\": [mapa],\n",
        "          \"lat\":mapa[0],\n",
        "          \"lng\":mapa[1],\n",
        "          \"descripcion\": [descripcion],\n",
        "          \"desc_texto\": descripcion[\"texto\"],\n",
        "          \"desc_title\": descripcion[\"title\"],\n",
        "          \"desc_vend\": descripcion[\"vendedor\"],\n",
        "          \"desc_sec\": descripcion[\"sec_descripcion\"],\n",
        "          \"desc_main\": descripcion[\"main_descripcion\"],\n",
        "          \"desc_ubica\": descripcion[\"ubicacion\"],\n",
        "          \"imagens\":[imagens],\n",
        "          \"percepcion_0\":percepcion_0,\n",
        "          \"percepcion_90\":percepcion_90,\n",
        "          \"percepcion_180\":percepcion_180,\n",
        "          \"percepcion_270\":percepcion_270,\n",
        "      })\n",
        "    \n",
        "    df = filtros(df)\n",
        "    return df\n",
        "\n",
        "\n",
        "url = \"https://inmuebles.mercadolibre.com.co/apartamentos/venta/antioquia/medellin/_Desde_1_OrderId_PRICE\"\n",
        "\n",
        "ind = 0\n",
        "for k in range(100):\n",
        "    break\n",
        "    #page = requests.get(url)\n",
        "    #br.get(url)\n",
        "    time.sleep(5)\n",
        "    fuente = str(get_fuente(url))\n",
        "    \n",
        "    #print len(str(br.page_source.encode('utf-8')).split(\"searchResults\"))\n",
        "    if len(fuente.split(\"searchResults\")) == 1:\n",
        "        print(\"termino\")\n",
        "        break\n",
        "\n",
        "    fuente = fuente.split(\"searchResults\")[1].split(\"item-url\")\n",
        "    fuente.pop(0)\n",
        "    ind = ind+len(fuente)\n",
        "\n",
        "    for link in fuente:\n",
        "        links.append(link.split(\" \")[0].split('\"')[1])\n",
        "        precios.append(int(link.split('price__fraction\">')[1].split('<')[0].replace('.', '')))\n",
        "        \n",
        "        df_a = get_feature(links[-1], precios[-1])\n",
        "\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        df = df.append(df_a).reset_index(drop=True)\n",
        "        print(df[[\"area\",\"habitaciones\",\"mapa\",\"percepcion_0\",\"precio\"]].tail())\n",
        "        os.system(\"mkdir images/\"+str(df.shape[0] -1 ))\n",
        "        if df[\"imagens\"][df.shape[0]-1] != 0:\n",
        "          [ os.system(\"wget -O images/\"+str(df.shape[0] -1)+\"/\"+j.split(\"/\")[-1]+\" \"+j) for j in df[\"imagens\"][df.shape[0]-1] ]\n",
        "        elif df[\"imagens\"][df.shape[0]-1] == 0:\n",
        "          os.system(\"wget -O images/\"+str(df.shape[0] -1)+\"/No_image.jpg https://http2.mlstatic.com/resources/frontend/statics/img-not-available/1.0.0/V.jpg\")\n",
        "\n",
        "    print(\"_________________________________________________________\")\n",
        "    url = \"https://listado.mercadolibre.com.co/inmuebles/apartamentos/venta/antioquia/medellin/_Desde_\"+str(ind+1)+\"_OrderId_PRICE\"\n",
        "    print(url)\n",
        "    #df.to_csv(\"df.csv\", sep=';')\n",
        "    #!./dropbox_uploader.sh upload df.csv /\n",
        "    print(\"_________________________________________________________\")\n",
        "    #      df[\"lat\"][0] <= 6.1 or \\\n",
        "#      df[\"lat\"][0] > 8 or \\\n",
        "#      df[\"lng\"][0] > -75.52 or \\\n",
        "#      df[\"lng\"][0] < -75.68:   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZQVai8QRWEr",
        "colab_type": "code",
        "outputId": "5872fefb-8ad6-4486-946e-0f3ede9ddf3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "!curl \"https://raw.githubusercontent.com/andreafabrizi/Dropbox-Uploader/master/dropbox_uploader.sh\" -o dropbox_uploader.sh\n",
        "\n",
        "\n",
        "!chmod +x dropbox_uploader.sh\n",
        "!./dropbox_uploader.sh\n",
        "#iJMCDCbjLNIAAAAAAAANHFZu-tNNmw6FXMABCQuh-2f03xDCxv33TFd9yO0XQlqE\n",
        "#%notebook ./filename.ipynb\n",
        "#!./dropbox_uploader.sh upload filename.ipynb /"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 49655  100 49655    0     0   418k      0 --:--:-- --:--:-- --:--:--  418k\n",
            "\n",
            " This is the first time you run this script, please follow the instructions:\n",
            "\n",
            " 1) Open the following URL in your Browser, and log in using your account: https://www.dropbox.com/developers/apps\n",
            " 2) Click on \"Create App\", then select \"Dropbox API app\"\n",
            " 3) Now go on with the configuration, choosing the app permissions and access restrictions to your DropBox folder\n",
            " 4) Enter the \"App Name\" that you prefer (e.g. MyUploader830410070244)\n",
            "\n",
            " Now, click on the \"Create App\" button.\n",
            "\n",
            " When your new App is successfully created, please click on the Generate button\n",
            " under the 'Generated access token' section, then copy and paste the new access token here:\n",
            "\n",
            " # Access token: iJMCDCbjLNIAAAAAAAANHFZu-tNNmw6FXMABCQuh-2f03xDCxv33TFd9yO0XQlqE\n",
            "\n",
            " > The access token is iJMCDCbjLNIAAAAAAAANHFZu-tNNmw6FXMABCQuh-2f03xDCxv33TFd9yO0XQlqE. Looks ok? [y/N]: y\n",
            "   The configuration has been saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5OmqlhvkRWEu",
        "colab_type": "code",
        "outputId": "5a9586d8-2412-4e9e-f58b-883cbc9bb7a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!./dropbox_uploader.sh download df.csv ."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " > Downloading \"/df.csv\" to \"/content/df.csv\"... DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ywrrTkXiRWEx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"df.csv\", delimiter=\";\", index_col=\"Unnamed: 0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GCu5jXz6RWEz",
        "colab_type": "code",
        "outputId": "c54de494-af1d-45bc-d261-9460343adaf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area</th>\n",
              "      <th>banos</th>\n",
              "      <th>desc_main</th>\n",
              "      <th>desc_sec</th>\n",
              "      <th>desc_texto</th>\n",
              "      <th>desc_title</th>\n",
              "      <th>desc_ubica</th>\n",
              "      <th>desc_vend</th>\n",
              "      <th>descripcion</th>\n",
              "      <th>habitaciones</th>\n",
              "      <th>imagens</th>\n",
              "      <th>lat</th>\n",
              "      <th>link</th>\n",
              "      <th>lng</th>\n",
              "      <th>mapa</th>\n",
              "      <th>percepcion_0</th>\n",
              "      <th>percepcion_180</th>\n",
              "      <th>percepcion_270</th>\n",
              "      <th>percepcion_90</th>\n",
              "      <th>precio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>77</td>\n",
              "      <td>2</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 77 Op...</td>\n",
              "      <td>0</td>\n",
              "      <td>APTO PISO SEPTIMO: Consta de 77 m2, 3 habitac...</td>\n",
              "      <td>Apto 77 M2 3 Hab Cerca De Estacion San Javier</td>\n",
              "      <td>Ubicacion Medellin 3053181060, San Javier, Me...</td>\n",
              "      <td>Asiestucasa</td>\n",
              "      <td>{'title': 'Apto 77 M2 3 Hab Cerca De Estacion ...</td>\n",
              "      <td>3</td>\n",
              "      <td>['https://http2.mlstatic.com/none-D_NQ_NP_8829...</td>\n",
              "      <td>6.255651</td>\n",
              "      <td>https://apartamento.mercadolibre.com.co/MCO-48...</td>\n",
              "      <td>-75.618627</td>\n",
              "      <td>['6.2556509', '-75.6186265']</td>\n",
              "      <td>4.852417</td>\n",
              "      <td>4.220643</td>\n",
              "      <td>3.951810</td>\n",
              "      <td>4.010629</td>\n",
              "      <td>200000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>55</td>\n",
              "      <td>2</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 55 Op...</td>\n",
              "      <td>Otros Condicion del item: Usado</td>\n",
              "      <td>Informacion detallada. Hermoso Apartamento ub...</td>\n",
              "      <td>Apartamento En Belen Los Alpes</td>\n",
              "      <td>Ubicacion Belen Los Alpes, Medellin, Antioquia</td>\n",
              "      <td>Luz Elena Meneses Moreno</td>\n",
              "      <td>{'title': 'Apartamento En Belen Los Alpes', 'v...</td>\n",
              "      <td>2</td>\n",
              "      <td>['https://http2.mlstatic.com/none-D_NQ_NP_8414...</td>\n",
              "      <td>6.228799</td>\n",
              "      <td>https://apartamento.mercadolibre.com.co/MCO-48...</td>\n",
              "      <td>-75.606185</td>\n",
              "      <td>['6.2287988', '-75.6061855']</td>\n",
              "      <td>4.482049</td>\n",
              "      <td>4.327452</td>\n",
              "      <td>5.193517</td>\n",
              "      <td>5.267939</td>\n",
              "      <td>200000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 67 Op...</td>\n",
              "      <td>0</td>\n",
              "      <td>Se vende apartamento en Rodeo Alto, 3 habitac...</td>\n",
              "      <td>Se Vende Apartamento En Rodeo Alto</td>\n",
              "      <td>Ubicacion Medellin, Antioquia</td>\n",
              "      <td>Prado Gestion Inmobiliaria S.a.s</td>\n",
              "      <td>{'title': 'Se Vende Apartamento En Rodeo Alto'...</td>\n",
              "      <td>3</td>\n",
              "      <td>['https://http2.mlstatic.com/none-D_NQ_NP_9144...</td>\n",
              "      <td>6.244203</td>\n",
              "      <td>https://apartamento.mercadolibre.com.co/MCO-48...</td>\n",
              "      <td>-75.581212</td>\n",
              "      <td>['6.244203', '-75.5812119']</td>\n",
              "      <td>4.042085</td>\n",
              "      <td>4.859144</td>\n",
              "      <td>4.474911</td>\n",
              "      <td>4.472118</td>\n",
              "      <td>200000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 67 Op...</td>\n",
              "      <td>Caracteristicas adicionales Balcon Cocina Int...</td>\n",
              "      <td>SE VENDE APARTAMETO EN LOS COLORES en Centro ...</td>\n",
              "      <td>Se Vende Apartameto En Los Colores</td>\n",
              "      <td>Ubicacion Centro Occidente, Medellin, Antioquia</td>\n",
              "      <td>Prado Gestion Inmobiliaria S.a.s</td>\n",
              "      <td>{'title': 'Se Vende Apartameto En Los Colores'...</td>\n",
              "      <td>3</td>\n",
              "      <td>['https://http2.mlstatic.com/none-D_NQ_NP_7736...</td>\n",
              "      <td>6.253453</td>\n",
              "      <td>https://apartamento.mercadolibre.com.co/MCO-48...</td>\n",
              "      <td>-75.624792</td>\n",
              "      <td>['6.2534528', '-75.6247916']</td>\n",
              "      <td>5.527111</td>\n",
              "      <td>4.960363</td>\n",
              "      <td>4.864713</td>\n",
              "      <td>5.027576</td>\n",
              "      <td>200000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 67 Op...</td>\n",
              "      <td>Caracteristicas adicionales Balcon Calefaccio...</td>\n",
              "      <td>HERMOSO APARTAMENTO EN BELEN LA MOTA CERCA A ...</td>\n",
              "      <td>Hermoso Apartamento En Belen La Mota</td>\n",
              "      <td>Ubicacion La Mota, Medellin, Antioquia</td>\n",
              "      <td>Su Propiedad</td>\n",
              "      <td>{'title': 'Hermoso Apartamento En Belen La Mot...</td>\n",
              "      <td>2</td>\n",
              "      <td>['https://http2.mlstatic.com/none-D_NQ_NP_9028...</td>\n",
              "      <td>6.208338</td>\n",
              "      <td>https://apartamento.mercadolibre.com.co/MCO-48...</td>\n",
              "      <td>-75.599514</td>\n",
              "      <td>['6.2083376', '-75.5995139']</td>\n",
              "      <td>4.486433</td>\n",
              "      <td>5.168179</td>\n",
              "      <td>6.034755</td>\n",
              "      <td>4.307685</td>\n",
              "      <td>200000000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    area banos                                          desc_main  \\\n",
              "936   77     2   Inmueble: Apartamento Metros de const.: 77 Op...   \n",
              "937   55     2   Inmueble: Apartamento Metros de const.: 55 Op...   \n",
              "938   67     2   Inmueble: Apartamento Metros de const.: 67 Op...   \n",
              "939   67     2   Inmueble: Apartamento Metros de const.: 67 Op...   \n",
              "940   67     2   Inmueble: Apartamento Metros de const.: 67 Op...   \n",
              "\n",
              "                                              desc_sec  \\\n",
              "936                                                  0   \n",
              "937                   Otros Condicion del item: Usado    \n",
              "938                                                  0   \n",
              "939   Caracteristicas adicionales Balcon Cocina Int...   \n",
              "940   Caracteristicas adicionales Balcon Calefaccio...   \n",
              "\n",
              "                                            desc_texto  \\\n",
              "936   APTO PISO SEPTIMO: Consta de 77 m2, 3 habitac...   \n",
              "937   Informacion detallada. Hermoso Apartamento ub...   \n",
              "938   Se vende apartamento en Rodeo Alto, 3 habitac...   \n",
              "939   SE VENDE APARTAMETO EN LOS COLORES en Centro ...   \n",
              "940   HERMOSO APARTAMENTO EN BELEN LA MOTA CERCA A ...   \n",
              "\n",
              "                                        desc_title  \\\n",
              "936  Apto 77 M2 3 Hab Cerca De Estacion San Javier   \n",
              "937                 Apartamento En Belen Los Alpes   \n",
              "938             Se Vende Apartamento En Rodeo Alto   \n",
              "939             Se Vende Apartameto En Los Colores   \n",
              "940           Hermoso Apartamento En Belen La Mota   \n",
              "\n",
              "                                            desc_ubica  \\\n",
              "936   Ubicacion Medellin 3053181060, San Javier, Me...   \n",
              "937    Ubicacion Belen Los Alpes, Medellin, Antioquia    \n",
              "938                     Ubicacion Medellin, Antioquia    \n",
              "939   Ubicacion Centro Occidente, Medellin, Antioquia    \n",
              "940            Ubicacion La Mota, Medellin, Antioquia    \n",
              "\n",
              "                              desc_vend  \\\n",
              "936                        Asiestucasa    \n",
              "937           Luz Elena Meneses Moreno    \n",
              "938   Prado Gestion Inmobiliaria S.a.s    \n",
              "939   Prado Gestion Inmobiliaria S.a.s    \n",
              "940                       Su Propiedad    \n",
              "\n",
              "                                           descripcion habitaciones  \\\n",
              "936  {'title': 'Apto 77 M2 3 Hab Cerca De Estacion ...            3   \n",
              "937  {'title': 'Apartamento En Belen Los Alpes', 'v...            2   \n",
              "938  {'title': 'Se Vende Apartamento En Rodeo Alto'...            3   \n",
              "939  {'title': 'Se Vende Apartameto En Los Colores'...            3   \n",
              "940  {'title': 'Hermoso Apartamento En Belen La Mot...            2   \n",
              "\n",
              "                                               imagens       lat  \\\n",
              "936  ['https://http2.mlstatic.com/none-D_NQ_NP_8829...  6.255651   \n",
              "937  ['https://http2.mlstatic.com/none-D_NQ_NP_8414...  6.228799   \n",
              "938  ['https://http2.mlstatic.com/none-D_NQ_NP_9144...  6.244203   \n",
              "939  ['https://http2.mlstatic.com/none-D_NQ_NP_7736...  6.253453   \n",
              "940  ['https://http2.mlstatic.com/none-D_NQ_NP_9028...  6.208338   \n",
              "\n",
              "                                                  link        lng  \\\n",
              "936  https://apartamento.mercadolibre.com.co/MCO-48... -75.618627   \n",
              "937  https://apartamento.mercadolibre.com.co/MCO-48... -75.606185   \n",
              "938  https://apartamento.mercadolibre.com.co/MCO-48... -75.581212   \n",
              "939  https://apartamento.mercadolibre.com.co/MCO-48... -75.624792   \n",
              "940  https://apartamento.mercadolibre.com.co/MCO-48... -75.599514   \n",
              "\n",
              "                             mapa  percepcion_0  percepcion_180  \\\n",
              "936  ['6.2556509', '-75.6186265']      4.852417        4.220643   \n",
              "937  ['6.2287988', '-75.6061855']      4.482049        4.327452   \n",
              "938   ['6.244203', '-75.5812119']      4.042085        4.859144   \n",
              "939  ['6.2534528', '-75.6247916']      5.527111        4.960363   \n",
              "940  ['6.2083376', '-75.5995139']      4.486433        5.168179   \n",
              "\n",
              "     percepcion_270  percepcion_90       precio  \n",
              "936        3.951810       4.010629  200000000.0  \n",
              "937        5.193517       5.267939  200000000.0  \n",
              "938        4.474911       4.472118  200000000.0  \n",
              "939        4.864713       5.027576  200000000.0  \n",
              "940        6.034755       4.307685  200000000.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "mhZ5c6V1RWE2",
        "colab_type": "code",
        "outputId": "cc46dfe5-e02e-443c-e0d1-e31a5bf45b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Get Distances - Interes Points\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get Distances - Interes Points\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U5MaTND0RWE5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df[\"lat\"] = df[\"lat\"].astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oAwa1bjHRWE8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "df[\"lng\"] = df[\"mapa\"].map(lambda x: eval(eval(x)[0]))\n",
        "df[\"lat\"] = df[\"mapa\"].map(lambda x: eval(eval(x)[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s-DhwnIrRWE_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_Estrato(x):\n",
        "  try:\n",
        "    y= x.split(\"Estrato:\")[1].split(\" \")\n",
        "    return int(y[1])\n",
        "  except:\n",
        "    return np.nan\n",
        "    \n",
        "df[\"Estrato\"] = df[\"desc_main\"].map(lambda x: get_Estrato(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vnb5dTmMRWFC",
        "colab_type": "code",
        "outputId": "537361cb-8eb3-4225-a846-020d85aad03c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "Oscar3.O_check_base(df[[\"Estrato\"]])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>columns</th>\n",
              "      <th>types</th>\n",
              "      <th>missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Estrato</td>\n",
              "      <td>float64</td>\n",
              "      <td>263.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   columns    types  missing\n",
              "0  Estrato  float64    263.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "fiHTAZ7-RWFF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df[\"Estrato\"] = df[[\"Estrato\"]].fillna(df[\"Estrato\"].mode()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GXhkTpvWRWFI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = df[df[\"area\"] != \"3</span>\\n\\t\\t\\t</li>\\n\"]\n",
        "df = df[df[\"area\"] != '1</span>\\n\\t\\t\\t</li>\\n']\n",
        "#df[df[\"banos\"] == 'M\\xc3\\xa1s de 10']\n",
        "#Oscar3.O_print_full(df[df[\"banos\"] == 'M\\xc3\\xa1s de 10'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jvEutKJvRWFK",
        "colab_type": "code",
        "outputId": "afef4434-8c65-43c6-92a6-6c0291e556aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "Oscar3.O_print_full(df[df[\"habitaciones\"] == 'M\\xc3\\xa1s de 10'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    area banos                                                                                                                                                                               desc_main                                                                                                                                                                                                                                                                                                                    desc_sec                                                                                                                                                                                                                                                                                                                                                                                                       desc_texto                       desc_title                                         desc_ubica            desc_vend  \\\n",
            "5    1    0      Inmueble: Apartamento Metros de const.: 1 Operacion: Venta Habitaciones: Mas de 10 Banos: No tiene Anos de antiguedad: 1 Metros de terreno: 1                                           Otros Condicion del item: Usado                                                                                                                                                                                                                                                                                            0                                                                                                                                                                                                                                                                                                                                                                                                                Apartamentos En Venta             Ubicacion Medellin, Antioquia                     0                     \n",
            "604  63   2      Inmueble: Apartamento Metros de const.: 63 Operacion: Venta Valor administracion ($): 148000 Habitaciones: Mas de 10 Banos: 2 Anos de antiguedad: 0 Estrato: 4 Metros de terreno: 63    Caracteristicas adicionales Balcon Calefaccion o Chimenea Cocina Integral Garaje Piscina Vista panoramica Cercanias a menos de dos cuadras Centro comercial Colegio Parque Universidad Instalaciones y comodidades Circuito Cerrado de TV Conjunto Cerrado Ascensores Parque infantil Salon de Fiesta Vigilancia privada    Apartamento en venta en rodeo alto con area de 63m2, 3 alcobas , 2 banos, sala comedor, cocina integral cerrada, balcon con vista panoramica, calentador de paso, parqueadero cubierto. Unidad cerrada con vigilancia las 24 horas, pscina, placas deportivas, amplias zonas verdes, sendero ecologico, parqueadero de visitantes. Valor de venta: 165.000.000. NEGOCIABLES ! Urve inmobiliaria Colombia SAS.   Apartamento En Venta Rodeo Alto   Ubicacion Belen Rodeo Alto, Medellin, Antioquia    Patricia Valencia    \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      descripcion habitaciones                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         imagens                  lat                                                                                       link                  lng                          mapa  \\\n",
            "5    {'title': 'Apartamentos En Venta', 'vendedor': 0, 'texto': 0, 'ubicacion': ' Ubicacion Medellin, Antioquia ', 'main_descripcion': ' Inmueble: Apartamento Metros de const.: 1 Operacion: Venta Habitaciones: Mas de 10 Banos: No tiene Anos de antiguedad: 1 Metros de terreno: 1 ', 'sec_descripcion': ' Otros Condicion del item: Usado '}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Más de 10    0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            -75.58  https://apartamento.mercadolibre.com.co/MCO-494405318-apartamentos-en-venta-_JM                           6.24  ['6.2447031', '-75.5807149']   \n",
            "604  {'title': 'Apartamento En Venta Rodeo Alto', 'vendedor': ' Patricia Valencia ', 'texto': ' Apartamento en venta en rodeo alto con area de 63m2, 3 alcobas , 2 banos, sala comedor, cocina integral cerrada, balcon con vista panoramica, calentador de paso, parqueadero cubierto. Unidad cerrada con vigilancia las 24 horas, pscina, placas deportivas, amplias zonas verdes, sendero ecologico, parqueadero de visitantes. Valor de venta: 165.000.000. NEGOCIABLES ! Urve inmobiliaria Colombia SAS. ', 'ubicacion': ' Ubicacion Belen Rodeo Alto, Medellin, Antioquia ', 'main_descripcion': ' Inmueble: Apartamento Metros de const.: 63 Operacion: Venta Valor administracion ($): 148000 Habitaciones: Mas de 10 Banos: 2 Anos de antiguedad: 0 Estrato: 4 Metros de terreno: 63 ', 'sec_descripcion': ' Caracteristicas adicionales Balcon Calefaccion o Chimenea Cocina Integral Garaje Piscina Vista panoramica Cercanias a menos de dos cuadras Centro comercial Colegio Parque Universidad Instalaciones y comodidades Circuito Cerrado de TV Conjunto Cerrado Ascensores Parque infantil Salon de Fiesta Vigilancia privada '}  Más de 10    ['https://http2.mlstatic.com/none-D_NQ_NP_715780-MCO27884834507_082018-F.jpg', 'https://http2.mlstatic.com/none-D_NQ_NP_756261-MCO27884834510_082018-F.jpg', 'https://http2.mlstatic.com/none-D_NQ_NP_823084-MCO27884834506_082018-F.jpg', 'https://http2.mlstatic.com/none-D_NQ_NP_974547-MCO27884834504_082018-F.jpg', 'https://http2.mlstatic.com/none-D_NQ_NP_831514-MCO27884834505_082018-F.jpg', 'https://http2.mlstatic.com/none-D_NQ_NP_853051-MCO27884834502_082018-F.jpg', 'https://http2.mlstatic.com/none-D_NQ_NP_655567-MCO27884834508_082018-F.jpg', 'https://http2.mlstatic.com/none-D_NQ_NP_982623-MCO27884834509_082018-F.jpg', 'https://http2.mlstatic.com/none-D_NQ_NP_615278-MCO27884834503_082018-F.jpg']               -75.61  https://apartamento.mercadolibre.com.co/MCO-479630765-apartamento-en-venta-rodeo-alto-_JM                 6.20  ['6.2036942', '-75.6050723']   \n",
            "\n",
            "            percepcion_0       percepcion_180       percepcion_270        percepcion_90               precio              Estrato  \n",
            "5                   5.18                 5.37                 5.30                 4.40         1,000,000.00                 3.00  \n",
            "604                 5.06                 5.37                 5.43                 5.10       165,000,000.00                 4.00  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tN5ZNjnoRWFQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Oscar3.O_print_full(df.iloc[603])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4J0CH8YcRWFX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.drop(index=5, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a5-vjumJRWFb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.at[407,\"banos\"] = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fFFLZI-zRWFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.at[604,\"habitaciones\"] = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cIIB7Z8tRWFk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df.iloc[603]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i6ABtLbqRWFq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df.iloc[407]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "roSSrD2FRWFt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df[\"area\"] = df[\"area\"].astype(int)\n",
        "df[\"banos\"] = df[\"banos\"].astype(int)\n",
        "df[\"habitaciones\"] = df[\"habitaciones\"].astype(int)\n",
        "df[\"Estrato\"] = df[\"Estrato\"].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dkq9NMhDRWFw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df[[\"desc_main\"]].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q-xiEMCBRWF0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df[\"lat\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tl7vt7-gRWF4",
        "colab_type": "code",
        "outputId": "4dada38f-86f4-4623-f7c5-7207001a8d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "cell_type": "code",
      "source": [
        "Oscar3.O_check_base(df)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>columns</th>\n",
              "      <th>types</th>\n",
              "      <th>missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>area</td>\n",
              "      <td>int64</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>banos</td>\n",
              "      <td>int64</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>desc_main</td>\n",
              "      <td>object</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>desc_sec</td>\n",
              "      <td>object</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>desc_texto</td>\n",
              "      <td>object</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>desc_title</td>\n",
              "      <td>object</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>desc_ubica</td>\n",
              "      <td>object</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>desc_vend</td>\n",
              "      <td>object</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>descripcion</td>\n",
              "      <td>object</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>habitaciones</td>\n",
              "      <td>int64</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>imagens</td>\n",
              "      <td>object</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>lat</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>link</td>\n",
              "      <td>object</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>lng</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>mapa</td>\n",
              "      <td>object</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>percepcion_0</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>percepcion_180</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>percepcion_270</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>percepcion_90</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>precio</td>\n",
              "      <td>float64</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Estrato</td>\n",
              "      <td>int64</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           columns    types  missing\n",
              "0             area    int64      0.0\n",
              "1            banos    int64      0.0\n",
              "2        desc_main   object      0.0\n",
              "3         desc_sec   object      0.0\n",
              "4       desc_texto   object      0.0\n",
              "5       desc_title   object      0.0\n",
              "6       desc_ubica   object      0.0\n",
              "7        desc_vend   object      0.0\n",
              "8      descripcion   object      0.0\n",
              "9     habitaciones    int64      0.0\n",
              "10         imagens   object      0.0\n",
              "11             lat  float64      0.0\n",
              "12            link   object      0.0\n",
              "13             lng  float64      0.0\n",
              "14            mapa   object      0.0\n",
              "15    percepcion_0  float64      0.0\n",
              "16  percepcion_180  float64      0.0\n",
              "17  percepcion_270  float64      0.0\n",
              "18   percepcion_90  float64      0.0\n",
              "19          precio  float64      0.0\n",
              "20         Estrato    int64      0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "WiYumkC6RWF9",
        "colab_type": "code",
        "outputId": "8d40b62c-32f6-41fb-d0ed-d7fb2ad00f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['area', 'banos', 'desc_main', 'desc_sec', 'desc_texto', 'desc_title', 'desc_ubica', 'desc_vend', 'descripcion', 'habitaciones', 'imagens', 'lat', 'link', 'lng', 'mapa', 'percepcion_0', 'percepcion_180', 'percepcion_270', 'percepcion_90', 'precio', 'Estrato']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-T8wVwxZRWGA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_0 = df\n",
        "df[\"description\"] = df_0['desc_main'] + df_0['desc_sec'] + df_0['desc_texto'] + df_0['desc_title'] + df_0['desc_ubica'] + df_0['desc_vend']\n",
        "df = df[['area', 'banos', 'habitaciones', 'lat', 'lng', 'percepcion_0', 'percepcion_180', 'percepcion_270', 'percepcion_90', 'Estrato', 'description', 'precio']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwnhuBFWRWGE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = df[df[\"precio\"] >0.8e8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJmYs1xMRWGK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df = df.drop(columns=['desc_main', 'desc_sec', 'desc_texto', 'desc_title', 'desc_ubica', 'desc_vend', 'descripcion','imagens','mapa','link'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72KwWODjRWGM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#lista"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jDhXmZ93RWGQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ind  = df.columns.tolist().index(\"precio\")\n",
        "lista = df.columns.tolist()\n",
        "V_objetivo = lista.pop(ind)\n",
        "X = df[lista]\n",
        "y = df[[V_objetivo]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bB8N1KEERWGT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#X.head().columns.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5mwf-1uRWGX",
        "colab_type": "code",
        "outputId": "243f14f5-6747-4105-a43a-4173740a36b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area</th>\n",
              "      <th>banos</th>\n",
              "      <th>habitaciones</th>\n",
              "      <th>lat</th>\n",
              "      <th>lng</th>\n",
              "      <th>percepcion_0</th>\n",
              "      <th>percepcion_180</th>\n",
              "      <th>percepcion_270</th>\n",
              "      <th>percepcion_90</th>\n",
              "      <th>Estrato</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-75.598370</td>\n",
              "      <td>6.278447</td>\n",
              "      <td>4.707252</td>\n",
              "      <td>4.382922</td>\n",
              "      <td>5.228550</td>\n",
              "      <td>4.345707</td>\n",
              "      <td>2</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 41 Op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-75.595000</td>\n",
              "      <td>6.282000</td>\n",
              "      <td>5.046718</td>\n",
              "      <td>5.681197</td>\n",
              "      <td>4.264784</td>\n",
              "      <td>5.246507</td>\n",
              "      <td>3</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 36 Op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-75.658270</td>\n",
              "      <td>6.186444</td>\n",
              "      <td>5.616747</td>\n",
              "      <td>5.264588</td>\n",
              "      <td>4.858189</td>\n",
              "      <td>5.142254</td>\n",
              "      <td>3</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 43 Op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-75.595636</td>\n",
              "      <td>6.200800</td>\n",
              "      <td>5.077016</td>\n",
              "      <td>5.385752</td>\n",
              "      <td>5.238197</td>\n",
              "      <td>5.441324</td>\n",
              "      <td>2</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 60 Op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-75.598985</td>\n",
              "      <td>6.260916</td>\n",
              "      <td>4.849460</td>\n",
              "      <td>5.030130</td>\n",
              "      <td>4.857601</td>\n",
              "      <td>5.665002</td>\n",
              "      <td>4</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 48 Op...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    area  banos  habitaciones        lat       lng  percepcion_0  \\\n",
              "53    41      1             2 -75.598370  6.278447      4.707252   \n",
              "54    36      1             3 -75.595000  6.282000      5.046718   \n",
              "55    43      1             2 -75.658270  6.186444      5.616747   \n",
              "56    60      1             2 -75.595636  6.200800      5.077016   \n",
              "57    48      1             2 -75.598985  6.260916      4.849460   \n",
              "\n",
              "    percepcion_180  percepcion_270  percepcion_90  Estrato  \\\n",
              "53        4.382922        5.228550       4.345707        2   \n",
              "54        5.681197        4.264784       5.246507        3   \n",
              "55        5.264588        4.858189       5.142254        3   \n",
              "56        5.385752        5.238197       5.441324        2   \n",
              "57        5.030130        4.857601       5.665002        4   \n",
              "\n",
              "                                          description  \n",
              "53   Inmueble: Apartamento Metros de const.: 41 Op...  \n",
              "54   Inmueble: Apartamento Metros de const.: 36 Op...  \n",
              "55   Inmueble: Apartamento Metros de const.: 43 Op...  \n",
              "56   Inmueble: Apartamento Metros de const.: 60 Op...  \n",
              "57   Inmueble: Apartamento Metros de const.: 48 Op...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "CgS3q0PhRWGb",
        "colab_type": "code",
        "outputId": "defd50b8-f4b1-4182-e3d1-98ae6d07e3fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "cell_type": "code",
      "source": [
        "y.hist()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff9d1d29d50>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEUCAYAAADUVaY3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff9d1cc3290>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LcRLw4zfRWGf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7PCMnJFHRWGh",
        "colab_type": "code",
        "outputId": "daf5bab2-ccb6-4d34-a9f4-9deeae52a5da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "cell_type": "code",
      "source": [
        "y_train.hist()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff9ceec9890>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEUCAYAAADUVaY3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUJekghjqklQQQ12SCvL/YMrRiofdeKAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff9ceec9190>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XI6t2pmuRWGj",
        "colab_type": "code",
        "outputId": "550fb969-8346-4db3-f76d-4ecaa2981a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "cell_type": "code",
      "source": [
        "y_test.hist()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7ff9cec03510>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEUCAYAAADk2bcWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQUyvCWpQP8Pe7vdDesMLs0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff9ceba35d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OJOoHdrGRWGm",
        "colab_type": "code",
        "outputId": "dd8bbd52-2b19-4dcc-b9f5-1ad64eb3e424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.columns[0 : -1 ]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([u'area', u'banos', u'habitaciones', u'lat', u'lng', u'percepcion_0',\n",
              "       u'percepcion_180', u'percepcion_270', u'percepcion_90', u'Estrato'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "tZSiaCk1RWGp",
        "colab_type": "code",
        "outputId": "eb4a8d66-eb49-4244-c81c-97f92eccf5f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area</th>\n",
              "      <th>banos</th>\n",
              "      <th>habitaciones</th>\n",
              "      <th>lat</th>\n",
              "      <th>lng</th>\n",
              "      <th>percepcion_0</th>\n",
              "      <th>percepcion_180</th>\n",
              "      <th>percepcion_270</th>\n",
              "      <th>percepcion_90</th>\n",
              "      <th>Estrato</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-75.560286</td>\n",
              "      <td>6.252380</td>\n",
              "      <td>4.318297</td>\n",
              "      <td>5.006413</td>\n",
              "      <td>4.393741</td>\n",
              "      <td>4.716533</td>\n",
              "      <td>4</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 45 Op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-75.599427</td>\n",
              "      <td>6.279888</td>\n",
              "      <td>4.623398</td>\n",
              "      <td>5.794126</td>\n",
              "      <td>5.650282</td>\n",
              "      <td>5.263768</td>\n",
              "      <td>3</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 45 Op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-75.656639</td>\n",
              "      <td>6.186241</td>\n",
              "      <td>4.402307</td>\n",
              "      <td>5.063399</td>\n",
              "      <td>4.032859</td>\n",
              "      <td>4.199199</td>\n",
              "      <td>3</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 38 Op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>-75.556054</td>\n",
              "      <td>6.237129</td>\n",
              "      <td>4.398416</td>\n",
              "      <td>5.371661</td>\n",
              "      <td>5.485881</td>\n",
              "      <td>5.190678</td>\n",
              "      <td>4</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 57 Op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-75.574635</td>\n",
              "      <td>6.227697</td>\n",
              "      <td>4.541640</td>\n",
              "      <td>4.799234</td>\n",
              "      <td>4.683369</td>\n",
              "      <td>4.625693</td>\n",
              "      <td>3</td>\n",
              "      <td>Inmueble: Apartamento Metros de const.: 28 Op...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     area  banos  habitaciones        lat       lng  percepcion_0  \\\n",
              "309    45      2             1 -75.560286  6.252380      4.318297   \n",
              "228    45      1             2 -75.599427  6.279888      4.623398   \n",
              "110    38      1             2 -75.656639  6.186241      4.402307   \n",
              "564    57      2             3 -75.556054  6.237129      4.398416   \n",
              "121    28      1             1 -75.574635  6.227697      4.541640   \n",
              "\n",
              "     percepcion_180  percepcion_270  percepcion_90  Estrato  \\\n",
              "309        5.006413        4.393741       4.716533        4   \n",
              "228        5.794126        5.650282       5.263768        3   \n",
              "110        5.063399        4.032859       4.199199        3   \n",
              "564        5.371661        5.485881       5.190678        4   \n",
              "121        4.799234        4.683369       4.625693        3   \n",
              "\n",
              "                                           description  \n",
              "309   Inmueble: Apartamento Metros de const.: 45 Op...  \n",
              "228   Inmueble: Apartamento Metros de const.: 45 Op...  \n",
              "110   Inmueble: Apartamento Metros de const.: 38 Op...  \n",
              "564   Inmueble: Apartamento Metros de const.: 57 Op...  \n",
              "121   Inmueble: Apartamento Metros de const.: 28 Op...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "oj8wMGC9RWGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df_0['desc_main'] + df_0['desc_sec'] + df_0['desc_texto'] + df_0['desc_title'] + df_0['desc_ubica'] + df_0['desc_vend']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Go9q3jALRWGv",
        "colab_type": "code",
        "outputId": "4bbb168f-5d5f-45b7-f71f-fe2f08d26f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from keras.preprocessing.text import Tokenizer\n",
        "    from keras.preprocessing.sequence import pad_sequences\n",
        "    from keras.layers import Input, Embedding, LSTM, Dense, SimpleRNN, concatenate, Dropout\n",
        "    from keras.models import Model\n",
        "    from keras.optimizers import RMSprop\n",
        "    from keras.callbacks import EarlyStopping \n",
        "except ModuleNotFoundError:\n",
        "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "    from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, SimpleRNN, concatenate\n",
        "    from tensorflow.keras.models import Model\n",
        "    from tensorflow.keras.optimizers import RMSprop\n",
        "    from tensorflow.keras.callbacks import EarlyStopping \n",
        "    \n",
        "    \n",
        "MAX_LEN = 100\n",
        "MAX_WORDS = 25000\n",
        "INDEX = 3\n",
        "\n",
        "tokenizer = Tokenizer(num_words = MAX_WORDS)\n",
        "tokenizer.fit_on_texts(X_train['description'])\n",
        "print('Found {} unique tokens.'.format(len(tokenizer.word_index)))\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(X_train['description'])\n",
        "X_train_main = pad_sequences(sequences, maxlen = MAX_LEN)\n",
        "print('\\nTrain Dataset:')\n",
        "print('\\tShape of the main input: {}'.format(X_train_main.shape))\n",
        "X_train_aux = X_train[X_train.columns[0 : -1 ]]\n",
        "print('\\tShape of the aux input: {}'.format(X_train_aux.shape))\n",
        "print('\\tShape of output: {}'.format(y_train.shape))\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(X_test['description'])\n",
        "X_test_main = pad_sequences(sequences, maxlen = MAX_LEN)\n",
        "#sequences = tokenizer.texts_to_sequences(X_test['description'])\n",
        "#np.vstack((X_test_main, pad_sequences(sequences, maxlen = MAX_LEN)))\n",
        "print('\\nValidation Dataset:')\n",
        "print('\\tShape of the main input: {}'.format(X_test_main.shape))\n",
        "X_test_aux = X_test[X_test.columns[0 : -1]]\n",
        "print('\\tShape of the aux input: {}'.format(X_test_aux.shape))\n",
        "print('\\tShape of output: {}'.format(y_test.shape))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 3102 unique tokens.\n",
            "\n",
            "Train Dataset:\n",
            "\tShape of the main input: (707, 100)\n",
            "\tShape of the aux input: (707, 10)\n",
            "\tShape of output: (707, 1)\n",
            "\n",
            "Validation Dataset:\n",
            "\tShape of the main input: (177, 100)\n",
            "\tShape of the aux input: (177, 10)\n",
            "\tShape of output: (177, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CjgpgEnhRWGx",
        "colab_type": "code",
        "outputId": "0184306f-2757-4fe6-bf0f-f5f0fc848637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 300\n",
        "\n",
        "embeddings_index = {}\n",
        "#with open('../datasets/{}/cbow_s{}.txt'.format(EMBEDDING, EMBEDDING_DIM), mode = 'r', encoding = 'UTF-8') as f:\n",
        "with open('./SBW-vectors-300-min5.txt', mode = 'r') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        values = line.split(' ')\n",
        "        word = values[0]\n",
        "        try:\n",
        "            coefs = np.asarray(values[1 : ], dtype = 'float32')\n",
        "            embeddings_index[word] = coefs\n",
        "        except:\n",
        "            print('[ERROR] {}: {}'.format(i, values[1 : ]))\n",
        "    f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "embedding_weights = np.zeros((MAX_WORDS, EMBEDDING_DIM))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < MAX_WORDS and embedding_vector is not None:\n",
        "            embedding_weights[i] = embedding_vector"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000654 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZXQYvq7LZ35b",
        "colab_type": "code",
        "outputId": "a5f77d16-7631-4c95-c816-0d44d4b94e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train_main.shape[1]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "6oOzwWBQRWGz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#X_train_main"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lFeO4FIrRWG2",
        "colab_type": "code",
        "outputId": "e4028775-dceb-4c0e-81b3-d8621211870a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "LSTM_SIZE = 40\n",
        "DENSE1_SIZE = 256\n",
        "DENSE2_SIZE = 256\n",
        "LEARNING_RATE = 0.01\n",
        "RHO = 0.05\n",
        "EPSILON = None\n",
        "DECAY = 0.0\n",
        "\n",
        "main_input = Input(shape = (X_train_main.shape[1], ), dtype = 'int32', name = 'main_input')\n",
        "\n",
        "x = Embedding(MAX_WORDS, EMBEDDING_DIM, \n",
        "              input_length = MAX_LEN, \n",
        "              weights = [embedding_weights], \n",
        "              name = 'embedding',\n",
        "              trainable = False)(main_input)\n",
        "\n",
        "lstm_out = LSTM(LSTM_SIZE, name = 'lstm')(x)\n",
        "\n",
        "aux_input = Input(shape = (X_train_aux.shape[1], ), name = 'aux_input')\n",
        "\n",
        "x = concatenate([lstm_out, aux_input])\n",
        "x = Dense(DENSE1_SIZE, kernel_initializer = 'uniform', activation = 'relu', name = 'dense1')(x)\n",
        "#x = Dropout(.5)(x)\n",
        "#x = Dense(DENSE2_SIZE, kernel_initializer = 'uniform', activation='relu', name = 'dense2')(x)\n",
        "#x = Dropout(.3)(x)\n",
        "#x = Dense(DENSE2_SIZE, kernel_initializer = 'uniform', activation='relu', name = 'dense3')(x)\n",
        "#x = Dropout(.3)(x)\n",
        "\n",
        "main_output = Dense(1, activation = 'linear', kernel_initializer = 'normal', name = 'main_output')(x)\n",
        "\n",
        "model = Model(inputs = [main_input, aux_input], outputs = [main_output])\n",
        "optimizer = RMSprop(lr = LEARNING_RATE, rho = RHO, epsilon = EPSILON, decay = DECAY)\n",
        "model.compile(optimizer = optimizer, loss = 'mse', metrics = ['mse'])\n",
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "main_input (InputLayer)         (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 300)     7500000     main_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 40)           54560       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "aux_input (InputLayer)          (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 50)           0           lstm[0][0]                       \n",
            "                                                                 aux_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 256)          13056       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "main_output (Dense)             (None, 1)            257         dense1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 7,567,873\n",
            "Trainable params: 67,873\n",
            "Non-trainable params: 7,500,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FfiONBuRRWG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#X_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2H5GqqYHRWG6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#y_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UuwH7-ogRWG9",
        "colab_type": "code",
        "outputId": "6667555e-821b-406d-e752-58dd727d3522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 59265
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "#df_results = pd.read_csv(DF_RESULTS_FILENAME, index_col = 0)\n",
        "    \n",
        "PATIENCE = 10\n",
        "EPOCHS = 2000\n",
        "BATCH_SIZE = int(math.ceil(y_train.shape[0] / 4))\n",
        "\n",
        "\n",
        "history = model.fit([X_train_main, X_train_aux], \n",
        "                    y_train,\n",
        "                    epochs = EPOCHS, \n",
        "                    batch_size = BATCH_SIZE,\n",
        "                    validation_data = ([X_test_main, X_test_aux], y_test),\n",
        "                    verbose = 1,\n",
        "                    callbacks = [EarlyStopping(monitor = 'mean_squared_error', \n",
        "                                               restore_best_weights = True,\n",
        "                                               patience = PATIENCE)])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 707 samples, validate on 177 samples\n",
            "Epoch 1/2000\n",
            "707/707 [==============================] - 2s 3ms/step - loss: 22943534381125128.0000 - mean_squared_error: 22943534381125128.0000 - val_loss: 24306116921064364.0000 - val_mean_squared_error: 24306116921064364.0000\n",
            "Epoch 2/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22943494165165440.0000 - mean_squared_error: 22943494165165440.0000 - val_loss: 24306052338830132.0000 - val_mean_squared_error: 24306052338830132.0000\n",
            "Epoch 3/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22943421670126928.0000 - mean_squared_error: 22943421670126928.0000 - val_loss: 24305951140179808.0000 - val_mean_squared_error: 24305951140179808.0000\n",
            "Epoch 4/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22943313208534140.0000 - mean_squared_error: 22943313208534140.0000 - val_loss: 24305811201895084.0000 - val_mean_squared_error: 24305811201895084.0000\n",
            "Epoch 5/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22943170107756736.0000 - mean_squared_error: 22943170107756736.0000 - val_loss: 24305638966426908.0000 - val_mean_squared_error: 24305638966426908.0000\n",
            "Epoch 6/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22942991620579756.0000 - mean_squared_error: 22942991620579756.0000 - val_loss: 24305430114542636.0000 - val_mean_squared_error: 24305430114542636.0000\n",
            "Epoch 7/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22942782904608908.0000 - mean_squared_error: 22942782904608908.0000 - val_loss: 24305184670507604.0000 - val_mean_squared_error: 24305184670507604.0000\n",
            "Epoch 8/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22942533486684904.0000 - mean_squared_error: 22942533486684904.0000 - val_loss: 24304904769672812.0000 - val_mean_squared_error: 24304904769672812.0000\n",
            "Epoch 9/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22942252151139720.0000 - mean_squared_error: 22942252151139720.0000 - val_loss: 24304586129203616.0000 - val_mean_squared_error: 24304586129203616.0000\n",
            "Epoch 10/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22941934937126572.0000 - mean_squared_error: 22941934937126572.0000 - val_loss: 24304235167285620.0000 - val_mean_squared_error: 24304235167285620.0000\n",
            "Epoch 11/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22941585061314744.0000 - mean_squared_error: 22941585061314744.0000 - val_loss: 24303845477865900.0000 - val_mean_squared_error: 24303845477865900.0000\n",
            "Epoch 12/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22941199382971436.0000 - mean_squared_error: 22941199382971436.0000 - val_loss: 24303421331646412.0000 - val_mean_squared_error: 24303421331646412.0000\n",
            "Epoch 13/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22940780550761052.0000 - mean_squared_error: 22940780550761052.0000 - val_loss: 24302958433659840.0000 - val_mean_squared_error: 24302958433659840.0000\n",
            "Epoch 14/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22940325174879144.0000 - mean_squared_error: 22940325174879144.0000 - val_loss: 24302463226357148.0000 - val_mean_squared_error: 24302463226357148.0000\n",
            "Epoch 15/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22939833932679112.0000 - mean_squared_error: 22939833932679112.0000 - val_loss: 24301929303685408.0000 - val_mean_squared_error: 24301929303685408.0000\n",
            "Epoch 16/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22939313328879808.0000 - mean_squared_error: 22939313328879808.0000 - val_loss: 24301360887815868.0000 - val_mean_squared_error: 24301360887815868.0000\n",
            "Epoch 17/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22938752135513340.0000 - mean_squared_error: 22938752135513340.0000 - val_loss: 24300755867662900.0000 - val_mean_squared_error: 24300755867662900.0000\n",
            "Epoch 18/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22938155447917492.0000 - mean_squared_error: 22938155447917492.0000 - val_loss: 24300114267491868.0000 - val_mean_squared_error: 24300114267491868.0000\n",
            "Epoch 19/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22937524701291736.0000 - mean_squared_error: 22937524701291736.0000 - val_loss: 24299436063037404.0000 - val_mean_squared_error: 24299436063037404.0000\n",
            "Epoch 20/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22936861200224796.0000 - mean_squared_error: 22936861200224796.0000 - val_loss: 24298727708883140.0000 - val_mean_squared_error: 24298727708883140.0000\n",
            "Epoch 21/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22936164004623048.0000 - mean_squared_error: 22936164004623048.0000 - val_loss: 24297976295861836.0000 - val_mean_squared_error: 24297976295861836.0000\n",
            "Epoch 22/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22935430464303352.0000 - mean_squared_error: 22935430464303352.0000 - val_loss: 24297192622055100.0000 - val_mean_squared_error: 24297192622055100.0000\n",
            "Epoch 23/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22934667888911252.0000 - mean_squared_error: 22934667888911252.0000 - val_loss: 24296376614666892.0000 - val_mean_squared_error: 24296376614666892.0000\n",
            "Epoch 24/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22933865012510604.0000 - mean_squared_error: 22933865012510604.0000 - val_loss: 24295519683762604.0000 - val_mean_squared_error: 24295519683762604.0000\n",
            "Epoch 25/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22933028099860992.0000 - mean_squared_error: 22933028099860992.0000 - val_loss: 24294628332456572.0000 - val_mean_squared_error: 24294628332456572.0000\n",
            "Epoch 26/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22932159823926504.0000 - mean_squared_error: 22932159823926504.0000 - val_loss: 24293700376867116.0000 - val_mean_squared_error: 24293700376867116.0000\n",
            "Epoch 27/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22931257362907556.0000 - mean_squared_error: 22931257362907556.0000 - val_loss: 24292735804861556.0000 - val_mean_squared_error: 24292735804861556.0000\n",
            "Epoch 28/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22930315477187032.0000 - mean_squared_error: 22930315477187032.0000 - val_loss: 24291741107421556.0000 - val_mean_squared_error: 24291741107421556.0000\n",
            "Epoch 29/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22929340486198788.0000 - mean_squared_error: 22929340486198788.0000 - val_loss: 24290701215763532.0000 - val_mean_squared_error: 24290701215763532.0000\n",
            "Epoch 30/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22928324948167808.0000 - mean_squared_error: 22928324948167808.0000 - val_loss: 24289628990524028.0000 - val_mean_squared_error: 24289628990524028.0000\n",
            "Epoch 31/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22927279290691484.0000 - mean_squared_error: 22927279290691484.0000 - val_loss: 24288518037782804.0000 - val_mean_squared_error: 24288518037782804.0000\n",
            "Epoch 32/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22926203492507612.0000 - mean_squared_error: 22926203492507612.0000 - val_loss: 24287379034294724.0000 - val_mean_squared_error: 24287379034294724.0000\n",
            "Epoch 33/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22925090655546364.0000 - mean_squared_error: 22925090655546364.0000 - val_loss: 24286201339702948.0000 - val_mean_squared_error: 24286201339702948.0000\n",
            "Epoch 34/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22923942796680648.0000 - mean_squared_error: 22923942796680648.0000 - val_loss: 24284982709462428.0000 - val_mean_squared_error: 24284982709462428.0000\n",
            "Epoch 35/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22922761297954388.0000 - mean_squared_error: 22922761297954388.0000 - val_loss: 24283729695218188.0000 - val_mean_squared_error: 24283729695218188.0000\n",
            "Epoch 36/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22921539505813236.0000 - mean_squared_error: 22921539505813236.0000 - val_loss: 24282446458478084.0000 - val_mean_squared_error: 24282446458478084.0000\n",
            "Epoch 37/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22920287226694180.0000 - mean_squared_error: 22920287226694180.0000 - val_loss: 24281118051785316.0000 - val_mean_squared_error: 24281118051785316.0000\n",
            "Epoch 38/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22919000999412476.0000 - mean_squared_error: 22919000999412476.0000 - val_loss: 24279759446862044.0000 - val_mean_squared_error: 24279759446862044.0000\n",
            "Epoch 39/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22917677213947880.0000 - mean_squared_error: 22917677213947880.0000 - val_loss: 24278362162967756.0000 - val_mean_squared_error: 24278362162967756.0000\n",
            "Epoch 40/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22916324065365280.0000 - mean_squared_error: 22916324065365280.0000 - val_loss: 24276934680842956.0000 - val_mean_squared_error: 24276934680842956.0000\n",
            "Epoch 41/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22914939787382164.0000 - mean_squared_error: 22914939787382164.0000 - val_loss: 24275466311600116.0000 - val_mean_squared_error: 24275466311600116.0000\n",
            "Epoch 42/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22913501834457684.0000 - mean_squared_error: 22913501834457684.0000 - val_loss: 24273959178457524.0000 - val_mean_squared_error: 24273959178457524.0000\n",
            "Epoch 43/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22912049579656604.0000 - mean_squared_error: 22912049579656604.0000 - val_loss: 24272424055231460.0000 - val_mean_squared_error: 24272424055231460.0000\n",
            "Epoch 44/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22910551708293396.0000 - mean_squared_error: 22910551708293396.0000 - val_loss: 24270850204503668.0000 - val_mean_squared_error: 24270850204503668.0000\n",
            "Epoch 45/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22909018766426364.0000 - mean_squared_error: 22909018766426364.0000 - val_loss: 24269233282776164.0000 - val_mean_squared_error: 24269233282776164.0000\n",
            "Epoch 46/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22907455197858316.0000 - mean_squared_error: 22907455197858316.0000 - val_loss: 24267592653799796.0000 - val_mean_squared_error: 24267592653799796.0000\n",
            "Epoch 47/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22905859906066476.0000 - mean_squared_error: 22905859906066476.0000 - val_loss: 24265904683121764.0000 - val_mean_squared_error: 24265904683121764.0000\n",
            "Epoch 48/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22904223028420852.0000 - mean_squared_error: 22904223028420852.0000 - val_loss: 24264188698094900.0000 - val_mean_squared_error: 24264188698094900.0000\n",
            "Epoch 49/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22902558458259780.0000 - mean_squared_error: 22902558458259780.0000 - val_loss: 24262438292666288.0000 - val_mean_squared_error: 24262438292666288.0000\n",
            "Epoch 50/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22900856108181300.0000 - mean_squared_error: 22900856108181300.0000 - val_loss: 24260646951588928.0000 - val_mean_squared_error: 24260646951588928.0000\n",
            "Epoch 51/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22899117932790384.0000 - mean_squared_error: 22899117932790384.0000 - val_loss: 24258827632560764.0000 - val_mean_squared_error: 24258827632560764.0000\n",
            "Epoch 52/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22897340920446256.0000 - mean_squared_error: 22897340920446256.0000 - val_loss: 24256960971830932.0000 - val_mean_squared_error: 24256960971830932.0000\n",
            "Epoch 53/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22895536861046764.0000 - mean_squared_error: 22895536861046764.0000 - val_loss: 24255068456368604.0000 - val_mean_squared_error: 24255068456368604.0000\n",
            "Epoch 54/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22893697005190704.0000 - mean_squared_error: 22893697005190704.0000 - val_loss: 24253137189139196.0000 - val_mean_squared_error: 24253137189139196.0000\n",
            "Epoch 55/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22891825793643416.0000 - mean_squared_error: 22891825793643416.0000 - val_loss: 24251162850910068.0000 - val_mean_squared_error: 24251162850910068.0000\n",
            "Epoch 56/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22889922239230664.0000 - mean_squared_error: 22889922239230664.0000 - val_loss: 24249164829697436.0000 - val_mean_squared_error: 24249164829697436.0000\n",
            "Epoch 57/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22887981409118720.0000 - mean_squared_error: 22887981409118720.0000 - val_loss: 24247119478915812.0000 - val_mean_squared_error: 24247119478915812.0000\n",
            "Epoch 58/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22885994752859964.0000 - mean_squared_error: 22885994752859964.0000 - val_loss: 24245037463187388.0000 - val_mean_squared_error: 24245037463187388.0000\n",
            "Epoch 59/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22883988350079004.0000 - mean_squared_error: 22883988350079004.0000 - val_loss: 24242933972622480.0000 - val_mean_squared_error: 24242933972622480.0000\n",
            "Epoch 60/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22881949779086484.0000 - mean_squared_error: 22881949779086484.0000 - val_loss: 24240798160608772.0000 - val_mean_squared_error: 24240798160608772.0000\n",
            "Epoch 61/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22879876863542892.0000 - mean_squared_error: 22879876863542892.0000 - val_loss: 24238617142244368.0000 - val_mean_squared_error: 24238617142244368.0000\n",
            "Epoch 62/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22877748798371500.0000 - mean_squared_error: 22877748798371500.0000 - val_loss: 24236395163965868.0000 - val_mean_squared_error: 24236395163965868.0000\n",
            "Epoch 63/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22875587842073260.0000 - mean_squared_error: 22875587842073260.0000 - val_loss: 24234145268399948.0000 - val_mean_squared_error: 24234145268399948.0000\n",
            "Epoch 64/2000\n",
            "528/707 [=====================>........] - ETA: 0s - loss: 22992318576809300.0000 - mean_squared_error: 22992318576809300.0000Epoch 65/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22871199744759736.0000 - mean_squared_error: 22871199744759736.0000 - val_loss: 24229522730985228.0000 - val_mean_squared_error: 24229522730985228.0000\n",
            "Epoch 66/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22868943854193212.0000 - mean_squared_error: 22868943854193212.0000 - val_loss: 24227160814422004.0000 - val_mean_squared_error: 24227160814422004.0000\n",
            "Epoch 67/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22866638683888772.0000 - mean_squared_error: 22866638683888772.0000 - val_loss: 24224758047138764.0000 - val_mean_squared_error: 24224758047138764.0000\n",
            "Epoch 68/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22864322603030920.0000 - mean_squared_error: 22864322603030920.0000 - val_loss: 24222327265506692.0000 - val_mean_squared_error: 24222327265506692.0000\n",
            "Epoch 69/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22861964131392600.0000 - mean_squared_error: 22861964131392600.0000 - val_loss: 24219853412874900.0000 - val_mean_squared_error: 24219853412874900.0000\n",
            "Epoch 70/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22859577538957088.0000 - mean_squared_error: 22859577538957088.0000 - val_loss: 24217351606557652.0000 - val_mean_squared_error: 24217351606557652.0000\n",
            "Epoch 71/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22857142924291768.0000 - mean_squared_error: 22857142924291768.0000 - val_loss: 24214802410008044.0000 - val_mean_squared_error: 24214802410008044.0000\n",
            "Epoch 72/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22854677804423792.0000 - mean_squared_error: 22854677804423792.0000 - val_loss: 24212238156807540.0000 - val_mean_squared_error: 24212238156807540.0000\n",
            "Epoch 73/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22852190960647680.0000 - mean_squared_error: 22852190960647680.0000 - val_loss: 24209622206274704.0000 - val_mean_squared_error: 24209622206274704.0000\n",
            "Epoch 74/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22849660204324052.0000 - mean_squared_error: 22849660204324052.0000 - val_loss: 24206974007089116.0000 - val_mean_squared_error: 24206974007089116.0000\n",
            "Epoch 75/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22847094796665968.0000 - mean_squared_error: 22847094796665968.0000 - val_loss: 24204284872254784.0000 - val_mean_squared_error: 24204284872254784.0000\n",
            "Epoch 76/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22844478396142988.0000 - mean_squared_error: 22844478396142988.0000 - val_loss: 24201561256355316.0000 - val_mean_squared_error: 24201561256355316.0000\n",
            "Epoch 77/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22841849657460772.0000 - mean_squared_error: 22841849657460772.0000 - val_loss: 24198807502888724.0000 - val_mean_squared_error: 24198807502888724.0000\n",
            "Epoch 78/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22839185732851292.0000 - mean_squared_error: 22839185732851292.0000 - val_loss: 24196017169404064.0000 - val_mean_squared_error: 24196017169404064.0000\n",
            "Epoch 79/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22836487453059632.0000 - mean_squared_error: 22836487453059632.0000 - val_loss: 24193213963150192.0000 - val_mean_squared_error: 24193213963150192.0000\n",
            "Epoch 80/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22833760973496844.0000 - mean_squared_error: 22833760973496844.0000 - val_loss: 24190339647282412.0000 - val_mean_squared_error: 24190339647282412.0000\n",
            "Epoch 81/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22830991008149544.0000 - mean_squared_error: 22830991008149544.0000 - val_loss: 24187439500947476.0000 - val_mean_squared_error: 24187439500947476.0000\n",
            "Epoch 82/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22828163747209528.0000 - mean_squared_error: 22828163747209528.0000 - val_loss: 24184504934210796.0000 - val_mean_squared_error: 24184504934210796.0000\n",
            "Epoch 83/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22825341106244944.0000 - mean_squared_error: 22825341106244944.0000 - val_loss: 24181542353125284.0000 - val_mean_squared_error: 24181542353125284.0000\n",
            "Epoch 84/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22822461395978348.0000 - mean_squared_error: 22822461395978348.0000 - val_loss: 24178541044538048.0000 - val_mean_squared_error: 24178541044538048.0000\n",
            "Epoch 85/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22819563166323064.0000 - mean_squared_error: 22819563166323064.0000 - val_loss: 24175496640685744.0000 - val_mean_squared_error: 24175496640685744.0000\n",
            "Epoch 86/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22816595407708172.0000 - mean_squared_error: 22816595407708172.0000 - val_loss: 24172422087133636.0000 - val_mean_squared_error: 24172422087133636.0000\n",
            "Epoch 87/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22813628909638844.0000 - mean_squared_error: 22813628909638844.0000 - val_loss: 24169304498979836.0000 - val_mean_squared_error: 24169304498979836.0000\n",
            "Epoch 88/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22810603633696712.0000 - mean_squared_error: 22810603633696712.0000 - val_loss: 24166156761126228.0000 - val_mean_squared_error: 24166156761126228.0000\n",
            "Epoch 89/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22807586733548296.0000 - mean_squared_error: 22807586733548296.0000 - val_loss: 24162974602870876.0000 - val_mean_squared_error: 24162974602870876.0000\n",
            "Epoch 90/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22804479620861912.0000 - mean_squared_error: 22804479620861912.0000 - val_loss: 24159747177601452.0000 - val_mean_squared_error: 24159747177601452.0000\n",
            "Epoch 91/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22801377184343952.0000 - mean_squared_error: 22801377184343952.0000 - val_loss: 24156500400713844.0000 - val_mean_squared_error: 24156500400713844.0000\n",
            "Epoch 92/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22798226938218324.0000 - mean_squared_error: 22798226938218324.0000 - val_loss: 24153208441740896.0000 - val_mean_squared_error: 24153208441740896.0000\n",
            "Epoch 93/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22795030316165772.0000 - mean_squared_error: 22795030316165772.0000 - val_loss: 24149884149186468.0000 - val_mean_squared_error: 24149884149186468.0000\n",
            "Epoch 94/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22791828910114992.0000 - mean_squared_error: 22791828910114992.0000 - val_loss: 24146512502797700.0000 - val_mean_squared_error: 24146512502797700.0000\n",
            "Epoch 95/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22788553459921516.0000 - mean_squared_error: 22788553459921516.0000 - val_loss: 24143123640141716.0000 - val_mean_squared_error: 24143123640141716.0000\n",
            "Epoch 96/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22785266907814696.0000 - mean_squared_error: 22785266907814696.0000 - val_loss: 24139691682220668.0000 - val_mean_squared_error: 24139691682220668.0000\n",
            "Epoch 97/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22781945519088416.0000 - mean_squared_error: 22781945519088416.0000 - val_loss: 24136212394730628.0000 - val_mean_squared_error: 24136212394730628.0000\n",
            "Epoch 98/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22778588567789928.0000 - mean_squared_error: 22778588567789928.0000 - val_loss: 24132711523210028.0000 - val_mean_squared_error: 24132711523210028.0000\n",
            "Epoch 99/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22775213631695568.0000 - mean_squared_error: 22775213631695568.0000 - val_loss: 24129176267685708.0000 - val_mean_squared_error: 24129176267685708.0000\n",
            "Epoch 100/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22771779392247968.0000 - mean_squared_error: 22771779392247968.0000 - val_loss: 24125608690712576.0000 - val_mean_squared_error: 24125608690712576.0000\n",
            "Epoch 101/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22768332346872416.0000 - mean_squared_error: 22768332346872416.0000 - val_loss: 24121993747772432.0000 - val_mean_squared_error: 24121993747772432.0000\n",
            "Epoch 102/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22764829169251016.0000 - mean_squared_error: 22764829169251016.0000 - val_loss: 24118335745965248.0000 - val_mean_squared_error: 24118335745965248.0000\n",
            "Epoch 103/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22761322250998624.0000 - mean_squared_error: 22761322250998624.0000 - val_loss: 24114671313839792.0000 - val_mean_squared_error: 24114671313839792.0000\n",
            "Epoch 104/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22757742776958536.0000 - mean_squared_error: 22757742776958536.0000 - val_loss: 24110948705533028.0000 - val_mean_squared_error: 24110948705533028.0000\n",
            "Epoch 105/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22754143138745608.0000 - mean_squared_error: 22754143138745608.0000 - val_loss: 24107195971791808.0000 - val_mean_squared_error: 24107195971791808.0000\n",
            "Epoch 106/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22750515619694768.0000 - mean_squared_error: 22750515619694768.0000 - val_loss: 24103404449885492.0000 - val_mean_squared_error: 24103404449885492.0000\n",
            "Epoch 107/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22746847960620720.0000 - mean_squared_error: 22746847960620720.0000 - val_loss: 24099582851075424.0000 - val_mean_squared_error: 24099582851075424.0000\n",
            "Epoch 108/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22743136024504044.0000 - mean_squared_error: 22743136024504044.0000 - val_loss: 24095722427702228.0000 - val_mean_squared_error: 24095722427702228.0000\n",
            "Epoch 109/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22739408172101208.0000 - mean_squared_error: 22739408172101208.0000 - val_loss: 24091821165741700.0000 - val_mean_squared_error: 24091821165741700.0000\n",
            "Epoch 110/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22735646702618776.0000 - mean_squared_error: 22735646702618776.0000 - val_loss: 24087904774334220.0000 - val_mean_squared_error: 24087904774334220.0000\n",
            "Epoch 111/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22731845323960036.0000 - mean_squared_error: 22731845323960036.0000 - val_loss: 24083919542123248.0000 - val_mean_squared_error: 24083919542123248.0000\n",
            "Epoch 112/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22728017794296392.0000 - mean_squared_error: 22728017794296392.0000 - val_loss: 24079936408865220.0000 - val_mean_squared_error: 24079936408865220.0000\n",
            "Epoch 113/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22724131061515652.0000 - mean_squared_error: 22724131061515652.0000 - val_loss: 24075895160089260.0000 - val_mean_squared_error: 24075895160089260.0000\n",
            "Epoch 114/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22720228482310316.0000 - mean_squared_error: 22720228482310316.0000 - val_loss: 24071821638395200.0000 - val_mean_squared_error: 24071821638395200.0000\n",
            "Epoch 115/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22716307578113680.0000 - mean_squared_error: 22716307578113680.0000 - val_loss: 24067711500285036.0000 - val_mean_squared_error: 24067711500285036.0000\n",
            "Epoch 116/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22712316663520156.0000 - mean_squared_error: 22712316663520156.0000 - val_loss: 24063586305523988.0000 - val_mean_squared_error: 24063586305523988.0000\n",
            "Epoch 117/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22708326985172520.0000 - mean_squared_error: 22708326985172520.0000 - val_loss: 24059394344647036.0000 - val_mean_squared_error: 24059394344647036.0000\n",
            "Epoch 118/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22704296240376620.0000 - mean_squared_error: 22704296240376620.0000 - val_loss: 24055172258335636.0000 - val_mean_squared_error: 24055172258335636.0000\n",
            "Epoch 119/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22700219432512092.0000 - mean_squared_error: 22700219432512092.0000 - val_loss: 24050935042577292.0000 - val_mean_squared_error: 24050935042577292.0000\n",
            "Epoch 120/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22696119702461780.0000 - mean_squared_error: 22696119702461780.0000 - val_loss: 24046659159980596.0000 - val_mean_squared_error: 24046659159980596.0000\n",
            "Epoch 121/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22691965802364256.0000 - mean_squared_error: 22691965802364256.0000 - val_loss: 24042331555786220.0000 - val_mean_squared_error: 24042331555786220.0000\n",
            "Epoch 122/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22687792372922864.0000 - mean_squared_error: 22687792372922864.0000 - val_loss: 24037965187692092.0000 - val_mean_squared_error: 24037965187692092.0000\n",
            "Epoch 123/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22683582513714664.0000 - mean_squared_error: 22683582513714664.0000 - val_loss: 24033603199493996.0000 - val_mean_squared_error: 24033603199493996.0000\n",
            "Epoch 124/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22679323903286452.0000 - mean_squared_error: 22679323903286452.0000 - val_loss: 24029170089549316.0000 - val_mean_squared_error: 24029170089549316.0000\n",
            "Epoch 125/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22675048554939364.0000 - mean_squared_error: 22675048554939364.0000 - val_loss: 24024704706686540.0000 - val_mean_squared_error: 24024704706686540.0000\n",
            "Epoch 126/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22670735974936248.0000 - mean_squared_error: 22670735974936248.0000 - val_loss: 24020217776191220.0000 - val_mean_squared_error: 24020217776191220.0000\n",
            "Epoch 127/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22666414120051488.0000 - mean_squared_error: 22666414120051488.0000 - val_loss: 24015687774696188.0000 - val_mean_squared_error: 24015687774696188.0000\n",
            "Epoch 128/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22662026914232236.0000 - mean_squared_error: 22662026914232236.0000 - val_loss: 24011123364932080.0000 - val_mean_squared_error: 24011123364932080.0000\n",
            "Epoch 129/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22657594758573148.0000 - mean_squared_error: 22657594758573148.0000 - val_loss: 24006513724551932.0000 - val_mean_squared_error: 24006513724551932.0000\n",
            "Epoch 130/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22653149133301276.0000 - mean_squared_error: 22653149133301276.0000 - val_loss: 24001867467755680.0000 - val_mean_squared_error: 24001867467755680.0000\n",
            "Epoch 131/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22648698806042576.0000 - mean_squared_error: 22648698806042576.0000 - val_loss: 23997199736122952.0000 - val_mean_squared_error: 23997199736122952.0000\n",
            "Epoch 132/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22644146608477532.0000 - mean_squared_error: 22644146608477532.0000 - val_loss: 23992491044576124.0000 - val_mean_squared_error: 23992491044576124.0000\n",
            "Epoch 133/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22639612477719756.0000 - mean_squared_error: 22639612477719756.0000 - val_loss: 23987739294162248.0000 - val_mean_squared_error: 23987739294162248.0000\n",
            "Epoch 134/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22634973800654088.0000 - mean_squared_error: 22634973800654088.0000 - val_loss: 23982946644497656.0000 - val_mean_squared_error: 23982946644497656.0000\n",
            "Epoch 135/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22630462759142348.0000 - mean_squared_error: 22630462759142348.0000 - val_loss: 23978231656091996.0000 - val_mean_squared_error: 23978231656091996.0000\n",
            "Epoch 136/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22625817878066284.0000 - mean_squared_error: 22625817878066284.0000 - val_loss: 23973370117093204.0000 - val_mean_squared_error: 23973370117093204.0000\n",
            "Epoch 137/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22621126841279080.0000 - mean_squared_error: 22621126841279080.0000 - val_loss: 23968499963894464.0000 - val_mean_squared_error: 23968499963894464.0000\n",
            "Epoch 138/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22616407036715876.0000 - mean_squared_error: 22616407036715876.0000 - val_loss: 23963569511296120.0000 - val_mean_squared_error: 23963569511296120.0000\n",
            "Epoch 139/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22611635978066288.0000 - mean_squared_error: 22611635978066288.0000 - val_loss: 23958626161663212.0000 - val_mean_squared_error: 23958626161663212.0000\n",
            "Epoch 140/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22606856970385996.0000 - mean_squared_error: 22606856970385996.0000 - val_loss: 23953635482461316.0000 - val_mean_squared_error: 23953635482461316.0000\n",
            "Epoch 141/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22602056925263348.0000 - mean_squared_error: 22602056925263348.0000 - val_loss: 23948601647330968.0000 - val_mean_squared_error: 23948601647330968.0000\n",
            "Epoch 142/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22597197488701140.0000 - mean_squared_error: 22597197488701140.0000 - val_loss: 23943542054529520.0000 - val_mean_squared_error: 23943542054529520.0000\n",
            "Epoch 143/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22592298920552172.0000 - mean_squared_error: 22592298920552172.0000 - val_loss: 23938460901962860.0000 - val_mean_squared_error: 23938460901962860.0000\n",
            "Epoch 144/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22587356679814960.0000 - mean_squared_error: 22587356679814960.0000 - val_loss: 23933319474261948.0000 - val_mean_squared_error: 23933319474261948.0000\n",
            "Epoch 145/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22582412249069668.0000 - mean_squared_error: 22582412249069668.0000 - val_loss: 23928167272744764.0000 - val_mean_squared_error: 23928167272744764.0000\n",
            "Epoch 146/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22577433367462236.0000 - mean_squared_error: 22577433367462236.0000 - val_loss: 23922961250676944.0000 - val_mean_squared_error: 23922961250676944.0000\n",
            "Epoch 147/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22572414998885320.0000 - mean_squared_error: 22572414998885320.0000 - val_loss: 23917718600060348.0000 - val_mean_squared_error: 23917718600060348.0000\n",
            "Epoch 148/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22567340883819872.0000 - mean_squared_error: 22567340883819872.0000 - val_loss: 23912452314990952.0000 - val_mean_squared_error: 23912452314990952.0000\n",
            "Epoch 149/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22562241500131416.0000 - mean_squared_error: 22562241500131416.0000 - val_loss: 23907138627556508.0000 - val_mean_squared_error: 23907138627556508.0000\n",
            "Epoch 150/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22557118758381780.0000 - mean_squared_error: 22557118758381780.0000 - val_loss: 23901829247222036.0000 - val_mean_squared_error: 23901829247222036.0000\n",
            "Epoch 151/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22551982386034024.0000 - mean_squared_error: 22551982386034024.0000 - val_loss: 23896459603885988.0000 - val_mean_squared_error: 23896459603885988.0000\n",
            "Epoch 152/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22546757040431648.0000 - mean_squared_error: 22546757040431648.0000 - val_loss: 23891023230832060.0000 - val_mean_squared_error: 23891023230832060.0000\n",
            "Epoch 153/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22541520061360572.0000 - mean_squared_error: 22541520061360572.0000 - val_loss: 23885632051996152.0000 - val_mean_squared_error: 23885632051996152.0000\n",
            "Epoch 154/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22536297564894916.0000 - mean_squared_error: 22536297564894916.0000 - val_loss: 23880131036044616.0000 - val_mean_squared_error: 23880131036044616.0000\n",
            "Epoch 155/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22530990604282808.0000 - mean_squared_error: 22530990604282808.0000 - val_loss: 23874619294807520.0000 - val_mean_squared_error: 23874619294807520.0000\n",
            "Epoch 156/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22525678486064996.0000 - mean_squared_error: 22525678486064996.0000 - val_loss: 23869064458305352.0000 - val_mean_squared_error: 23869064458305352.0000\n",
            "Epoch 157/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22520290558940692.0000 - mean_squared_error: 22520290558940692.0000 - val_loss: 23863479544899432.0000 - val_mean_squared_error: 23863479544899432.0000\n",
            "Epoch 158/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22514926059739132.0000 - mean_squared_error: 22514926059739132.0000 - val_loss: 23857864445395684.0000 - val_mean_squared_error: 23857864445395684.0000\n",
            "Epoch 159/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22509481061794092.0000 - mean_squared_error: 22509481061794092.0000 - val_loss: 23852208434508540.0000 - val_mean_squared_error: 23852208434508540.0000\n",
            "Epoch 160/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22504021300278656.0000 - mean_squared_error: 22504021300278656.0000 - val_loss: 23846552447886748.0000 - val_mean_squared_error: 23846552447886748.0000\n",
            "Epoch 161/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22498540777729648.0000 - mean_squared_error: 22498540777729648.0000 - val_loss: 23840812454616488.0000 - val_mean_squared_error: 23840812454616488.0000\n",
            "Epoch 162/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22493021731085720.0000 - mean_squared_error: 22493021731085720.0000 - val_loss: 23835070338127928.0000 - val_mean_squared_error: 23835070338127928.0000\n",
            "Epoch 163/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22487464420049636.0000 - mean_squared_error: 22487464420049636.0000 - val_loss: 23829293764839596.0000 - val_mean_squared_error: 23829293764839596.0000\n",
            "Epoch 164/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22481888820471764.0000 - mean_squared_error: 22481888820471764.0000 - val_loss: 23823478512580248.0000 - val_mean_squared_error: 23823478512580248.0000\n",
            "Epoch 165/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22476240536014180.0000 - mean_squared_error: 22476240536014180.0000 - val_loss: 23817598556759912.0000 - val_mean_squared_error: 23817598556759912.0000\n",
            "Epoch 166/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22470609317521060.0000 - mean_squared_error: 22470609317521060.0000 - val_loss: 23811690659386800.0000 - val_mean_squared_error: 23811690659386800.0000\n",
            "Epoch 167/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22464897967817028.0000 - mean_squared_error: 22464897967817028.0000 - val_loss: 23805761214381156.0000 - val_mean_squared_error: 23805761214381156.0000\n",
            "Epoch 168/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22459152920540728.0000 - mean_squared_error: 22459152920540728.0000 - val_loss: 23799797361106436.0000 - val_mean_squared_error: 23799797361106436.0000\n",
            "Epoch 169/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22453389981111064.0000 - mean_squared_error: 22453389981111064.0000 - val_loss: 23793818439048152.0000 - val_mean_squared_error: 23793818439048152.0000\n",
            "Epoch 170/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22447613364002668.0000 - mean_squared_error: 22447613364002668.0000 - val_loss: 23787772738741288.0000 - val_mean_squared_error: 23787772738741288.0000\n",
            "Epoch 171/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22441779805165544.0000 - mean_squared_error: 22441779805165544.0000 - val_loss: 23781686127051028.0000 - val_mean_squared_error: 23781686127051028.0000\n",
            "Epoch 172/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22435879482975404.0000 - mean_squared_error: 22435879482975404.0000 - val_loss: 23775588741544504.0000 - val_mean_squared_error: 23775588741544504.0000\n",
            "Epoch 173/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22430007065922848.0000 - mean_squared_error: 22430007065922848.0000 - val_loss: 23769450481052608.0000 - val_mean_squared_error: 23769450481052608.0000\n",
            "Epoch 174/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22424057737366120.0000 - mean_squared_error: 22424057737366120.0000 - val_loss: 23763260523228376.0000 - val_mean_squared_error: 23763260523228376.0000\n",
            "Epoch 175/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22418088230967988.0000 - mean_squared_error: 22418088230967988.0000 - val_loss: 23757046894553308.0000 - val_mean_squared_error: 23757046894553308.0000\n",
            "Epoch 176/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22412090682746604.0000 - mean_squared_error: 22412090682746604.0000 - val_loss: 23750809558629380.0000 - val_mean_squared_error: 23750809558629380.0000\n",
            "Epoch 177/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22406031167320264.0000 - mean_squared_error: 22406031167320264.0000 - val_loss: 23744522721387468.0000 - val_mean_squared_error: 23744522721387468.0000\n",
            "Epoch 178/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22399996045728692.0000 - mean_squared_error: 22399996045728692.0000 - val_loss: 23738210053678400.0000 - val_mean_squared_error: 23738210053678400.0000\n",
            "Epoch 179/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22393882073215248.0000 - mean_squared_error: 22393882073215248.0000 - val_loss: 23731899594116356.0000 - val_mean_squared_error: 23731899594116356.0000\n",
            "Epoch 180/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22387781019015744.0000 - mean_squared_error: 22387781019015744.0000 - val_loss: 23725500784407848.0000 - val_mean_squared_error: 23725500784407848.0000\n",
            "Epoch 181/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22381608011964196.0000 - mean_squared_error: 22381608011964196.0000 - val_loss: 23719069701781236.0000 - val_mean_squared_error: 23719069701781236.0000\n",
            "Epoch 182/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22375417688357800.0000 - mean_squared_error: 22375417688357800.0000 - val_loss: 23712614936171120.0000 - val_mean_squared_error: 23712614936171120.0000\n",
            "Epoch 183/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22369167226096884.0000 - mean_squared_error: 22369167226096884.0000 - val_loss: 23706106350010368.0000 - val_mean_squared_error: 23706106350010368.0000\n",
            "Epoch 184/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22362966207596672.0000 - mean_squared_error: 22362966207596672.0000 - val_loss: 23699712029391972.0000 - val_mean_squared_error: 23699712029391972.0000\n",
            "Epoch 185/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22356694322136084.0000 - mean_squared_error: 22356694322136084.0000 - val_loss: 23693216400929160.0000 - val_mean_squared_error: 23693216400929160.0000\n",
            "Epoch 186/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22350410532872920.0000 - mean_squared_error: 22350410532872920.0000 - val_loss: 23686602309018108.0000 - val_mean_squared_error: 23686602309018108.0000\n",
            "Epoch 187/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22344044619825616.0000 - mean_squared_error: 22344044619825616.0000 - val_loss: 23679979615039788.0000 - val_mean_squared_error: 23679979615039788.0000\n",
            "Epoch 188/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22337659540410816.0000 - mean_squared_error: 22337659540410816.0000 - val_loss: 23673309542961776.0000 - val_mean_squared_error: 23673309542961776.0000\n",
            "Epoch 189/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22331207327072976.0000 - mean_squared_error: 22331207327072976.0000 - val_loss: 23666605050482016.0000 - val_mean_squared_error: 23666605050482016.0000\n",
            "Epoch 190/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22324744968621436.0000 - mean_squared_error: 22324744968621436.0000 - val_loss: 23659885464953340.0000 - val_mean_squared_error: 23659885464953340.0000\n",
            "Epoch 191/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22318226532598316.0000 - mean_squared_error: 22318226532598316.0000 - val_loss: 23653109874992352.0000 - val_mean_squared_error: 23653109874992352.0000\n",
            "Epoch 192/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22311718208276844.0000 - mean_squared_error: 22311718208276844.0000 - val_loss: 23646314921280508.0000 - val_mean_squared_error: 23646314921280508.0000\n",
            "Epoch 193/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22305127830032784.0000 - mean_squared_error: 22305127830032784.0000 - val_loss: 23639487694650560.0000 - val_mean_squared_error: 23639487694650560.0000\n",
            "Epoch 194/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22298527347680728.0000 - mean_squared_error: 22298527347680728.0000 - val_loss: 23632649706337020.0000 - val_mean_squared_error: 23632649706337020.0000\n",
            "Epoch 195/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22291940913577428.0000 - mean_squared_error: 22291940913577428.0000 - val_loss: 23625723428540392.0000 - val_mean_squared_error: 23625723428540392.0000\n",
            "Epoch 196/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22285258711423296.0000 - mean_squared_error: 22285258711423296.0000 - val_loss: 23618838098525188.0000 - val_mean_squared_error: 23618838098525188.0000\n",
            "Epoch 197/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22278557505405740.0000 - mean_squared_error: 22278557505405740.0000 - val_loss: 23611877388194140.0000 - val_mean_squared_error: 23611877388194140.0000\n",
            "Epoch 198/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22271864966777984.0000 - mean_squared_error: 22271864966777984.0000 - val_loss: 23604847752130860.0000 - val_mean_squared_error: 23604847752130860.0000\n",
            "Epoch 199/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22265079237383516.0000 - mean_squared_error: 22265079237383516.0000 - val_loss: 23597813857498316.0000 - val_mean_squared_error: 23597813857498316.0000\n",
            "Epoch 200/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22258316941986708.0000 - mean_squared_error: 22258316941986708.0000 - val_loss: 23590739002951668.0000 - val_mean_squared_error: 23590739002951668.0000\n",
            "Epoch 201/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22251473099923004.0000 - mean_squared_error: 22251473099923004.0000 - val_loss: 23583627580519628.0000 - val_mean_squared_error: 23583627580519628.0000\n",
            "Epoch 202/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22244592850873436.0000 - mean_squared_error: 22244592850873436.0000 - val_loss: 23576483848771456.0000 - val_mean_squared_error: 23576483848771456.0000\n",
            "Epoch 203/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22237695118208764.0000 - mean_squared_error: 22237695118208764.0000 - val_loss: 23569327219988724.0000 - val_mean_squared_error: 23569327219988724.0000\n",
            "Epoch 204/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22230811324444316.0000 - mean_squared_error: 22230811324444316.0000 - val_loss: 23562097358373788.0000 - val_mean_squared_error: 23562097358373788.0000\n",
            "Epoch 205/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22223813386000936.0000 - mean_squared_error: 22223813386000936.0000 - val_loss: 23554880442324124.0000 - val_mean_squared_error: 23554880442324124.0000\n",
            "Epoch 206/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22216800384797428.0000 - mean_squared_error: 22216800384797428.0000 - val_loss: 23547598895509528.0000 - val_mean_squared_error: 23547598895509528.0000\n",
            "Epoch 207/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22209785182954736.0000 - mean_squared_error: 22209785182954736.0000 - val_loss: 23540291554625804.0000 - val_mean_squared_error: 23540291554625804.0000\n",
            "Epoch 208/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22202733100282544.0000 - mean_squared_error: 22202733100282544.0000 - val_loss: 23532941191273060.0000 - val_mean_squared_error: 23532941191273060.0000\n",
            "Epoch 209/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22195667547997572.0000 - mean_squared_error: 22195667547997572.0000 - val_loss: 23525558457940812.0000 - val_mean_squared_error: 23525558457940812.0000\n",
            "Epoch 210/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22188523140234544.0000 - mean_squared_error: 22188523140234544.0000 - val_loss: 23518126235423252.0000 - val_mean_squared_error: 23518126235423252.0000\n",
            "Epoch 211/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22181362561038784.0000 - mean_squared_error: 22181362561038784.0000 - val_loss: 23510722015121848.0000 - val_mean_squared_error: 23510722015121848.0000\n",
            "Epoch 212/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22174136816193540.0000 - mean_squared_error: 22174136816193540.0000 - val_loss: 23503218707255736.0000 - val_mean_squared_error: 23503218707255736.0000\n",
            "Epoch 213/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22166952711876348.0000 - mean_squared_error: 22166952711876348.0000 - val_loss: 23495700367004088.0000 - val_mean_squared_error: 23495700367004088.0000\n",
            "Epoch 214/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22159646091642688.0000 - mean_squared_error: 22159646091642688.0000 - val_loss: 23488136808269072.0000 - val_mean_squared_error: 23488136808269072.0000\n",
            "Epoch 215/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22152395971187436.0000 - mean_squared_error: 22152395971187436.0000 - val_loss: 23480562463585112.0000 - val_mean_squared_error: 23480562463585112.0000\n",
            "Epoch 216/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22145075202468860.0000 - mean_squared_error: 22145075202468860.0000 - val_loss: 23472927892297600.0000 - val_mean_squared_error: 23472927892297600.0000\n",
            "Epoch 217/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22137712465176648.0000 - mean_squared_error: 22137712465176648.0000 - val_loss: 23465278191563144.0000 - val_mean_squared_error: 23465278191563144.0000\n",
            "Epoch 218/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22130324937661248.0000 - mean_squared_error: 22130324937661248.0000 - val_loss: 23457606991726860.0000 - val_mean_squared_error: 23457606991726860.0000\n",
            "Epoch 219/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22122923689942680.0000 - mean_squared_error: 22122923689942680.0000 - val_loss: 23449866902556372.0000 - val_mean_squared_error: 23449866902556372.0000\n",
            "Epoch 220/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22115440180235576.0000 - mean_squared_error: 22115440180235576.0000 - val_loss: 23442107401104320.0000 - val_mean_squared_error: 23442107401104320.0000\n",
            "Epoch 221/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22107949234828372.0000 - mean_squared_error: 22107949234828372.0000 - val_loss: 23434313430719816.0000 - val_mean_squared_error: 23434313430719816.0000\n",
            "Epoch 222/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22100463194917760.0000 - mean_squared_error: 22100463194917760.0000 - val_loss: 23426495862280540.0000 - val_mean_squared_error: 23426495862280540.0000\n",
            "Epoch 223/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22092901145628356.0000 - mean_squared_error: 22092901145628356.0000 - val_loss: 23418645960259780.0000 - val_mean_squared_error: 23418645960259780.0000\n",
            "Epoch 224/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22085275857957324.0000 - mean_squared_error: 22085275857957324.0000 - val_loss: 23410759441822924.0000 - val_mean_squared_error: 23410759441822924.0000\n",
            "Epoch 225/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22077665332337960.0000 - mean_squared_error: 22077665332337960.0000 - val_loss: 23402840674733316.0000 - val_mean_squared_error: 23402840674733316.0000\n",
            "Epoch 226/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22070022052277408.0000 - mean_squared_error: 22070022052277408.0000 - val_loss: 23394872345662344.0000 - val_mean_squared_error: 23394872345662344.0000\n",
            "Epoch 227/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22062387517061868.0000 - mean_squared_error: 22062387517061868.0000 - val_loss: 23386869559791592.0000 - val_mean_squared_error: 23386869559791592.0000\n",
            "Epoch 228/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22054647091462748.0000 - mean_squared_error: 22054647091462748.0000 - val_loss: 23378856048635280.0000 - val_mean_squared_error: 23378856048635280.0000\n",
            "Epoch 229/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22046870562623680.0000 - mean_squared_error: 22046870562623680.0000 - val_loss: 23370777894581356.0000 - val_mean_squared_error: 23370777894581356.0000\n",
            "Epoch 230/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22039073564347124.0000 - mean_squared_error: 22039073564347124.0000 - val_loss: 23362723496307000.0000 - val_mean_squared_error: 23362723496307000.0000\n",
            "Epoch 231/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22031305333846568.0000 - mean_squared_error: 22031305333846568.0000 - val_loss: 23354559236651668.0000 - val_mean_squared_error: 23354559236651668.0000\n",
            "Epoch 232/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22023491467040392.0000 - mean_squared_error: 22023491467040392.0000 - val_loss: 23346420819596168.0000 - val_mean_squared_error: 23346420819596168.0000\n",
            "Epoch 233/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22015582407781908.0000 - mean_squared_error: 22015582407781908.0000 - val_loss: 23338282475336720.0000 - val_mean_squared_error: 23338282475336720.0000\n",
            "Epoch 234/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 22007727075101588.0000 - mean_squared_error: 22007727075101588.0000 - val_loss: 23330077340696020.0000 - val_mean_squared_error: 23330077340696020.0000\n",
            "Epoch 235/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21999795728486292.0000 - mean_squared_error: 21999795728486292.0000 - val_loss: 23321783880174204.0000 - val_mean_squared_error: 23321783880174204.0000\n",
            "Epoch 236/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21991810099437788.0000 - mean_squared_error: 21991810099437788.0000 - val_loss: 23313473251915880.0000 - val_mean_squared_error: 23313473251915880.0000\n",
            "Epoch 237/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21983802801155420.0000 - mean_squared_error: 21983802801155420.0000 - val_loss: 23305166930757528.0000 - val_mean_squared_error: 23305166930757528.0000\n",
            "Epoch 238/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21975767248427656.0000 - mean_squared_error: 21975767248427656.0000 - val_loss: 23296802433417864.0000 - val_mean_squared_error: 23296802433417864.0000\n",
            "Epoch 239/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21967717998277668.0000 - mean_squared_error: 21967717998277668.0000 - val_loss: 23288450930174172.0000 - val_mean_squared_error: 23288450930174172.0000\n",
            "Epoch 240/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21959609323276072.0000 - mean_squared_error: 21959609323276072.0000 - val_loss: 23280011052518660.0000 - val_mean_squared_error: 23280011052518660.0000\n",
            "Epoch 241/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21951499462146660.0000 - mean_squared_error: 21951499462146660.0000 - val_loss: 23271536802992104.0000 - val_mean_squared_error: 23271536802992104.0000\n",
            "Epoch 242/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21943284204220784.0000 - mean_squared_error: 21943284204220784.0000 - val_loss: 23263032391633068.0000 - val_mean_squared_error: 23263032391633068.0000\n",
            "Epoch 243/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21935114210511764.0000 - mean_squared_error: 21935114210511764.0000 - val_loss: 23254489240639640.0000 - val_mean_squared_error: 23254489240639640.0000\n",
            "Epoch 244/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21926868473201636.0000 - mean_squared_error: 21926868473201636.0000 - val_loss: 23245954703846152.0000 - val_mean_squared_error: 23245954703846152.0000\n",
            "Epoch 245/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21918577274239796.0000 - mean_squared_error: 21918577274239796.0000 - val_loss: 23237325398720604.0000 - val_mean_squared_error: 23237325398720604.0000\n",
            "Epoch 246/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21910259459541792.0000 - mean_squared_error: 21910259459541792.0000 - val_loss: 23228702572444028.0000 - val_mean_squared_error: 23228702572444028.0000\n",
            "Epoch 247/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21901974583051260.0000 - mean_squared_error: 21901974583051260.0000 - val_loss: 23220038846916736.0000 - val_mean_squared_error: 23220038846916736.0000\n",
            "Epoch 248/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21893591705977388.0000 - mean_squared_error: 21893591705977388.0000 - val_loss: 23211325583673424.0000 - val_mean_squared_error: 23211325583673424.0000\n",
            "Epoch 249/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21885207446859584.0000 - mean_squared_error: 21885207446859584.0000 - val_loss: 23202592980944608.0000 - val_mean_squared_error: 23202592980944608.0000\n",
            "Epoch 250/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21876784885381384.0000 - mean_squared_error: 21876784885381384.0000 - val_loss: 23193942310176664.0000 - val_mean_squared_error: 23193942310176664.0000\n",
            "Epoch 251/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21868414896246860.0000 - mean_squared_error: 21868414896246860.0000 - val_loss: 23185117086599436.0000 - val_mean_squared_error: 23185117086599436.0000\n",
            "Epoch 252/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21859893781367748.0000 - mean_squared_error: 21859893781367748.0000 - val_loss: 23176276782105964.0000 - val_mean_squared_error: 23176276782105964.0000\n",
            "Epoch 253/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21851353828166736.0000 - mean_squared_error: 21851353828166736.0000 - val_loss: 23167423616975960.0000 - val_mean_squared_error: 23167423616975960.0000\n",
            "Epoch 254/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21842832616088932.0000 - mean_squared_error: 21842832616088932.0000 - val_loss: 23158499342232048.0000 - val_mean_squared_error: 23158499342232048.0000\n",
            "Epoch 255/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21834226188093524.0000 - mean_squared_error: 21834226188093524.0000 - val_loss: 23149605289984000.0000 - val_mean_squared_error: 23149605289984000.0000\n",
            "Epoch 256/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21825582119903824.0000 - mean_squared_error: 21825582119903824.0000 - val_loss: 23140640176652752.0000 - val_mean_squared_error: 23140640176652752.0000\n",
            "Epoch 257/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21816963217063516.0000 - mean_squared_error: 21816963217063516.0000 - val_loss: 23131636263023724.0000 - val_mean_squared_error: 23131636263023724.0000\n",
            "Epoch 258/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21808261400699680.0000 - mean_squared_error: 21808261400699680.0000 - val_loss: 23122623771592784.0000 - val_mean_squared_error: 23122623771592784.0000\n",
            "Epoch 259/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21799571281591184.0000 - mean_squared_error: 21799571281591184.0000 - val_loss: 23113520806797080.0000 - val_mean_squared_error: 23113520806797080.0000\n",
            "Epoch 260/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21790797368095988.0000 - mean_squared_error: 21790797368095988.0000 - val_loss: 23104473931362420.0000 - val_mean_squared_error: 23104473931362420.0000\n",
            "Epoch 261/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21782072640177472.0000 - mean_squared_error: 21782072640177472.0000 - val_loss: 23095336521899616.0000 - val_mean_squared_error: 23095336521899616.0000\n",
            "Epoch 262/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21773239473447108.0000 - mean_squared_error: 21773239473447108.0000 - val_loss: 23086179748685952.0000 - val_mean_squared_error: 23086179748685952.0000\n",
            "Epoch 263/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21764379346228968.0000 - mean_squared_error: 21764379346228968.0000 - val_loss: 23076984247970568.0000 - val_mean_squared_error: 23076984247970568.0000\n",
            "Epoch 264/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21755544206668860.0000 - mean_squared_error: 21755544206668860.0000 - val_loss: 23067737037790168.0000 - val_mean_squared_error: 23067737037790168.0000\n",
            "Epoch 265/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21746620792469744.0000 - mean_squared_error: 21746620792469744.0000 - val_loss: 23058474758826204.0000 - val_mean_squared_error: 23058474758826204.0000\n",
            "Epoch 266/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21737646877474120.0000 - mean_squared_error: 21737646877474120.0000 - val_loss: 23049167322042252.0000 - val_mean_squared_error: 23049167322042252.0000\n",
            "Epoch 267/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21728696065393104.0000 - mean_squared_error: 21728696065393104.0000 - val_loss: 23039842656858412.0000 - val_mean_squared_error: 23039842656858412.0000\n",
            "Epoch 268/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21719665346873152.0000 - mean_squared_error: 21719665346873152.0000 - val_loss: 23030472724660500.0000 - val_mean_squared_error: 23030472724660500.0000\n",
            "Epoch 269/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21710682255713312.0000 - mean_squared_error: 21710682255713312.0000 - val_loss: 23021087760077056.0000 - val_mean_squared_error: 23021087760077056.0000\n",
            "Epoch 270/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21701663049163688.0000 - mean_squared_error: 21701663049163688.0000 - val_loss: 23011661871977536.0000 - val_mean_squared_error: 23011661871977536.0000\n",
            "Epoch 271/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21692528294628988.0000 - mean_squared_error: 21692528294628988.0000 - val_loss: 23002203710959916.0000 - val_mean_squared_error: 23002203710959916.0000\n",
            "Epoch 272/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21683380384858532.0000 - mean_squared_error: 21683380384858532.0000 - val_loss: 22992706761777200.0000 - val_mean_squared_error: 22992706761777200.0000\n",
            "Epoch 273/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21674184796091148.0000 - mean_squared_error: 21674184796091148.0000 - val_loss: 22983145218227576.0000 - val_mean_squared_error: 22983145218227576.0000\n",
            "Epoch 274/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21665064226490868.0000 - mean_squared_error: 21665064226490868.0000 - val_loss: 22973622523506432.0000 - val_mean_squared_error: 22973622523506432.0000\n",
            "Epoch 275/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21655836118685392.0000 - mean_squared_error: 21655836118685392.0000 - val_loss: 22964026571687740.0000 - val_mean_squared_error: 22964026571687740.0000\n",
            "Epoch 276/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21646528730157572.0000 - mean_squared_error: 21646528730157572.0000 - val_loss: 22954422005669100.0000 - val_mean_squared_error: 22954422005669100.0000\n",
            "Epoch 277/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21637273172833388.0000 - mean_squared_error: 21637273172833388.0000 - val_loss: 22944750661401884.0000 - val_mean_squared_error: 22944750661401884.0000\n",
            "Epoch 278/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21627943978386032.0000 - mean_squared_error: 21627943978386032.0000 - val_loss: 22935064284749128.0000 - val_mean_squared_error: 22935064284749128.0000\n",
            "Epoch 279/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21618609444085424.0000 - mean_squared_error: 21618609444085424.0000 - val_loss: 22925326186498684.0000 - val_mean_squared_error: 22925326186498684.0000\n",
            "Epoch 280/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21609169227467184.0000 - mean_squared_error: 21609169227467184.0000 - val_loss: 22915553692111844.0000 - val_mean_squared_error: 22915553692111844.0000\n",
            "Epoch 281/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21599743958185620.0000 - mean_squared_error: 21599743958185620.0000 - val_loss: 22905783369474000.0000 - val_mean_squared_error: 22905783369474000.0000\n",
            "Epoch 282/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21590345816452092.0000 - mean_squared_error: 21590345816452092.0000 - val_loss: 22895972123320088.0000 - val_mean_squared_error: 22895972123320088.0000\n",
            "Epoch 283/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21580941405402796.0000 - mean_squared_error: 21580941405402796.0000 - val_loss: 22886107044482864.0000 - val_mean_squared_error: 22886107044482864.0000\n",
            "Epoch 284/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21571388533979352.0000 - mean_squared_error: 21571388533979352.0000 - val_loss: 22876282889161712.0000 - val_mean_squared_error: 22876282889161712.0000\n",
            "Epoch 285/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21561894964390424.0000 - mean_squared_error: 21561894964390424.0000 - val_loss: 22866361830157528.0000 - val_mean_squared_error: 22866361830157528.0000\n",
            "Epoch 286/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21552290814580916.0000 - mean_squared_error: 21552290814580916.0000 - val_loss: 22856382619237380.0000 - val_mean_squared_error: 22856382619237380.0000\n",
            "Epoch 287/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21542710318984860.0000 - mean_squared_error: 21542710318984860.0000 - val_loss: 22846407763947912.0000 - val_mean_squared_error: 22846407763947912.0000\n",
            "Epoch 288/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21533054284816188.0000 - mean_squared_error: 21533054284816188.0000 - val_loss: 22836385506293400.0000 - val_mean_squared_error: 22836385506293400.0000\n",
            "Epoch 289/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21523354347212364.0000 - mean_squared_error: 21523354347212364.0000 - val_loss: 22826324496871816.0000 - val_mean_squared_error: 22826324496871816.0000\n",
            "Epoch 290/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21513753268274100.0000 - mean_squared_error: 21513753268274100.0000 - val_loss: 22816280740115472.0000 - val_mean_squared_error: 22816280740115472.0000\n",
            "Epoch 291/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21503954099915972.0000 - mean_squared_error: 21503954099915972.0000 - val_loss: 22806168045494224.0000 - val_mean_squared_error: 22806168045494224.0000\n",
            "Epoch 292/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21494228883058032.0000 - mean_squared_error: 21494228883058032.0000 - val_loss: 22796001542455020.0000 - val_mean_squared_error: 22796001542455020.0000\n",
            "Epoch 293/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21484457835497092.0000 - mean_squared_error: 21484457835497092.0000 - val_loss: 22785804926114036.0000 - val_mean_squared_error: 22785804926114036.0000\n",
            "Epoch 294/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21474624342331376.0000 - mean_squared_error: 21474624342331376.0000 - val_loss: 22775655675740068.0000 - val_mean_squared_error: 22775655675740068.0000\n",
            "Epoch 295/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21464794873799084.0000 - mean_squared_error: 21464794873799084.0000 - val_loss: 22765379396248616.0000 - val_mean_squared_error: 22765379396248616.0000\n",
            "Epoch 296/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21454943798300840.0000 - mean_squared_error: 21454943798300840.0000 - val_loss: 22755107399591784.0000 - val_mean_squared_error: 22755107399591784.0000\n",
            "Epoch 297/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21445005609991728.0000 - mean_squared_error: 21445005609991728.0000 - val_loss: 22744841893916604.0000 - val_mean_squared_error: 22744841893916604.0000\n",
            "Epoch 298/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21435005509151928.0000 - mean_squared_error: 21435005509151928.0000 - val_loss: 22734449298460556.0000 - val_mean_squared_error: 22734449298460556.0000\n",
            "Epoch 299/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21425098085748232.0000 - mean_squared_error: 21425098085748232.0000 - val_loss: 22724089072984016.0000 - val_mean_squared_error: 22724089072984016.0000\n",
            "Epoch 300/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21415104684024676.0000 - mean_squared_error: 21415104684024676.0000 - val_loss: 22713694354309676.0000 - val_mean_squared_error: 22713694354309676.0000\n",
            "Epoch 301/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21405067451764996.0000 - mean_squared_error: 21405067451764996.0000 - val_loss: 22703228623082836.0000 - val_mean_squared_error: 22703228623082836.0000\n",
            "Epoch 302/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21394964002894956.0000 - mean_squared_error: 21394964002894956.0000 - val_loss: 22692773629274240.0000 - val_mean_squared_error: 22692773629274240.0000\n",
            "Epoch 303/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21384882830750616.0000 - mean_squared_error: 21384882830750616.0000 - val_loss: 22682282031182216.0000 - val_mean_squared_error: 22682282031182216.0000\n",
            "Epoch 304/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21374700295555620.0000 - mean_squared_error: 21374700295555620.0000 - val_loss: 22671779695671956.0000 - val_mean_squared_error: 22671779695671956.0000\n",
            "Epoch 305/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21364615976603560.0000 - mean_squared_error: 21364615976603560.0000 - val_loss: 22661180468611340.0000 - val_mean_squared_error: 22661180468611340.0000\n",
            "Epoch 306/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21354375307477108.0000 - mean_squared_error: 21354375307477108.0000 - val_loss: 22650579033403692.0000 - val_mean_squared_error: 22650579033403692.0000\n",
            "Epoch 307/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21344226105359272.0000 - mean_squared_error: 21344226105359272.0000 - val_loss: 22639966885043160.0000 - val_mean_squared_error: 22639966885043160.0000\n",
            "Epoch 308/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21333944737317116.0000 - mean_squared_error: 21333944737317116.0000 - val_loss: 22629272926048512.0000 - val_mean_squared_error: 22629272926048512.0000\n",
            "Epoch 309/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21323649448599496.0000 - mean_squared_error: 21323649448599496.0000 - val_loss: 22618594072235452.0000 - val_mean_squared_error: 22618594072235452.0000\n",
            "Epoch 310/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21313381421078108.0000 - mean_squared_error: 21313381421078108.0000 - val_loss: 22607861312943028.0000 - val_mean_squared_error: 22607861312943028.0000\n",
            "Epoch 311/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21303012920481604.0000 - mean_squared_error: 21303012920481604.0000 - val_loss: 22597122171863040.0000 - val_mean_squared_error: 22597122171863040.0000\n",
            "Epoch 312/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21292657429322816.0000 - mean_squared_error: 21292657429322816.0000 - val_loss: 22586311969699852.0000 - val_mean_squared_error: 22586311969699852.0000\n",
            "Epoch 313/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21282215350833600.0000 - mean_squared_error: 21282215350833600.0000 - val_loss: 22575516824187552.0000 - val_mean_squared_error: 22575516824187552.0000\n",
            "Epoch 314/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21271768910552984.0000 - mean_squared_error: 21271768910552984.0000 - val_loss: 22564644138743080.0000 - val_mean_squared_error: 22564644138743080.0000\n",
            "Epoch 315/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21261334125003284.0000 - mean_squared_error: 21261334125003284.0000 - val_loss: 22553784423129228.0000 - val_mean_squared_error: 22553784423129228.0000\n",
            "Epoch 316/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21250842295969980.0000 - mean_squared_error: 21250842295969980.0000 - val_loss: 22542847167583204.0000 - val_mean_squared_error: 22542847167583204.0000\n",
            "Epoch 317/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21240247844859180.0000 - mean_squared_error: 21240247844859180.0000 - val_loss: 22531912108051532.0000 - val_mean_squared_error: 22531912108051532.0000\n",
            "Epoch 318/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21229751840838216.0000 - mean_squared_error: 21229751840838216.0000 - val_loss: 22520882268055124.0000 - val_mean_squared_error: 22520882268055124.0000\n",
            "Epoch 319/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21219100838312200.0000 - mean_squared_error: 21219100838312200.0000 - val_loss: 22509927808374564.0000 - val_mean_squared_error: 22509927808374564.0000\n",
            "Epoch 320/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21208532778165580.0000 - mean_squared_error: 21208532778165580.0000 - val_loss: 22498882948125296.0000 - val_mean_squared_error: 22498882948125296.0000\n",
            "Epoch 321/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21197879034332640.0000 - mean_squared_error: 21197879034332640.0000 - val_loss: 22487803594678224.0000 - val_mean_squared_error: 22487803594678224.0000\n",
            "Epoch 322/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21187216653484496.0000 - mean_squared_error: 21187216653484496.0000 - val_loss: 22476685501596760.0000 - val_mean_squared_error: 22476685501596760.0000\n",
            "Epoch 323/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21176450853225816.0000 - mean_squared_error: 21176450853225816.0000 - val_loss: 22465509268732008.0000 - val_mean_squared_error: 22465509268732008.0000\n",
            "Epoch 324/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21165808537833084.0000 - mean_squared_error: 21165808537833084.0000 - val_loss: 22454533613266516.0000 - val_mean_squared_error: 22454533613266516.0000\n",
            "Epoch 325/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21155115909966316.0000 - mean_squared_error: 21155115909966316.0000 - val_loss: 22443294945651184.0000 - val_mean_squared_error: 22443294945651184.0000\n",
            "Epoch 326/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21144353813889116.0000 - mean_squared_error: 21144353813889116.0000 - val_loss: 22432123056284436.0000 - val_mean_squared_error: 22432123056284436.0000\n",
            "Epoch 327/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21133509284206940.0000 - mean_squared_error: 21133509284206940.0000 - val_loss: 22420856459249004.0000 - val_mean_squared_error: 22420856459249004.0000\n",
            "Epoch 328/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21122646599631172.0000 - mean_squared_error: 21122646599631172.0000 - val_loss: 22409581223748280.0000 - val_mean_squared_error: 22409581223748280.0000\n",
            "Epoch 329/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21111728876294868.0000 - mean_squared_error: 21111728876294868.0000 - val_loss: 22398239197866296.0000 - val_mean_squared_error: 22398239197866296.0000\n",
            "Epoch 330/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21100891805093732.0000 - mean_squared_error: 21100891805093732.0000 - val_loss: 22386877856764160.0000 - val_mean_squared_error: 22386877856764160.0000\n",
            "Epoch 331/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21089868777603468.0000 - mean_squared_error: 21089868777603468.0000 - val_loss: 22375462682978708.0000 - val_mean_squared_error: 22375462682978708.0000\n",
            "Epoch 332/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21078877913768572.0000 - mean_squared_error: 21078877913768572.0000 - val_loss: 22364053951644204.0000 - val_mean_squared_error: 22364053951644204.0000\n",
            "Epoch 333/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21067889698598096.0000 - mean_squared_error: 21067889698598096.0000 - val_loss: 22352602161442656.0000 - val_mean_squared_error: 22352602161442656.0000\n",
            "Epoch 334/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21056830987037256.0000 - mean_squared_error: 21056830987037256.0000 - val_loss: 22341113754825004.0000 - val_mean_squared_error: 22341113754825004.0000\n",
            "Epoch 335/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21045764025737252.0000 - mean_squared_error: 21045764025737252.0000 - val_loss: 22329593063156580.0000 - val_mean_squared_error: 22329593063156580.0000\n",
            "Epoch 336/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21034641872285020.0000 - mean_squared_error: 21034641872285020.0000 - val_loss: 22318055155220944.0000 - val_mean_squared_error: 22318055155220944.0000\n",
            "Epoch 337/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21023538730289860.0000 - mean_squared_error: 21023538730289860.0000 - val_loss: 22306459131767376.0000 - val_mean_squared_error: 22306459131767376.0000\n",
            "Epoch 338/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21012339908330192.0000 - mean_squared_error: 21012339908330192.0000 - val_loss: 22294860960830156.0000 - val_mean_squared_error: 22294860960830156.0000\n",
            "Epoch 339/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 21001121731680552.0000 - mean_squared_error: 21001121731680552.0000 - val_loss: 22283226149211488.0000 - val_mean_squared_error: 22283226149211488.0000\n",
            "Epoch 340/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20989919762913160.0000 - mean_squared_error: 20989919762913160.0000 - val_loss: 22271548327256480.0000 - val_mean_squared_error: 22271548327256480.0000\n",
            "Epoch 341/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20978659891061212.0000 - mean_squared_error: 20978659891061212.0000 - val_loss: 22259846810185288.0000 - val_mean_squared_error: 22259846810185288.0000\n",
            "Epoch 342/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20967435429908508.0000 - mean_squared_error: 20967435429908508.0000 - val_loss: 22248115119148940.0000 - val_mean_squared_error: 22248115119148940.0000\n",
            "Epoch 343/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20956004760207520.0000 - mean_squared_error: 20956004760207520.0000 - val_loss: 22236338209629224.0000 - val_mean_squared_error: 22236338209629224.0000\n",
            "Epoch 344/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20944753148725844.0000 - mean_squared_error: 20944753148725844.0000 - val_loss: 22224552770838296.0000 - val_mean_squared_error: 22224552770838296.0000\n",
            "Epoch 345/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20933366620900548.0000 - mean_squared_error: 20933366620900548.0000 - val_loss: 22212700553798788.0000 - val_mean_squared_error: 22212700553798788.0000\n",
            "Epoch 346/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20921921419994788.0000 - mean_squared_error: 20921921419994788.0000 - val_loss: 22200833219445012.0000 - val_mean_squared_error: 22200833219445012.0000\n",
            "Epoch 347/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20910494787077068.0000 - mean_squared_error: 20910494787077068.0000 - val_loss: 22188942262771112.0000 - val_mean_squared_error: 22188942262771112.0000\n",
            "Epoch 348/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20899067100161008.0000 - mean_squared_error: 20899067100161008.0000 - val_loss: 22177021156397404.0000 - val_mean_squared_error: 22177021156397404.0000\n",
            "Epoch 349/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20887637150337848.0000 - mean_squared_error: 20887637150337848.0000 - val_loss: 22165039738491412.0000 - val_mean_squared_error: 22165039738491412.0000\n",
            "Epoch 350/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20875981842304936.0000 - mean_squared_error: 20875981842304936.0000 - val_loss: 22153077720734308.0000 - val_mean_squared_error: 22153077720734308.0000\n",
            "Epoch 351/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20864431278014764.0000 - mean_squared_error: 20864431278014764.0000 - val_loss: 22141055415710276.0000 - val_mean_squared_error: 22141055415710276.0000\n",
            "Epoch 352/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20852924465286780.0000 - mean_squared_error: 20852924465286780.0000 - val_loss: 22129022336869972.0000 - val_mean_squared_error: 22129022336869972.0000\n",
            "Epoch 353/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20841249723589964.0000 - mean_squared_error: 20841249723589964.0000 - val_loss: 22116916061595496.0000 - val_mean_squared_error: 22116916061595496.0000\n",
            "Epoch 354/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20829609189758556.0000 - mean_squared_error: 20829609189758556.0000 - val_loss: 22104844206722772.0000 - val_mean_squared_error: 22104844206722772.0000\n",
            "Epoch 355/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20817943842923020.0000 - mean_squared_error: 20817943842923020.0000 - val_loss: 22092677692712068.0000 - val_mean_squared_error: 22092677692712068.0000\n",
            "Epoch 356/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20806315571314364.0000 - mean_squared_error: 20806315571314364.0000 - val_loss: 22080496061387100.0000 - val_mean_squared_error: 22080496061387100.0000\n",
            "Epoch 357/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20794524810826292.0000 - mean_squared_error: 20794524810826292.0000 - val_loss: 22068325240276424.0000 - val_mean_squared_error: 22068325240276424.0000\n",
            "Epoch 358/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20782812360592348.0000 - mean_squared_error: 20782812360592348.0000 - val_loss: 22056175894002232.0000 - val_mean_squared_error: 22056175894002232.0000\n",
            "Epoch 359/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20771030832461484.0000 - mean_squared_error: 20771030832461484.0000 - val_loss: 22043847881941592.0000 - val_mean_squared_error: 22043847881941592.0000\n",
            "Epoch 360/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20759235093577796.0000 - mean_squared_error: 20759235093577796.0000 - val_loss: 22031597373415100.0000 - val_mean_squared_error: 22031597373415100.0000\n",
            "Epoch 361/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20747361360335732.0000 - mean_squared_error: 20747361360335732.0000 - val_loss: 22019297351437944.0000 - val_mean_squared_error: 22019297351437944.0000\n",
            "Epoch 362/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20735453060808080.0000 - mean_squared_error: 20735453060808080.0000 - val_loss: 22006900462175780.0000 - val_mean_squared_error: 22006900462175780.0000\n",
            "Epoch 363/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20723573797871560.0000 - mean_squared_error: 20723573797871560.0000 - val_loss: 21994537981182692.0000 - val_mean_squared_error: 21994537981182692.0000\n",
            "Epoch 364/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20711643037851912.0000 - mean_squared_error: 20711643037851912.0000 - val_loss: 21982102315888108.0000 - val_mean_squared_error: 21982102315888108.0000\n",
            "Epoch 365/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20699723317477700.0000 - mean_squared_error: 20699723317477700.0000 - val_loss: 21969714028693216.0000 - val_mean_squared_error: 21969714028693216.0000\n",
            "Epoch 366/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20687702288727092.0000 - mean_squared_error: 20687702288727092.0000 - val_loss: 21957241759115208.0000 - val_mean_squared_error: 21957241759115208.0000\n",
            "Epoch 367/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20675652774684188.0000 - mean_squared_error: 20675652774684188.0000 - val_loss: 21944752285402660.0000 - val_mean_squared_error: 21944752285402660.0000\n",
            "Epoch 368/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20663661297374048.0000 - mean_squared_error: 20663661297374048.0000 - val_loss: 21932228403421044.0000 - val_mean_squared_error: 21932228403421044.0000\n",
            "Epoch 369/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20651566263967708.0000 - mean_squared_error: 20651566263967708.0000 - val_loss: 21919661414041680.0000 - val_mean_squared_error: 21919661414041680.0000\n",
            "Epoch 370/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20639420070636220.0000 - mean_squared_error: 20639420070636220.0000 - val_loss: 21907038444495356.0000 - val_mean_squared_error: 21907038444495356.0000\n",
            "Epoch 371/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20627311716452596.0000 - mean_squared_error: 20627311716452596.0000 - val_loss: 21894419782049004.0000 - val_mean_squared_error: 21894419782049004.0000\n",
            "Epoch 372/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20615183512473164.0000 - mean_squared_error: 20615183512473164.0000 - val_loss: 21881732230268452.0000 - val_mean_squared_error: 21881732230268452.0000\n",
            "Epoch 373/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20602927597003320.0000 - mean_squared_error: 20602927597003320.0000 - val_loss: 21869141630701636.0000 - val_mean_squared_error: 21869141630701636.0000\n",
            "Epoch 374/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20590815192367868.0000 - mean_squared_error: 20590815192367868.0000 - val_loss: 21856398086621452.0000 - val_mean_squared_error: 21856398086621452.0000\n",
            "Epoch 375/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20578572391128080.0000 - mean_squared_error: 20578572391128080.0000 - val_loss: 21843648124355672.0000 - val_mean_squared_error: 21843648124355672.0000\n",
            "Epoch 376/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20566255712805848.0000 - mean_squared_error: 20566255712805848.0000 - val_loss: 21830848624373876.0000 - val_mean_squared_error: 21830848624373876.0000\n",
            "Epoch 377/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20553915524549480.0000 - mean_squared_error: 20553915524549480.0000 - val_loss: 21818059873942996.0000 - val_mean_squared_error: 21818059873942996.0000\n",
            "Epoch 378/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20541550085894856.0000 - mean_squared_error: 20541550085894856.0000 - val_loss: 21805200098826944.0000 - val_mean_squared_error: 21805200098826944.0000\n",
            "Epoch 379/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20529110138366276.0000 - mean_squared_error: 20529110138366276.0000 - val_loss: 21792325254927332.0000 - val_mean_squared_error: 21792325254927332.0000\n",
            "Epoch 380/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20516784075813876.0000 - mean_squared_error: 20516784075813876.0000 - val_loss: 21779461160578632.0000 - val_mean_squared_error: 21779461160578632.0000\n",
            "Epoch 381/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20504335886139788.0000 - mean_squared_error: 20504335886139788.0000 - val_loss: 21766506677793900.0000 - val_mean_squared_error: 21766506677793900.0000\n",
            "Epoch 382/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20491863304149660.0000 - mean_squared_error: 20491863304149660.0000 - val_loss: 21753526340276664.0000 - val_mean_squared_error: 21753526340276664.0000\n",
            "Epoch 383/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20479376667835860.0000 - mean_squared_error: 20479376667835860.0000 - val_loss: 21740580459559200.0000 - val_mean_squared_error: 21740580459559200.0000\n",
            "Epoch 384/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20466911193500244.0000 - mean_squared_error: 20466911193500244.0000 - val_loss: 21727542006524032.0000 - val_mean_squared_error: 21727542006524032.0000\n",
            "Epoch 385/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20454399716845176.0000 - mean_squared_error: 20454399716845176.0000 - val_loss: 21714505664574480.0000 - val_mean_squared_error: 21714505664574480.0000\n",
            "Epoch 386/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20441719527556812.0000 - mean_squared_error: 20441719527556812.0000 - val_loss: 21701421980923268.0000 - val_mean_squared_error: 21701421980923268.0000\n",
            "Epoch 387/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20429189320409644.0000 - mean_squared_error: 20429189320409644.0000 - val_loss: 21688325436635516.0000 - val_mean_squared_error: 21688325436635516.0000\n",
            "Epoch 388/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20416507978405512.0000 - mean_squared_error: 20416507978405512.0000 - val_loss: 21675151279619540.0000 - val_mean_squared_error: 21675151279619540.0000\n",
            "Epoch 389/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20403800111789000.0000 - mean_squared_error: 20403800111789000.0000 - val_loss: 21661998791562860.0000 - val_mean_squared_error: 21661998791562860.0000\n",
            "Epoch 390/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20391225963238448.0000 - mean_squared_error: 20391225963238448.0000 - val_loss: 21648841911477472.0000 - val_mean_squared_error: 21648841911477472.0000\n",
            "Epoch 391/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20378493481052652.0000 - mean_squared_error: 20378493481052652.0000 - val_loss: 21635590323723408.0000 - val_mean_squared_error: 21635590323723408.0000\n",
            "Epoch 392/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20365761497010160.0000 - mean_squared_error: 20365761497010160.0000 - val_loss: 21622379623087388.0000 - val_mean_squared_error: 21622379623087388.0000\n",
            "Epoch 393/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20353027000988916.0000 - mean_squared_error: 20353027000988916.0000 - val_loss: 21609044065082884.0000 - val_mean_squared_error: 21609044065082884.0000\n",
            "Epoch 394/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20340166394218256.0000 - mean_squared_error: 20340166394218256.0000 - val_loss: 21595792525859520.0000 - val_mean_squared_error: 21595792525859520.0000\n",
            "Epoch 395/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20327379149680704.0000 - mean_squared_error: 20327379149680704.0000 - val_loss: 21582444010157072.0000 - val_mean_squared_error: 21582444010157072.0000\n",
            "Epoch 396/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20314534380222264.0000 - mean_squared_error: 20314534380222264.0000 - val_loss: 21569061061920200.0000 - val_mean_squared_error: 21569061061920200.0000\n",
            "Epoch 397/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20301608317724768.0000 - mean_squared_error: 20301608317724768.0000 - val_loss: 21555620046696100.0000 - val_mean_squared_error: 21555620046696100.0000\n",
            "Epoch 398/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20288673829315476.0000 - mean_squared_error: 20288673829315476.0000 - val_loss: 21542219918590044.0000 - val_mean_squared_error: 21542219918590044.0000\n",
            "Epoch 399/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20275773649007744.0000 - mean_squared_error: 20275773649007744.0000 - val_loss: 21528733648484548.0000 - val_mean_squared_error: 21528733648484548.0000\n",
            "Epoch 400/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20262803962521348.0000 - mean_squared_error: 20262803962521348.0000 - val_loss: 21515324954709252.0000 - val_mean_squared_error: 21515324954709252.0000\n",
            "Epoch 401/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20249885501265476.0000 - mean_squared_error: 20249885501265476.0000 - val_loss: 21501778397336824.0000 - val_mean_squared_error: 21501778397336824.0000\n",
            "Epoch 402/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20236879785956884.0000 - mean_squared_error: 20236879785956884.0000 - val_loss: 21488218967195184.0000 - val_mean_squared_error: 21488218967195184.0000\n",
            "Epoch 403/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20223804763423208.0000 - mean_squared_error: 20223804763423208.0000 - val_loss: 21474618577139444.0000 - val_mean_squared_error: 21474618577139444.0000\n",
            "Epoch 404/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20210752532464564.0000 - mean_squared_error: 20210752532464564.0000 - val_loss: 21461057023779512.0000 - val_mean_squared_error: 21461057023779512.0000\n",
            "Epoch 405/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20197574997201924.0000 - mean_squared_error: 20197574997201924.0000 - val_loss: 21447398518205840.0000 - val_mean_squared_error: 21447398518205840.0000\n",
            "Epoch 406/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20184462018578192.0000 - mean_squared_error: 20184462018578192.0000 - val_loss: 21433705580097744.0000 - val_mean_squared_error: 21433705580097744.0000\n",
            "Epoch 407/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20171254204403604.0000 - mean_squared_error: 20171254204403604.0000 - val_loss: 21420034213887536.0000 - val_mean_squared_error: 21420034213887536.0000\n",
            "Epoch 408/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20158053465990200.0000 - mean_squared_error: 20158053465990200.0000 - val_loss: 21406336980812148.0000 - val_mean_squared_error: 21406336980812148.0000\n",
            "Epoch 409/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20144850440370024.0000 - mean_squared_error: 20144850440370024.0000 - val_loss: 21392545027935400.0000 - val_mean_squared_error: 21392545027935400.0000\n",
            "Epoch 410/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20131597228330364.0000 - mean_squared_error: 20131597228330364.0000 - val_loss: 21378763812476892.0000 - val_mean_squared_error: 21378763812476892.0000\n",
            "Epoch 411/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20118397733756500.0000 - mean_squared_error: 20118397733756500.0000 - val_loss: 21364935267449400.0000 - val_mean_squared_error: 21364935267449400.0000\n",
            "Epoch 412/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20105017133715832.0000 - mean_squared_error: 20105017133715832.0000 - val_loss: 21351123938689116.0000 - val_mean_squared_error: 21351123938689116.0000\n",
            "Epoch 413/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20091656186036132.0000 - mean_squared_error: 20091656186036132.0000 - val_loss: 21337263084345496.0000 - val_mean_squared_error: 21337263084345496.0000\n",
            "Epoch 414/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20078365639066828.0000 - mean_squared_error: 20078365639066828.0000 - val_loss: 21323365625718448.0000 - val_mean_squared_error: 21323365625718448.0000\n",
            "Epoch 415/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20064948308550896.0000 - mean_squared_error: 20064948308550896.0000 - val_loss: 21309422948608036.0000 - val_mean_squared_error: 21309422948608036.0000\n",
            "Epoch 416/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20051544392973480.0000 - mean_squared_error: 20051544392973480.0000 - val_loss: 21295510481860804.0000 - val_mean_squared_error: 21295510481860804.0000\n",
            "Epoch 417/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20038113533614308.0000 - mean_squared_error: 20038113533614308.0000 - val_loss: 21281516155948756.0000 - val_mean_squared_error: 21281516155948756.0000\n",
            "Epoch 418/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20024629634142748.0000 - mean_squared_error: 20024629634142748.0000 - val_loss: 21267478771169660.0000 - val_mean_squared_error: 21267478771169660.0000\n",
            "Epoch 419/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 20011177936294796.0000 - mean_squared_error: 20011177936294796.0000 - val_loss: 21253430624706976.0000 - val_mean_squared_error: 21253430624706976.0000\n",
            "Epoch 420/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19997648806018424.0000 - mean_squared_error: 19997648806018424.0000 - val_loss: 21239386761078912.0000 - val_mean_squared_error: 21239386761078912.0000\n",
            "Epoch 421/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19984068122465928.0000 - mean_squared_error: 19984068122465928.0000 - val_loss: 21225286977947268.0000 - val_mean_squared_error: 21225286977947268.0000\n",
            "Epoch 422/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19970464325367724.0000 - mean_squared_error: 19970464325367724.0000 - val_loss: 21211107531665152.0000 - val_mean_squared_error: 21211107531665152.0000\n",
            "Epoch 423/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19956862662084600.0000 - mean_squared_error: 19956862662084600.0000 - val_loss: 21196990495868268.0000 - val_mean_squared_error: 21196990495868268.0000\n",
            "Epoch 424/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19943182642985456.0000 - mean_squared_error: 19943182642985456.0000 - val_loss: 21182804570737184.0000 - val_mean_squared_error: 21182804570737184.0000\n",
            "Epoch 425/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19929585112165560.0000 - mean_squared_error: 19929585112165560.0000 - val_loss: 21168569095757408.0000 - val_mean_squared_error: 21168569095757408.0000\n",
            "Epoch 426/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19915891120754136.0000 - mean_squared_error: 19915891120754136.0000 - val_loss: 21154385366640676.0000 - val_mean_squared_error: 21154385366640676.0000\n",
            "Epoch 427/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19902175824603948.0000 - mean_squared_error: 19902175824603948.0000 - val_loss: 21140074608406460.0000 - val_mean_squared_error: 21140074608406460.0000\n",
            "Epoch 428/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19888404302046680.0000 - mean_squared_error: 19888404302046680.0000 - val_loss: 21125800405924964.0000 - val_mean_squared_error: 21125800405924964.0000\n",
            "Epoch 429/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19874626511692368.0000 - mean_squared_error: 19874626511692368.0000 - val_loss: 21111552106706676.0000 - val_mean_squared_error: 21111552106706676.0000\n",
            "Epoch 430/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19860851936488608.0000 - mean_squared_error: 19860851936488608.0000 - val_loss: 21097161685321996.0000 - val_mean_squared_error: 21097161685321996.0000\n",
            "Epoch 431/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19847083990539536.0000 - mean_squared_error: 19847083990539536.0000 - val_loss: 21082754011272072.0000 - val_mean_squared_error: 21082754011272072.0000\n",
            "Epoch 432/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19833233706665440.0000 - mean_squared_error: 19833233706665440.0000 - val_loss: 21068372167689304.0000 - val_mean_squared_error: 21068372167689304.0000\n",
            "Epoch 433/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19819424467977396.0000 - mean_squared_error: 19819424467977396.0000 - val_loss: 21053908525605096.0000 - val_mean_squared_error: 21053908525605096.0000\n",
            "Epoch 434/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19805458775841344.0000 - mean_squared_error: 19805458775841344.0000 - val_loss: 21039492322283960.0000 - val_mean_squared_error: 21039492322283960.0000\n",
            "Epoch 435/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19791523309461700.0000 - mean_squared_error: 19791523309461700.0000 - val_loss: 21024933911867692.0000 - val_mean_squared_error: 21024933911867692.0000\n",
            "Epoch 436/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19777545821352880.0000 - mean_squared_error: 19777545821352880.0000 - val_loss: 21010446647463356.0000 - val_mean_squared_error: 21010446647463356.0000\n",
            "Epoch 437/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19763564176481156.0000 - mean_squared_error: 19763564176481156.0000 - val_loss: 20995935639412136.0000 - val_mean_squared_error: 20995935639412136.0000\n",
            "Epoch 438/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19749581404712076.0000 - mean_squared_error: 19749581404712076.0000 - val_loss: 20981334267190232.0000 - val_mean_squared_error: 20981334267190232.0000\n",
            "Epoch 439/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19735541108022100.0000 - mean_squared_error: 19735541108022100.0000 - val_loss: 20966709151321440.0000 - val_mean_squared_error: 20966709151321440.0000\n",
            "Epoch 440/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19721539156216960.0000 - mean_squared_error: 19721539156216960.0000 - val_loss: 20952124958968724.0000 - val_mean_squared_error: 20952124958968724.0000\n",
            "Epoch 441/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19707404657286368.0000 - mean_squared_error: 19707404657286368.0000 - val_loss: 20937454709545296.0000 - val_mean_squared_error: 20937454709545296.0000\n",
            "Epoch 442/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19693317205561188.0000 - mean_squared_error: 19693317205561188.0000 - val_loss: 20922724112191556.0000 - val_mean_squared_error: 20922724112191556.0000\n",
            "Epoch 443/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19679075525326856.0000 - mean_squared_error: 19679075525326856.0000 - val_loss: 20907995662321468.0000 - val_mean_squared_error: 20907995662321468.0000\n",
            "Epoch 444/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19664907697875296.0000 - mean_squared_error: 19664907697875296.0000 - val_loss: 20893258634649460.0000 - val_mean_squared_error: 20893258634649460.0000\n",
            "Epoch 445/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19650715294341416.0000 - mean_squared_error: 19650715294341416.0000 - val_loss: 20878472093526792.0000 - val_mean_squared_error: 20878472093526792.0000\n",
            "Epoch 446/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19636494581687880.0000 - mean_squared_error: 19636494581687880.0000 - val_loss: 20863704928287656.0000 - val_mean_squared_error: 20863704928287656.0000\n",
            "Epoch 447/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19622225300061884.0000 - mean_squared_error: 19622225300061884.0000 - val_loss: 20848892556697832.0000 - val_mean_squared_error: 20848892556697832.0000\n",
            "Epoch 448/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19607991488365588.0000 - mean_squared_error: 19607991488365588.0000 - val_loss: 20834041433340932.0000 - val_mean_squared_error: 20834041433340932.0000\n",
            "Epoch 449/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19593785682043028.0000 - mean_squared_error: 19593785682043028.0000 - val_loss: 20819114929668188.0000 - val_mean_squared_error: 20819114929668188.0000\n",
            "Epoch 450/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19579377224036904.0000 - mean_squared_error: 19579377224036904.0000 - val_loss: 20804207886807712.0000 - val_mean_squared_error: 20804207886807712.0000\n",
            "Epoch 451/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19564954410998636.0000 - mean_squared_error: 19564954410998636.0000 - val_loss: 20789253356653460.0000 - val_mean_squared_error: 20789253356653460.0000\n",
            "Epoch 452/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19550684491506208.0000 - mean_squared_error: 19550684491506208.0000 - val_loss: 20774408772808912.0000 - val_mean_squared_error: 20774408772808912.0000\n",
            "Epoch 453/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19536329969662932.0000 - mean_squared_error: 19536329969662932.0000 - val_loss: 20759378983665572.0000 - val_mean_squared_error: 20759378983665572.0000\n",
            "Epoch 454/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19521884922423392.0000 - mean_squared_error: 19521884922423392.0000 - val_loss: 20744323303391696.0000 - val_mean_squared_error: 20744323303391696.0000\n",
            "Epoch 455/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19507377604232976.0000 - mean_squared_error: 19507377604232976.0000 - val_loss: 20729256885699580.0000 - val_mean_squared_error: 20729256885699580.0000\n",
            "Epoch 456/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19492883801217228.0000 - mean_squared_error: 19492883801217228.0000 - val_loss: 20714309016384436.0000 - val_mean_squared_error: 20714309016384436.0000\n",
            "Epoch 457/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19478388233437696.0000 - mean_squared_error: 19478388233437696.0000 - val_loss: 20699141387909316.0000 - val_mean_squared_error: 20699141387909316.0000\n",
            "Epoch 458/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19463845556184836.0000 - mean_squared_error: 19463845556184836.0000 - val_loss: 20684008252632000.0000 - val_mean_squared_error: 20684008252632000.0000\n",
            "Epoch 459/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19449274679160848.0000 - mean_squared_error: 19449274679160848.0000 - val_loss: 20668857901087472.0000 - val_mean_squared_error: 20668857901087472.0000\n",
            "Epoch 460/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19434722427836620.0000 - mean_squared_error: 19434722427836620.0000 - val_loss: 20653670908861492.0000 - val_mean_squared_error: 20653670908861492.0000\n",
            "Epoch 461/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19420108285243920.0000 - mean_squared_error: 19420108285243920.0000 - val_loss: 20638503341049752.0000 - val_mean_squared_error: 20638503341049752.0000\n",
            "Epoch 462/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19405462067082160.0000 - mean_squared_error: 19405462067082160.0000 - val_loss: 20623228120004064.0000 - val_mean_squared_error: 20623228120004064.0000\n",
            "Epoch 463/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19390772928103304.0000 - mean_squared_error: 19390772928103304.0000 - val_loss: 20607993798209096.0000 - val_mean_squared_error: 20607993798209096.0000\n",
            "Epoch 464/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19376063483709756.0000 - mean_squared_error: 19376063483709756.0000 - val_loss: 20592647540345560.0000 - val_mean_squared_error: 20592647540345560.0000\n",
            "Epoch 465/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19361398302690268.0000 - mean_squared_error: 19361398302690268.0000 - val_loss: 20577337874632772.0000 - val_mean_squared_error: 20577337874632772.0000\n",
            "Epoch 466/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19346606930428692.0000 - mean_squared_error: 19346606930428692.0000 - val_loss: 20561972204487676.0000 - val_mean_squared_error: 20561972204487676.0000\n",
            "Epoch 467/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19331768286189728.0000 - mean_squared_error: 19331768286189728.0000 - val_loss: 20546574249291800.0000 - val_mean_squared_error: 20546574249291800.0000\n",
            "Epoch 468/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19316986319420536.0000 - mean_squared_error: 19316986319420536.0000 - val_loss: 20531217254010024.0000 - val_mean_squared_error: 20531217254010024.0000\n",
            "Epoch 469/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19302255385003212.0000 - mean_squared_error: 19302255385003212.0000 - val_loss: 20515771993510512.0000 - val_mean_squared_error: 20515771993510512.0000\n",
            "Epoch 470/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19287395114054808.0000 - mean_squared_error: 19287395114054808.0000 - val_loss: 20500287920580552.0000 - val_mean_squared_error: 20500287920580552.0000\n",
            "Epoch 471/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19272505993319008.0000 - mean_squared_error: 19272505993319008.0000 - val_loss: 20484816841746560.0000 - val_mean_squared_error: 20484816841746560.0000\n",
            "Epoch 472/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19257478886887084.0000 - mean_squared_error: 19257478886887084.0000 - val_loss: 20469287562465904.0000 - val_mean_squared_error: 20469287562465904.0000\n",
            "Epoch 473/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19242620647998876.0000 - mean_squared_error: 19242620647998876.0000 - val_loss: 20453790641032084.0000 - val_mean_squared_error: 20453790641032084.0000\n",
            "Epoch 474/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19227719271115244.0000 - mean_squared_error: 19227719271115244.0000 - val_loss: 20438185993568256.0000 - val_mean_squared_error: 20438185993568256.0000\n",
            "Epoch 475/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19212742458932600.0000 - mean_squared_error: 19212742458932600.0000 - val_loss: 20422598659433048.0000 - val_mean_squared_error: 20422598659433048.0000\n",
            "Epoch 476/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19197721188978508.0000 - mean_squared_error: 19197721188978508.0000 - val_loss: 20407090952050284.0000 - val_mean_squared_error: 20407090952050284.0000\n",
            "Epoch 477/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19182713870074480.0000 - mean_squared_error: 19182713870074480.0000 - val_loss: 20391404518217692.0000 - val_mean_squared_error: 20391404518217692.0000\n",
            "Epoch 478/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19167607917276880.0000 - mean_squared_error: 19167607917276880.0000 - val_loss: 20375718157181160.0000 - val_mean_squared_error: 20375718157181160.0000\n",
            "Epoch 479/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19152624732504852.0000 - mean_squared_error: 19152624732504852.0000 - val_loss: 20360005880748736.0000 - val_mean_squared_error: 20360005880748736.0000\n",
            "Epoch 480/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19137463836626672.0000 - mean_squared_error: 19137463836626672.0000 - val_loss: 20344328133912148.0000 - val_mean_squared_error: 20344328133912148.0000\n",
            "Epoch 481/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19122324546195716.0000 - mean_squared_error: 19122324546195716.0000 - val_loss: 20328538390343612.0000 - val_mean_squared_error: 20328538390343612.0000\n",
            "Epoch 482/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19107131617272908.0000 - mean_squared_error: 19107131617272908.0000 - val_loss: 20312864962739668.0000 - val_mean_squared_error: 20312864962739668.0000\n",
            "Epoch 483/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19092101423263716.0000 - mean_squared_error: 19092101423263716.0000 - val_loss: 20297025717853144.0000 - val_mean_squared_error: 20297025717853144.0000\n",
            "Epoch 484/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19076810674486392.0000 - mean_squared_error: 19076810674486392.0000 - val_loss: 20281199430664564.0000 - val_mean_squared_error: 20281199430664564.0000\n",
            "Epoch 485/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19061667065547832.0000 - mean_squared_error: 19061667065547832.0000 - val_loss: 20265472194642660.0000 - val_mean_squared_error: 20265472194642660.0000\n",
            "Epoch 486/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19046445289115724.0000 - mean_squared_error: 19046445289115724.0000 - val_loss: 20249531763238484.0000 - val_mean_squared_error: 20249531763238484.0000\n",
            "Epoch 487/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19031167558888496.0000 - mean_squared_error: 19031167558888496.0000 - val_loss: 20233587048999688.0000 - val_mean_squared_error: 20233587048999688.0000\n",
            "Epoch 488/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19015816294811708.0000 - mean_squared_error: 19015816294811708.0000 - val_loss: 20217689724993260.0000 - val_mean_squared_error: 20217689724993260.0000\n",
            "Epoch 489/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 19000585159208468.0000 - mean_squared_error: 19000585159208468.0000 - val_loss: 20201734212672840.0000 - val_mean_squared_error: 20201734212672840.0000\n",
            "Epoch 490/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18985144089613244.0000 - mean_squared_error: 18985144089613244.0000 - val_loss: 20185720584834492.0000 - val_mean_squared_error: 20185720584834492.0000\n",
            "Epoch 491/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18969750554735632.0000 - mean_squared_error: 18969750554735632.0000 - val_loss: 20169760826077484.0000 - val_mean_squared_error: 20169760826077484.0000\n",
            "Epoch 492/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18954428992453544.0000 - mean_squared_error: 18954428992453544.0000 - val_loss: 20153732093057544.0000 - val_mean_squared_error: 20153732093057544.0000\n",
            "Epoch 493/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18938960076951184.0000 - mean_squared_error: 18938960076951184.0000 - val_loss: 20137673283133856.0000 - val_mean_squared_error: 20137673283133856.0000\n",
            "Epoch 494/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18923453048929632.0000 - mean_squared_error: 18923453048929632.0000 - val_loss: 20121584408439096.0000 - val_mean_squared_error: 20121584408439096.0000\n",
            "Epoch 495/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18908063116478616.0000 - mean_squared_error: 18908063116478616.0000 - val_loss: 20105433014065024.0000 - val_mean_squared_error: 20105433014065024.0000\n",
            "Epoch 496/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18892524864895308.0000 - mean_squared_error: 18892524864895308.0000 - val_loss: 20089328985657968.0000 - val_mean_squared_error: 20089328985657968.0000\n",
            "Epoch 497/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18876948441562348.0000 - mean_squared_error: 18876948441562348.0000 - val_loss: 20073143170882148.0000 - val_mean_squared_error: 20073143170882148.0000\n",
            "Epoch 498/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18861427104070544.0000 - mean_squared_error: 18861427104070544.0000 - val_loss: 20056918592206580.0000 - val_mean_squared_error: 20056918592206580.0000\n",
            "Epoch 499/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18845838462557988.0000 - mean_squared_error: 18845838462557988.0000 - val_loss: 20040715512632848.0000 - val_mean_squared_error: 20040715512632848.0000\n",
            "Epoch 500/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18830171150852384.0000 - mean_squared_error: 18830171150852384.0000 - val_loss: 20024469434855448.0000 - val_mean_squared_error: 20024469434855448.0000\n",
            "Epoch 501/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18814667333425196.0000 - mean_squared_error: 18814667333425196.0000 - val_loss: 20008197502345540.0000 - val_mean_squared_error: 20008197502345540.0000\n",
            "Epoch 502/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18798936105984568.0000 - mean_squared_error: 18798936105984568.0000 - val_loss: 19991955768066140.0000 - val_mean_squared_error: 19991955768066140.0000\n",
            "Epoch 503/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18783293384029844.0000 - mean_squared_error: 18783293384029844.0000 - val_loss: 19975578293407904.0000 - val_mean_squared_error: 19975578293407904.0000\n",
            "Epoch 504/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18767623897503464.0000 - mean_squared_error: 18767623897503464.0000 - val_loss: 19959291328512464.0000 - val_mean_squared_error: 19959291328512464.0000\n",
            "Epoch 505/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18751940348300392.0000 - mean_squared_error: 18751940348300392.0000 - val_loss: 19943049679161796.0000 - val_mean_squared_error: 19943049679161796.0000\n",
            "Epoch 506/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18736121108201612.0000 - mean_squared_error: 18736121108201612.0000 - val_loss: 19926577508967556.0000 - val_mean_squared_error: 19926577508967556.0000\n",
            "Epoch 507/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18720475061747804.0000 - mean_squared_error: 18720475061747804.0000 - val_loss: 19910124751054884.0000 - val_mean_squared_error: 19910124751054884.0000\n",
            "Epoch 508/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18704598712100684.0000 - mean_squared_error: 18704598712100684.0000 - val_loss: 19893725850090872.0000 - val_mean_squared_error: 19893725850090872.0000\n",
            "Epoch 509/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18688821010015704.0000 - mean_squared_error: 18688821010015704.0000 - val_loss: 19877342030043100.0000 - val_mean_squared_error: 19877342030043100.0000\n",
            "Epoch 510/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18673084037221016.0000 - mean_squared_error: 18673084037221016.0000 - val_loss: 19860822566677904.0000 - val_mean_squared_error: 19860822566677904.0000\n",
            "Epoch 511/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18657097268338652.0000 - mean_squared_error: 18657097268338652.0000 - val_loss: 19844318135698240.0000 - val_mean_squared_error: 19844318135698240.0000\n",
            "Epoch 512/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18641301781930112.0000 - mean_squared_error: 18641301781930112.0000 - val_loss: 19827749134617028.0000 - val_mean_squared_error: 19827749134617028.0000\n",
            "Epoch 513/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18625318657998780.0000 - mean_squared_error: 18625318657998780.0000 - val_loss: 19811139246417768.0000 - val_mean_squared_error: 19811139246417768.0000\n",
            "Epoch 514/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18609411242737780.0000 - mean_squared_error: 18609411242737780.0000 - val_loss: 19794563790752936.0000 - val_mean_squared_error: 19794563790752936.0000\n",
            "Epoch 515/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18593507830847996.0000 - mean_squared_error: 18593507830847996.0000 - val_loss: 19777927987157792.0000 - val_mean_squared_error: 19777927987157792.0000\n",
            "Epoch 516/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18577432400050580.0000 - mean_squared_error: 18577432400050580.0000 - val_loss: 19761272953271220.0000 - val_mean_squared_error: 19761272953271220.0000\n",
            "Epoch 517/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18561493897913492.0000 - mean_squared_error: 18561493897913492.0000 - val_loss: 19744566173521608.0000 - val_mean_squared_error: 19744566173521608.0000\n",
            "Epoch 518/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18545358671694440.0000 - mean_squared_error: 18545358671694440.0000 - val_loss: 19727921852787928.0000 - val_mean_squared_error: 19727921852787928.0000\n",
            "Epoch 519/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18529369040006792.0000 - mean_squared_error: 18529369040006792.0000 - val_loss: 19711187095087508.0000 - val_mean_squared_error: 19711187095087508.0000\n",
            "Epoch 520/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18513245143510524.0000 - mean_squared_error: 18513245143510524.0000 - val_loss: 19694415733103668.0000 - val_mean_squared_error: 19694415733103668.0000\n",
            "Epoch 521/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18497134487298872.0000 - mean_squared_error: 18497134487298872.0000 - val_loss: 19677646567134180.0000 - val_mean_squared_error: 19677646567134180.0000\n",
            "Epoch 522/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18481004183282440.0000 - mean_squared_error: 18481004183282440.0000 - val_loss: 19660881671866636.0000 - val_mean_squared_error: 19660881671866636.0000\n",
            "Epoch 523/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18464845070484312.0000 - mean_squared_error: 18464845070484312.0000 - val_loss: 19644056501464832.0000 - val_mean_squared_error: 19644056501464832.0000\n",
            "Epoch 524/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18448765206515208.0000 - mean_squared_error: 18448765206515208.0000 - val_loss: 19627296010358668.0000 - val_mean_squared_error: 19627296010358668.0000\n",
            "Epoch 525/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18432591881445524.0000 - mean_squared_error: 18432591881445524.0000 - val_loss: 19610371800922864.0000 - val_mean_squared_error: 19610371800922864.0000\n",
            "Epoch 526/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18416331660743312.0000 - mean_squared_error: 18416331660743312.0000 - val_loss: 19593451910719708.0000 - val_mean_squared_error: 19593451910719708.0000\n",
            "Epoch 527/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18400123462604660.0000 - mean_squared_error: 18400123462604660.0000 - val_loss: 19576527749814608.0000 - val_mean_squared_error: 19576527749814608.0000\n",
            "Epoch 528/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18383797526472844.0000 - mean_squared_error: 18383797526472844.0000 - val_loss: 19559603552511480.0000 - val_mean_squared_error: 19559603552511480.0000\n",
            "Epoch 529/2000\n",
            "707/707 [==============================] - 2s 3ms/step - loss: 18367524293295456.0000 - mean_squared_error: 18367524293295456.0000 - val_loss: 19542625546790392.0000 - val_mean_squared_error: 19542625546790392.0000\n",
            "Epoch 530/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18351235224324576.0000 - mean_squared_error: 18351235224324576.0000 - val_loss: 19525690636334376.0000 - val_mean_squared_error: 19525690636334376.0000\n",
            "Epoch 531/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18334875880697852.0000 - mean_squared_error: 18334875880697852.0000 - val_loss: 19508712654878640.0000 - val_mean_squared_error: 19508712654878640.0000\n",
            "Epoch 532/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18318496640194696.0000 - mean_squared_error: 18318496640194696.0000 - val_loss: 19491586108805560.0000 - val_mean_squared_error: 19491586108805560.0000\n",
            "Epoch 533/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18302172559950448.0000 - mean_squared_error: 18302172559950448.0000 - val_loss: 19474549963301188.0000 - val_mean_squared_error: 19474549963301188.0000\n",
            "Epoch 534/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18285807319096708.0000 - mean_squared_error: 18285807319096708.0000 - val_loss: 19457483716627716.0000 - val_mean_squared_error: 19457483716627716.0000\n",
            "Epoch 535/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18269318098271164.0000 - mean_squared_error: 18269318098271164.0000 - val_loss: 19440380889936172.0000 - val_mean_squared_error: 19440380889936172.0000\n",
            "Epoch 536/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18252885530615728.0000 - mean_squared_error: 18252885530615728.0000 - val_loss: 19423256515612092.0000 - val_mean_squared_error: 19423256515612092.0000\n",
            "Epoch 537/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18236414457090124.0000 - mean_squared_error: 18236414457090124.0000 - val_loss: 19406117084637128.0000 - val_mean_squared_error: 19406117084637128.0000\n",
            "Epoch 538/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18219896690223108.0000 - mean_squared_error: 18219896690223108.0000 - val_loss: 19388867840811888.0000 - val_mean_squared_error: 19388867840811888.0000\n",
            "Epoch 539/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18203397160261072.0000 - mean_squared_error: 18203397160261072.0000 - val_loss: 19371726274485948.0000 - val_mean_squared_error: 19371726274485948.0000\n",
            "Epoch 540/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18186910065656968.0000 - mean_squared_error: 18186910065656968.0000 - val_loss: 19354453371942552.0000 - val_mean_squared_error: 19354453371942552.0000\n",
            "Epoch 541/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18170344024451028.0000 - mean_squared_error: 18170344024451028.0000 - val_loss: 19337171843066540.0000 - val_mean_squared_error: 19337171843066540.0000\n",
            "Epoch 542/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18153645574324040.0000 - mean_squared_error: 18153645574324040.0000 - val_loss: 19319903235490440.0000 - val_mean_squared_error: 19319903235490440.0000\n",
            "Epoch 543/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18137057715048732.0000 - mean_squared_error: 18137057715048732.0000 - val_loss: 19302626037979748.0000 - val_mean_squared_error: 19302626037979748.0000\n",
            "Epoch 544/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18120360531542224.0000 - mean_squared_error: 18120360531542224.0000 - val_loss: 19285275656167564.0000 - val_mean_squared_error: 19285275656167564.0000\n",
            "Epoch 545/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18103770910540588.0000 - mean_squared_error: 18103770910540588.0000 - val_loss: 19267972628189716.0000 - val_mean_squared_error: 19267972628189716.0000\n",
            "Epoch 546/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18087127868225428.0000 - mean_squared_error: 18087127868225428.0000 - val_loss: 19250574868277840.0000 - val_mean_squared_error: 19250574868277840.0000\n",
            "Epoch 547/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18070393310302308.0000 - mean_squared_error: 18070393310302308.0000 - val_loss: 19233174973014988.0000 - val_mean_squared_error: 19233174973014988.0000\n",
            "Epoch 548/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18053681575847544.0000 - mean_squared_error: 18053681575847544.0000 - val_loss: 19215742780568684.0000 - val_mean_squared_error: 19215742780568684.0000\n",
            "Epoch 549/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18036880691965528.0000 - mean_squared_error: 18036880691965528.0000 - val_loss: 19198278290938932.0000 - val_mean_squared_error: 19198278290938932.0000\n",
            "Epoch 550/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18020101837256296.0000 - mean_squared_error: 18020101837256296.0000 - val_loss: 19180785799093024.0000 - val_mean_squared_error: 19180785799093024.0000\n",
            "Epoch 551/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 18003284804722492.0000 - mean_squared_error: 18003284804722492.0000 - val_loss: 19163323493344944.0000 - val_mean_squared_error: 19163323493344944.0000\n",
            "Epoch 552/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17986544158212420.0000 - mean_squared_error: 17986544158212420.0000 - val_loss: 19145833246044092.0000 - val_mean_squared_error: 19145833246044092.0000\n",
            "Epoch 553/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17969693795638912.0000 - mean_squared_error: 17969693795638912.0000 - val_loss: 19128254672862120.0000 - val_mean_squared_error: 19128254672862120.0000\n",
            "Epoch 554/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17952798313127856.0000 - mean_squared_error: 17952798313127856.0000 - val_loss: 19110676051149448.0000 - val_mean_squared_error: 19110676051149448.0000\n",
            "Epoch 555/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17935994253582256.0000 - mean_squared_error: 17935994253582256.0000 - val_loss: 19093127664065312.0000 - val_mean_squared_error: 19093127664065312.0000\n",
            "Epoch 556/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17919042022221132.0000 - mean_squared_error: 17919042022221132.0000 - val_loss: 19075454358949308.0000 - val_mean_squared_error: 19075454358949308.0000\n",
            "Epoch 557/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17902221637851110.0000 - mean_squared_error: 17902221637851110.0000 - val_loss: 19057908131481496.0000 - val_mean_squared_error: 19057908131481496.0000\n",
            "Epoch 558/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17885147731949716.0000 - mean_squared_error: 17885147731949716.0000 - val_loss: 19040264976065300.0000 - val_mean_squared_error: 19040264976065300.0000\n",
            "Epoch 559/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17868309051444258.0000 - mean_squared_error: 17868309051444258.0000 - val_loss: 19022546537394660.0000 - val_mean_squared_error: 19022546537394660.0000\n",
            "Epoch 560/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17851235449288782.0000 - mean_squared_error: 17851235449288782.0000 - val_loss: 19004890460678548.0000 - val_mean_squared_error: 19004890460678548.0000\n",
            "Epoch 561/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17834202509599496.0000 - mean_squared_error: 17834202509599496.0000 - val_loss: 18987085867875796.0000 - val_mean_squared_error: 18987085867875796.0000\n",
            "Epoch 562/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17817223923723702.0000 - mean_squared_error: 17817223923723702.0000 - val_loss: 18969388916174316.0000 - val_mean_squared_error: 18969388916174316.0000\n",
            "Epoch 563/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17800217311211956.0000 - mean_squared_error: 17800217311211956.0000 - val_loss: 18951661839038384.0000 - val_mean_squared_error: 18951661839038384.0000\n",
            "Epoch 564/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17783107352188694.0000 - mean_squared_error: 17783107352188694.0000 - val_loss: 18933820641952208.0000 - val_mean_squared_error: 18933820641952208.0000\n",
            "Epoch 565/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17765929202206596.0000 - mean_squared_error: 17765929202206596.0000 - val_loss: 18916007434949512.0000 - val_mean_squared_error: 18916007434949512.0000\n",
            "Epoch 566/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17748782555232496.0000 - mean_squared_error: 17748782555232496.0000 - val_loss: 18898170544963308.0000 - val_mean_squared_error: 18898170544963308.0000\n",
            "Epoch 567/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17731664859800676.0000 - mean_squared_error: 17731664859800676.0000 - val_loss: 18880303578073356.0000 - val_mean_squared_error: 18880303578073356.0000\n",
            "Epoch 568/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17714533650712914.0000 - mean_squared_error: 17714533650712914.0000 - val_loss: 18862430120201756.0000 - val_mean_squared_error: 18862430120201756.0000\n",
            "Epoch 569/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17697337256232186.0000 - mean_squared_error: 17697337256232186.0000 - val_loss: 18844505001395844.0000 - val_mean_squared_error: 18844505001395844.0000\n",
            "Epoch 570/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17680270025147364.0000 - mean_squared_error: 17680270025147364.0000 - val_loss: 18826532504490240.0000 - val_mean_squared_error: 18826532504490240.0000\n",
            "Epoch 571/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17662926206066074.0000 - mean_squared_error: 17662926206066074.0000 - val_loss: 18808618183765948.0000 - val_mean_squared_error: 18808618183765948.0000\n",
            "Epoch 572/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17645556368109354.0000 - mean_squared_error: 17645556368109354.0000 - val_loss: 18790611217927892.0000 - val_mean_squared_error: 18790611217927892.0000\n",
            "Epoch 573/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17628435337547340.0000 - mean_squared_error: 17628435337547340.0000 - val_loss: 18772651678720232.0000 - val_mean_squared_error: 18772651678720232.0000\n",
            "Epoch 574/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17611130505773498.0000 - mean_squared_error: 17611130505773498.0000 - val_loss: 18754653363480148.0000 - val_mean_squared_error: 18754653363480148.0000\n",
            "Epoch 575/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17593834938250182.0000 - mean_squared_error: 17593834938250182.0000 - val_loss: 18736603423703780.0000 - val_mean_squared_error: 18736603423703780.0000\n",
            "Epoch 576/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17576521770169590.0000 - mean_squared_error: 17576521770169590.0000 - val_loss: 18718525457445904.0000 - val_mean_squared_error: 18718525457445904.0000\n",
            "Epoch 577/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17559127340943260.0000 - mean_squared_error: 17559127340943260.0000 - val_loss: 18700441060869764.0000 - val_mean_squared_error: 18700441060869764.0000\n",
            "Epoch 578/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17541772673576466.0000 - mean_squared_error: 17541772673576466.0000 - val_loss: 18682332969177436.0000 - val_mean_squared_error: 18682332969177436.0000\n",
            "Epoch 579/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17524387712110436.0000 - mean_squared_error: 17524387712110436.0000 - val_loss: 18664233552348432.0000 - val_mean_squared_error: 18664233552348432.0000\n",
            "Epoch 580/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17506982402705284.0000 - mean_squared_error: 17506982402705284.0000 - val_loss: 18646069456223792.0000 - val_mean_squared_error: 18646069456223792.0000\n",
            "Epoch 581/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17489466868462280.0000 - mean_squared_error: 17489466868462280.0000 - val_loss: 18627860202279168.0000 - val_mean_squared_error: 18627860202279168.0000\n",
            "Epoch 582/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17472057826019784.0000 - mean_squared_error: 17472057826019784.0000 - val_loss: 18609678950550696.0000 - val_mean_squared_error: 18609678950550696.0000\n",
            "Epoch 583/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17454531387298286.0000 - mean_squared_error: 17454531387298286.0000 - val_loss: 18591461070273448.0000 - val_mean_squared_error: 18591461070273448.0000\n",
            "Epoch 584/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17436991849534026.0000 - mean_squared_error: 17436991849534026.0000 - val_loss: 18573271277141092.0000 - val_mean_squared_error: 18573271277141092.0000\n",
            "Epoch 585/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17419630707822970.0000 - mean_squared_error: 17419630707822970.0000 - val_loss: 18554965131646108.0000 - val_mean_squared_error: 18554965131646108.0000\n",
            "Epoch 586/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17401929077567712.0000 - mean_squared_error: 17401929077567712.0000 - val_loss: 18536643953765592.0000 - val_mean_squared_error: 18536643953765592.0000\n",
            "Epoch 587/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17384346454963560.0000 - mean_squared_error: 17384346454963560.0000 - val_loss: 18518419643170076.0000 - val_mean_squared_error: 18518419643170076.0000\n",
            "Epoch 588/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17366890770816456.0000 - mean_squared_error: 17366890770816456.0000 - val_loss: 18500083372240640.0000 - val_mean_squared_error: 18500083372240640.0000\n",
            "Epoch 589/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17349292433917178.0000 - mean_squared_error: 17349292433917178.0000 - val_loss: 18481682506944304.0000 - val_mean_squared_error: 18481682506944304.0000\n",
            "Epoch 590/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17331535486973868.0000 - mean_squared_error: 17331535486973868.0000 - val_loss: 18463350652308924.0000 - val_mean_squared_error: 18463350652308924.0000\n",
            "Epoch 591/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17314005860438948.0000 - mean_squared_error: 17314005860438948.0000 - val_loss: 18444958413345208.0000 - val_mean_squared_error: 18444958413345208.0000\n",
            "Epoch 592/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17296285252138670.0000 - mean_squared_error: 17296285252138670.0000 - val_loss: 18426538208563360.0000 - val_mean_squared_error: 18426538208563360.0000\n",
            "Epoch 593/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17278627201829156.0000 - mean_squared_error: 17278627201829156.0000 - val_loss: 18408107254230600.0000 - val_mean_squared_error: 18408107254230600.0000\n",
            "Epoch 594/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17260974167883500.0000 - mean_squared_error: 17260974167883500.0000 - val_loss: 18389596648880048.0000 - val_mean_squared_error: 18389596648880048.0000\n",
            "Epoch 595/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17243200445053076.0000 - mean_squared_error: 17243200445053076.0000 - val_loss: 18371180811861552.0000 - val_mean_squared_error: 18371180811861552.0000\n",
            "Epoch 596/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17225455497592298.0000 - mean_squared_error: 17225455497592298.0000 - val_loss: 18352663715529352.0000 - val_mean_squared_error: 18352663715529352.0000\n",
            "Epoch 597/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17207634209669676.0000 - mean_squared_error: 17207634209669676.0000 - val_loss: 18334183332674660.0000 - val_mean_squared_error: 18334183332674660.0000\n",
            "Epoch 598/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17189947892764932.0000 - mean_squared_error: 17189947892764932.0000 - val_loss: 18315726560007416.0000 - val_mean_squared_error: 18315726560007416.0000\n",
            "Epoch 599/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17172160202178422.0000 - mean_squared_error: 17172160202178422.0000 - val_loss: 18297123418737184.0000 - val_mean_squared_error: 18297123418737184.0000\n",
            "Epoch 600/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17154352206177216.0000 - mean_squared_error: 17154352206177216.0000 - val_loss: 18278518142115980.0000 - val_mean_squared_error: 18278518142115980.0000\n",
            "Epoch 601/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17136552637606540.0000 - mean_squared_error: 17136552637606540.0000 - val_loss: 18259891281464212.0000 - val_mean_squared_error: 18259891281464212.0000\n",
            "Epoch 602/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17118557894058088.0000 - mean_squared_error: 17118557894058088.0000 - val_loss: 18241354845646500.0000 - val_mean_squared_error: 18241354845646500.0000\n",
            "Epoch 603/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17100665418723138.0000 - mean_squared_error: 17100665418723138.0000 - val_loss: 18222646235023996.0000 - val_mean_squared_error: 18222646235023996.0000\n",
            "Epoch 604/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17082874418824836.0000 - mean_squared_error: 17082874418824836.0000 - val_loss: 18204077574818892.0000 - val_mean_squared_error: 18204077574818892.0000\n",
            "Epoch 605/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17065009408195890.0000 - mean_squared_error: 17065009408195890.0000 - val_loss: 18185306505180456.0000 - val_mean_squared_error: 18185306505180456.0000\n",
            "Epoch 606/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17046998386144270.0000 - mean_squared_error: 17046998386144270.0000 - val_loss: 18166746495573320.0000 - val_mean_squared_error: 18166746495573320.0000\n",
            "Epoch 607/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17029088203181598.0000 - mean_squared_error: 17029088203181598.0000 - val_loss: 18147932391333192.0000 - val_mean_squared_error: 18147932391333192.0000\n",
            "Epoch 608/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 17011137618214866.0000 - mean_squared_error: 17011137618214866.0000 - val_loss: 18129169935894700.0000 - val_mean_squared_error: 18129169935894700.0000\n",
            "Epoch 609/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16993104071125248.0000 - mean_squared_error: 16993104071125248.0000 - val_loss: 18110433407984772.0000 - val_mean_squared_error: 18110433407984772.0000\n",
            "Epoch 610/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16975042350082908.0000 - mean_squared_error: 16975042350082908.0000 - val_loss: 18091690389093196.0000 - val_mean_squared_error: 18091690389093196.0000\n",
            "Epoch 611/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16957154654189994.0000 - mean_squared_error: 16957154654189994.0000 - val_loss: 18072839704834996.0000 - val_mean_squared_error: 18072839704834996.0000\n",
            "Epoch 612/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16939038114602904.0000 - mean_squared_error: 16939038114602904.0000 - val_loss: 18054161340973704.0000 - val_mean_squared_error: 18054161340973704.0000\n",
            "Epoch 613/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16920961013385948.0000 - mean_squared_error: 16920961013385948.0000 - val_loss: 18035192229665288.0000 - val_mean_squared_error: 18035192229665288.0000\n",
            "Epoch 614/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16902849118073962.0000 - mean_squared_error: 16902849118073962.0000 - val_loss: 18016370663829436.0000 - val_mean_squared_error: 18016370663829436.0000\n",
            "Epoch 615/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16884839042190878.0000 - mean_squared_error: 16884839042190878.0000 - val_loss: 17997684789841712.0000 - val_mean_squared_error: 17997684789841712.0000\n",
            "Epoch 616/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16866837829613716.0000 - mean_squared_error: 16866837829613716.0000 - val_loss: 17978772799171798.0000 - val_mean_squared_error: 17978772799171798.0000\n",
            "Epoch 617/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16848692545031572.0000 - mean_squared_error: 16848692545031572.0000 - val_loss: 17959759585586202.0000 - val_mean_squared_error: 17959759585586202.0000\n",
            "Epoch 618/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16830482807084128.0000 - mean_squared_error: 16830482807084128.0000 - val_loss: 17940814242190030.0000 - val_mean_squared_error: 17940814242190030.0000\n",
            "Epoch 619/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16812327874012864.0000 - mean_squared_error: 16812327874012864.0000 - val_loss: 17921960379170726.0000 - val_mean_squared_error: 17921960379170726.0000\n",
            "Epoch 620/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16794169826027200.0000 - mean_squared_error: 16794169826027200.0000 - val_loss: 17902928905907784.0000 - val_mean_squared_error: 17902928905907784.0000\n",
            "Epoch 621/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16775902300418646.0000 - mean_squared_error: 16775902300418646.0000 - val_loss: 17883880155714254.0000 - val_mean_squared_error: 17883880155714254.0000\n",
            "Epoch 622/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16757770746670776.0000 - mean_squared_error: 16757770746670776.0000 - val_loss: 17864873530171718.0000 - val_mean_squared_error: 17864873530171718.0000\n",
            "Epoch 623/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16739372822939152.0000 - mean_squared_error: 16739372822939152.0000 - val_loss: 17845887323922848.0000 - val_mean_squared_error: 17845887323922848.0000\n",
            "Epoch 624/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16721163687927356.0000 - mean_squared_error: 16721163687927356.0000 - val_loss: 17826754652009582.0000 - val_mean_squared_error: 17826754652009582.0000\n",
            "Epoch 625/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16702683603962078.0000 - mean_squared_error: 16702683603962078.0000 - val_loss: 17807642460053366.0000 - val_mean_squared_error: 17807642460053366.0000\n",
            "Epoch 626/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16684518492365066.0000 - mean_squared_error: 16684518492365066.0000 - val_loss: 17788534623727824.0000 - val_mean_squared_error: 17788534623727824.0000\n",
            "Epoch 627/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16666093027990960.0000 - mean_squared_error: 16666093027990960.0000 - val_loss: 17769392282071802.0000 - val_mean_squared_error: 17769392282071802.0000\n",
            "Epoch 628/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16647668239451526.0000 - mean_squared_error: 16647668239451526.0000 - val_loss: 17750277966897290.0000 - val_mean_squared_error: 17750277966897290.0000\n",
            "Epoch 629/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16629302837795462.0000 - mean_squared_error: 16629302837795462.0000 - val_loss: 17731075374372366.0000 - val_mean_squared_error: 17731075374372366.0000\n",
            "Epoch 630/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16610918862076446.0000 - mean_squared_error: 16610918862076446.0000 - val_loss: 17711932025704240.0000 - val_mean_squared_error: 17711932025704240.0000\n",
            "Epoch 631/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16592580472544968.0000 - mean_squared_error: 16592580472544968.0000 - val_loss: 17692696104718406.0000 - val_mean_squared_error: 17692696104718406.0000\n",
            "Epoch 632/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16574184392551074.0000 - mean_squared_error: 16574184392551074.0000 - val_loss: 17673478467675270.0000 - val_mean_squared_error: 17673478467675270.0000\n",
            "Epoch 633/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16555676005541058.0000 - mean_squared_error: 16555676005541058.0000 - val_loss: 17654226422363062.0000 - val_mean_squared_error: 17654226422363062.0000\n",
            "Epoch 634/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16537200612931500.0000 - mean_squared_error: 16537200612931500.0000 - val_loss: 17634890321871682.0000 - val_mean_squared_error: 17634890321871682.0000\n",
            "Epoch 635/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16518762178606648.0000 - mean_squared_error: 16518762178606648.0000 - val_loss: 17615625367392232.0000 - val_mean_squared_error: 17615625367392232.0000\n",
            "Epoch 636/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16500210201019782.0000 - mean_squared_error: 16500210201019782.0000 - val_loss: 17596360437178136.0000 - val_mean_squared_error: 17596360437178136.0000\n",
            "Epoch 637/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16481754246630316.0000 - mean_squared_error: 16481754246630316.0000 - val_loss: 17577052387433616.0000 - val_mean_squared_error: 17577052387433616.0000\n",
            "Epoch 638/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16463165400363790.0000 - mean_squared_error: 16463165400363790.0000 - val_loss: 17557645347185798.0000 - val_mean_squared_error: 17557645347185798.0000\n",
            "Epoch 639/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16444570852786360.0000 - mean_squared_error: 16444570852786360.0000 - val_loss: 17538300717423206.0000 - val_mean_squared_error: 17538300717423206.0000\n",
            "Epoch 640/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16426016007838016.0000 - mean_squared_error: 16426016007838016.0000 - val_loss: 17518916231820026.0000 - val_mean_squared_error: 17518916231820026.0000\n",
            "Epoch 641/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16407338604448780.0000 - mean_squared_error: 16407338604448780.0000 - val_loss: 17499517830037504.0000 - val_mean_squared_error: 17499517830037504.0000\n",
            "Epoch 642/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16388699354584436.0000 - mean_squared_error: 16388699354584436.0000 - val_loss: 17480132337422218.0000 - val_mean_squared_error: 17480132337422218.0000\n",
            "Epoch 643/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16370117221102722.0000 - mean_squared_error: 16370117221102722.0000 - val_loss: 17460637031956666.0000 - val_mean_squared_error: 17460637031956666.0000\n",
            "Epoch 644/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16351475396991714.0000 - mean_squared_error: 16351475396991714.0000 - val_loss: 17441273111239270.0000 - val_mean_squared_error: 17441273111239270.0000\n",
            "Epoch 645/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16332949983504202.0000 - mean_squared_error: 16332949983504202.0000 - val_loss: 17421776713832874.0000 - val_mean_squared_error: 17421776713832874.0000\n",
            "Epoch 646/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16314093729961610.0000 - mean_squared_error: 16314093729961610.0000 - val_loss: 17402229759565686.0000 - val_mean_squared_error: 17402229759565686.0000\n",
            "Epoch 647/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16295525173922478.0000 - mean_squared_error: 16295525173922478.0000 - val_loss: 17382747411798074.0000 - val_mean_squared_error: 17382747411798074.0000\n",
            "Epoch 648/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16276719706697560.0000 - mean_squared_error: 16276719706697560.0000 - val_loss: 17363184345337184.0000 - val_mean_squared_error: 17363184345337184.0000\n",
            "Epoch 649/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16257907359627572.0000 - mean_squared_error: 16257907359627572.0000 - val_loss: 17343650336635262.0000 - val_mean_squared_error: 17343650336635262.0000\n",
            "Epoch 650/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16239271797238688.0000 - mean_squared_error: 16239271797238688.0000 - val_loss: 17324056064931760.0000 - val_mean_squared_error: 17324056064931760.0000\n",
            "Epoch 651/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16220421437885660.0000 - mean_squared_error: 16220421437885660.0000 - val_loss: 17304513442029894.0000 - val_mean_squared_error: 17304513442029894.0000\n",
            "Epoch 652/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16201689197726916.0000 - mean_squared_error: 16201689197726916.0000 - val_loss: 17284831984916816.0000 - val_mean_squared_error: 17284831984916816.0000\n",
            "Epoch 653/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16182879994427192.0000 - mean_squared_error: 16182879994427192.0000 - val_loss: 17265262403208926.0000 - val_mean_squared_error: 17265262403208926.0000\n",
            "Epoch 654/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16164071801082650.0000 - mean_squared_error: 16164071801082650.0000 - val_loss: 17245579866287688.0000 - val_mean_squared_error: 17245579866287688.0000\n",
            "Epoch 655/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16145169508771102.0000 - mean_squared_error: 16145169508771102.0000 - val_loss: 17225898494103344.0000 - val_mean_squared_error: 17225898494103344.0000\n",
            "Epoch 656/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16126305202164832.0000 - mean_squared_error: 16126305202164832.0000 - val_loss: 17206374227940230.0000 - val_mean_squared_error: 17206374227940230.0000\n",
            "Epoch 657/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16107566461084054.0000 - mean_squared_error: 16107566461084054.0000 - val_loss: 17186636814925546.0000 - val_mean_squared_error: 17186636814925546.0000\n",
            "Epoch 658/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16088723024100520.0000 - mean_squared_error: 16088723024100520.0000 - val_loss: 17166892959459918.0000 - val_mean_squared_error: 17166892959459918.0000\n",
            "Epoch 659/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16069654163601858.0000 - mean_squared_error: 16069654163601858.0000 - val_loss: 17147116746147458.0000 - val_mean_squared_error: 17147116746147458.0000\n",
            "Epoch 660/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16050815580478110.0000 - mean_squared_error: 16050815580478110.0000 - val_loss: 17127432255865386.0000 - val_mean_squared_error: 17127432255865386.0000\n",
            "Epoch 661/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16031819351703622.0000 - mean_squared_error: 16031819351703622.0000 - val_loss: 17107671232663254.0000 - val_mean_squared_error: 17107671232663254.0000\n",
            "Epoch 662/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 16012886320305060.0000 - mean_squared_error: 16012886320305060.0000 - val_loss: 17087853076689938.0000 - val_mean_squared_error: 17087853076689938.0000\n",
            "Epoch 663/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15993932748848084.0000 - mean_squared_error: 15993932748848084.0000 - val_loss: 17068210529068720.0000 - val_mean_squared_error: 17068210529068720.0000\n",
            "Epoch 664/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15974962515408720.0000 - mean_squared_error: 15974962515408720.0000 - val_loss: 17048403183309702.0000 - val_mean_squared_error: 17048403183309702.0000\n",
            "Epoch 665/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15956008287101194.0000 - mean_squared_error: 15956008287101194.0000 - val_loss: 17028483913614794.0000 - val_mean_squared_error: 17028483913614794.0000\n",
            "Epoch 666/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15936965878315896.0000 - mean_squared_error: 15936965878315896.0000 - val_loss: 17008617360397006.0000 - val_mean_squared_error: 17008617360397006.0000\n",
            "Epoch 667/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15917879587357668.0000 - mean_squared_error: 15917879587357668.0000 - val_loss: 16988794970119776.0000 - val_mean_squared_error: 16988794970119776.0000\n",
            "Epoch 668/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15898860536633548.0000 - mean_squared_error: 15898860536633548.0000 - val_loss: 16968850925500520.0000 - val_mean_squared_error: 16968850925500520.0000\n",
            "Epoch 669/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15879742508782964.0000 - mean_squared_error: 15879742508782964.0000 - val_loss: 16948952160028010.0000 - val_mean_squared_error: 16948952160028010.0000\n",
            "Epoch 670/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15860664406814714.0000 - mean_squared_error: 15860664406814714.0000 - val_loss: 16929049063190182.0000 - val_mean_squared_error: 16929049063190182.0000\n",
            "Epoch 671/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15841648303185374.0000 - mean_squared_error: 15841648303185374.0000 - val_loss: 16909212768866280.0000 - val_mean_squared_error: 16909212768866280.0000\n",
            "Epoch 672/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15822589319744638.0000 - mean_squared_error: 15822589319744638.0000 - val_loss: 16889184802527290.0000 - val_mean_squared_error: 16889184802527290.0000\n",
            "Epoch 673/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15803328698372332.0000 - mean_squared_error: 15803328698372332.0000 - val_loss: 16869278478397648.0000 - val_mean_squared_error: 16869278478397648.0000\n",
            "Epoch 674/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15784242135561508.0000 - mean_squared_error: 15784242135561508.0000 - val_loss: 16849182702532618.0000 - val_mean_squared_error: 16849182702532618.0000\n",
            "Epoch 675/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15765076478832078.0000 - mean_squared_error: 15765076478832078.0000 - val_loss: 16829260326872662.0000 - val_mean_squared_error: 16829260326872662.0000\n",
            "Epoch 676/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15745999063329604.0000 - mean_squared_error: 15745999063329604.0000 - val_loss: 16809165630815794.0000 - val_mean_squared_error: 16809165630815794.0000\n",
            "Epoch 677/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15726755363642454.0000 - mean_squared_error: 15726755363642454.0000 - val_loss: 16789230345988594.0000 - val_mean_squared_error: 16789230345988594.0000\n",
            "Epoch 678/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15707625533744182.0000 - mean_squared_error: 15707625533744182.0000 - val_loss: 16769105536629950.0000 - val_mean_squared_error: 16769105536629950.0000\n",
            "Epoch 679/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15688230483540464.0000 - mean_squared_error: 15688230483540464.0000 - val_loss: 16748974248422336.0000 - val_mean_squared_error: 16748974248422336.0000\n",
            "Epoch 680/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15669099832009480.0000 - mean_squared_error: 15669099832009480.0000 - val_loss: 16728971154069098.0000 - val_mean_squared_error: 16728971154069098.0000\n",
            "Epoch 681/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15649775905431448.0000 - mean_squared_error: 15649775905431448.0000 - val_loss: 16708831300192246.0000 - val_mean_squared_error: 16708831300192246.0000\n",
            "Epoch 682/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15630487741897930.0000 - mean_squared_error: 15630487741897930.0000 - val_loss: 16688691458448066.0000 - val_mean_squared_error: 16688691458448066.0000\n",
            "Epoch 683/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15611295859745846.0000 - mean_squared_error: 15611295859745846.0000 - val_loss: 16668534412569352.0000 - val_mean_squared_error: 16668534412569352.0000\n",
            "Epoch 684/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15591936475387948.0000 - mean_squared_error: 15591936475387948.0000 - val_loss: 16648346137182670.0000 - val_mean_squared_error: 16648346137182670.0000\n",
            "Epoch 685/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15572530513871450.0000 - mean_squared_error: 15572530513871450.0000 - val_loss: 16628252533066642.0000 - val_mean_squared_error: 16628252533066642.0000\n",
            "Epoch 686/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15553151011661966.0000 - mean_squared_error: 15553151011661966.0000 - val_loss: 16608035236319024.0000 - val_mean_squared_error: 16608035236319024.0000\n",
            "Epoch 687/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15533901885553970.0000 - mean_squared_error: 15533901885553970.0000 - val_loss: 16587850261020210.0000 - val_mean_squared_error: 16587850261020210.0000\n",
            "Epoch 688/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15514533613590478.0000 - mean_squared_error: 15514533613590478.0000 - val_loss: 16567625393482778.0000 - val_mean_squared_error: 16567625393482778.0000\n",
            "Epoch 689/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15495126624653410.0000 - mean_squared_error: 15495126624653410.0000 - val_loss: 16547334900300990.0000 - val_mean_squared_error: 16547334900300990.0000\n",
            "Epoch 690/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15475695062671486.0000 - mean_squared_error: 15475695062671486.0000 - val_loss: 16527007814968454.0000 - val_mean_squared_error: 16527007814968454.0000\n",
            "Epoch 691/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15456353265202306.0000 - mean_squared_error: 15456353265202306.0000 - val_loss: 16506794813188130.0000 - val_mean_squared_error: 16506794813188130.0000\n",
            "Epoch 692/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15436879468869060.0000 - mean_squared_error: 15436879468869060.0000 - val_loss: 16486480685553536.0000 - val_mean_squared_error: 16486480685553536.0000\n",
            "Epoch 693/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15417359541124356.0000 - mean_squared_error: 15417359541124356.0000 - val_loss: 16466208536977824.0000 - val_mean_squared_error: 16466208536977824.0000\n",
            "Epoch 694/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15398111634556224.0000 - mean_squared_error: 15398111634556224.0000 - val_loss: 16445852393886320.0000 - val_mean_squared_error: 16445852393886320.0000\n",
            "Epoch 695/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15378537971120970.0000 - mean_squared_error: 15378537971120970.0000 - val_loss: 16425507000345734.0000 - val_mean_squared_error: 16425507000345734.0000\n",
            "Epoch 696/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15359033022606264.0000 - mean_squared_error: 15359033022606264.0000 - val_loss: 16405106815640432.0000 - val_mean_squared_error: 16405106815640432.0000\n",
            "Epoch 697/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15339480632016454.0000 - mean_squared_error: 15339480632016454.0000 - val_loss: 16384720510716448.0000 - val_mean_squared_error: 16384720510716448.0000\n",
            "Epoch 698/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15319991695467874.0000 - mean_squared_error: 15319991695467874.0000 - val_loss: 16364363372745514.0000 - val_mean_squared_error: 16364363372745514.0000\n",
            "Epoch 699/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15300362299212656.0000 - mean_squared_error: 15300362299212656.0000 - val_loss: 16343996516501122.0000 - val_mean_squared_error: 16343996516501122.0000\n",
            "Epoch 700/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15280884280811136.0000 - mean_squared_error: 15280884280811136.0000 - val_loss: 16323526350520782.0000 - val_mean_squared_error: 16323526350520782.0000\n",
            "Epoch 701/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15261305995881726.0000 - mean_squared_error: 15261305995881726.0000 - val_loss: 16303093844366678.0000 - val_mean_squared_error: 16303093844366678.0000\n",
            "Epoch 702/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15241700455830992.0000 - mean_squared_error: 15241700455830992.0000 - val_loss: 16282611824761910.0000 - val_mean_squared_error: 16282611824761910.0000\n",
            "Epoch 703/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15222066053843028.0000 - mean_squared_error: 15222066053843028.0000 - val_loss: 16262154580081482.0000 - val_mean_squared_error: 16262154580081482.0000\n",
            "Epoch 704/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15202500855806540.0000 - mean_squared_error: 15202500855806540.0000 - val_loss: 16241643502717750.0000 - val_mean_squared_error: 16241643502717750.0000\n",
            "Epoch 705/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15182945960831628.0000 - mean_squared_error: 15182945960831628.0000 - val_loss: 16221108790901210.0000 - val_mean_squared_error: 16221108790901210.0000\n",
            "Epoch 706/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15163304921995330.0000 - mean_squared_error: 15163304921995330.0000 - val_loss: 16200614917672010.0000 - val_mean_squared_error: 16200614917672010.0000\n",
            "Epoch 707/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15143581777599644.0000 - mean_squared_error: 15143581777599644.0000 - val_loss: 16180113619245114.0000 - val_mean_squared_error: 16180113619245114.0000\n",
            "Epoch 708/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15123918173479016.0000 - mean_squared_error: 15123918173479016.0000 - val_loss: 16159498176602622.0000 - val_mean_squared_error: 16159498176602622.0000\n",
            "Epoch 709/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15104210778309234.0000 - mean_squared_error: 15104210778309234.0000 - val_loss: 16138948396002518.0000 - val_mean_squared_error: 16138948396002518.0000\n",
            "Epoch 710/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15084473338111864.0000 - mean_squared_error: 15084473338111864.0000 - val_loss: 16118424458002246.0000 - val_mean_squared_error: 16118424458002246.0000\n",
            "Epoch 711/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15064868012202004.0000 - mean_squared_error: 15064868012202004.0000 - val_loss: 16097772447474358.0000 - val_mean_squared_error: 16097772447474358.0000\n",
            "Epoch 712/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15045044794157082.0000 - mean_squared_error: 15045044794157082.0000 - val_loss: 16077139812830006.0000 - val_mean_squared_error: 16077139812830006.0000\n",
            "Epoch 713/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15025348156149024.0000 - mean_squared_error: 15025348156149024.0000 - val_loss: 16056593271654390.0000 - val_mean_squared_error: 16056593271654390.0000\n",
            "Epoch 714/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 15005703747251754.0000 - mean_squared_error: 15005703747251754.0000 - val_loss: 16035887440575864.0000 - val_mean_squared_error: 16035887440575864.0000\n",
            "Epoch 715/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14985847507469238.0000 - mean_squared_error: 14985847507469238.0000 - val_loss: 16015286071837506.0000 - val_mean_squared_error: 16015286071837506.0000\n",
            "Epoch 716/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14966034426944364.0000 - mean_squared_error: 14966034426944364.0000 - val_loss: 15994623323891376.0000 - val_mean_squared_error: 15994623323891376.0000\n",
            "Epoch 717/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14946349196114300.0000 - mean_squared_error: 14946349196114300.0000 - val_loss: 15973999412641050.0000 - val_mean_squared_error: 15973999412641050.0000\n",
            "Epoch 718/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14926504330097724.0000 - mean_squared_error: 14926504330097724.0000 - val_loss: 15953250534828160.0000 - val_mean_squared_error: 15953250534828160.0000\n",
            "Epoch 719/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14906761588015334.0000 - mean_squared_error: 14906761588015334.0000 - val_loss: 15932628746796130.0000 - val_mean_squared_error: 15932628746796130.0000\n",
            "Epoch 720/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14886879043836224.0000 - mean_squared_error: 14886879043836224.0000 - val_loss: 15911843313230518.0000 - val_mean_squared_error: 15911843313230518.0000\n",
            "Epoch 721/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14866968257361556.0000 - mean_squared_error: 14866968257361556.0000 - val_loss: 15891040675530370.0000 - val_mean_squared_error: 15891040675530370.0000\n",
            "Epoch 722/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14847168890964932.0000 - mean_squared_error: 14847168890964932.0000 - val_loss: 15870354244600734.0000 - val_mean_squared_error: 15870354244600734.0000\n",
            "Epoch 723/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14827277711289342.0000 - mean_squared_error: 14827277711289342.0000 - val_loss: 15849530095666078.0000 - val_mean_squared_error: 15849530095666078.0000\n",
            "Epoch 724/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14807432773892476.0000 - mean_squared_error: 14807432773892476.0000 - val_loss: 15828779155298270.0000 - val_mean_squared_error: 15828779155298270.0000\n",
            "Epoch 725/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14787477763530718.0000 - mean_squared_error: 14787477763530718.0000 - val_loss: 15808014262353086.0000 - val_mean_squared_error: 15808014262353086.0000\n",
            "Epoch 726/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14767624874825054.0000 - mean_squared_error: 14767624874825054.0000 - val_loss: 15787341978123640.0000 - val_mean_squared_error: 15787341978123640.0000\n",
            "Epoch 727/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14747769196213122.0000 - mean_squared_error: 14747769196213122.0000 - val_loss: 15766424201328466.0000 - val_mean_squared_error: 15766424201328466.0000\n",
            "Epoch 728/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14727760551915698.0000 - mean_squared_error: 14727760551915698.0000 - val_loss: 15745565668390090.0000 - val_mean_squared_error: 15745565668390090.0000\n",
            "Epoch 729/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14707855972488890.0000 - mean_squared_error: 14707855972488890.0000 - val_loss: 15724729677963680.0000 - val_mean_squared_error: 15724729677963680.0000\n",
            "Epoch 730/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14687878483410388.0000 - mean_squared_error: 14687878483410388.0000 - val_loss: 15703890545174192.0000 - val_mean_squared_error: 15703890545174192.0000\n",
            "Epoch 731/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14667777198126372.0000 - mean_squared_error: 14667777198126372.0000 - val_loss: 15683020158611386.0000 - val_mean_squared_error: 15683020158611386.0000\n",
            "Epoch 732/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14647983472291462.0000 - mean_squared_error: 14647983472291462.0000 - val_loss: 15662129352754910.0000 - val_mean_squared_error: 15662129352754910.0000\n",
            "Epoch 733/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14628025397133382.0000 - mean_squared_error: 14628025397133382.0000 - val_loss: 15641159927158102.0000 - val_mean_squared_error: 15641159927158102.0000\n",
            "Epoch 734/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14607988305891588.0000 - mean_squared_error: 14607988305891588.0000 - val_loss: 15620553365634424.0000 - val_mean_squared_error: 15620553365634424.0000\n",
            "Epoch 735/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14588069383202796.0000 - mean_squared_error: 14588069383202796.0000 - val_loss: 15599515074968766.0000 - val_mean_squared_error: 15599515074968766.0000\n",
            "Epoch 736/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14568084148603358.0000 - mean_squared_error: 14568084148603358.0000 - val_loss: 15578588805300410.0000 - val_mean_squared_error: 15578588805300410.0000\n",
            "Epoch 737/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14548026145594082.0000 - mean_squared_error: 14548026145594082.0000 - val_loss: 15557675444799290.0000 - val_mean_squared_error: 15557675444799290.0000\n",
            "Epoch 738/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14527935697964458.0000 - mean_squared_error: 14527935697964458.0000 - val_loss: 15536664125072330.0000 - val_mean_squared_error: 15536664125072330.0000\n",
            "Epoch 739/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14507835896479256.0000 - mean_squared_error: 14507835896479256.0000 - val_loss: 15515666745790070.0000 - val_mean_squared_error: 15515666745790070.0000\n",
            "Epoch 740/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14487661157838354.0000 - mean_squared_error: 14487661157838354.0000 - val_loss: 15494597322677856.0000 - val_mean_squared_error: 15494597322677856.0000\n",
            "Epoch 741/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14467669590136506.0000 - mean_squared_error: 14467669590136506.0000 - val_loss: 15473657039768744.0000 - val_mean_squared_error: 15473657039768744.0000\n",
            "Epoch 742/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14447566903065072.0000 - mean_squared_error: 14447566903065072.0000 - val_loss: 15452643633221514.0000 - val_mean_squared_error: 15452643633221514.0000\n",
            "Epoch 743/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14427487505711984.0000 - mean_squared_error: 14427487505711984.0000 - val_loss: 15431548355376794.0000 - val_mean_squared_error: 15431548355376794.0000\n",
            "Epoch 744/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14407297642043040.0000 - mean_squared_error: 14407297642043040.0000 - val_loss: 15410512321388870.0000 - val_mean_squared_error: 15410512321388870.0000\n",
            "Epoch 745/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14387184627610358.0000 - mean_squared_error: 14387184627610358.0000 - val_loss: 15389391225209666.0000 - val_mean_squared_error: 15389391225209666.0000\n",
            "Epoch 746/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14367055672591842.0000 - mean_squared_error: 14367055672591842.0000 - val_loss: 15368298179777322.0000 - val_mean_squared_error: 15368298179777322.0000\n",
            "Epoch 747/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14346787682435048.0000 - mean_squared_error: 14346787682435048.0000 - val_loss: 15347241677965022.0000 - val_mean_squared_error: 15347241677965022.0000\n",
            "Epoch 748/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14326565281503252.0000 - mean_squared_error: 14326565281503252.0000 - val_loss: 15326196022765048.0000 - val_mean_squared_error: 15326196022765048.0000\n",
            "Epoch 749/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14306393388961614.0000 - mean_squared_error: 14306393388961614.0000 - val_loss: 15305016859598616.0000 - val_mean_squared_error: 15305016859598616.0000\n",
            "Epoch 750/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14286237726323796.0000 - mean_squared_error: 14286237726323796.0000 - val_loss: 15283910844335654.0000 - val_mean_squared_error: 15283910844335654.0000\n",
            "Epoch 751/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14266016970935516.0000 - mean_squared_error: 14266016970935516.0000 - val_loss: 15262713385093848.0000 - val_mean_squared_error: 15262713385093848.0000\n",
            "Epoch 752/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14245712254859644.0000 - mean_squared_error: 14245712254859644.0000 - val_loss: 15241526760331690.0000 - val_mean_squared_error: 15241526760331690.0000\n",
            "Epoch 753/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14225481107564106.0000 - mean_squared_error: 14225481107564106.0000 - val_loss: 15220392815648630.0000 - val_mean_squared_error: 15220392815648630.0000\n",
            "Epoch 754/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14205256103529784.0000 - mean_squared_error: 14205256103529784.0000 - val_loss: 15199247150800570.0000 - val_mean_squared_error: 15199247150800570.0000\n",
            "Epoch 755/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14185061957043382.0000 - mean_squared_error: 14185061957043382.0000 - val_loss: 15178022805548802.0000 - val_mean_squared_error: 15178022805548802.0000\n",
            "Epoch 756/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14164758914607526.0000 - mean_squared_error: 14164758914607526.0000 - val_loss: 15156821099870406.0000 - val_mean_squared_error: 15156821099870406.0000\n",
            "Epoch 757/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14144499063322632.0000 - mean_squared_error: 14144499063322632.0000 - val_loss: 15135537559292538.0000 - val_mean_squared_error: 15135537559292538.0000\n",
            "Epoch 758/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14124183556672986.0000 - mean_squared_error: 14124183556672986.0000 - val_loss: 15114378948879216.0000 - val_mean_squared_error: 15114378948879216.0000\n",
            "Epoch 759/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14103824579426128.0000 - mean_squared_error: 14103824579426128.0000 - val_loss: 15093089026513786.0000 - val_mean_squared_error: 15093089026513786.0000\n",
            "Epoch 760/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14083464166979800.0000 - mean_squared_error: 14083464166979800.0000 - val_loss: 15071823842674678.0000 - val_mean_squared_error: 15071823842674678.0000\n",
            "Epoch 761/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14063162939425812.0000 - mean_squared_error: 14063162939425812.0000 - val_loss: 15050550032502946.0000 - val_mean_squared_error: 15050550032502946.0000\n",
            "Epoch 762/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14042833995056702.0000 - mean_squared_error: 14042833995056702.0000 - val_loss: 15029252575745736.0000 - val_mean_squared_error: 15029252575745736.0000\n",
            "Epoch 763/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14022399142079254.0000 - mean_squared_error: 14022399142079254.0000 - val_loss: 15007935755237666.0000 - val_mean_squared_error: 15007935755237666.0000\n",
            "Epoch 764/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 14002050076061736.0000 - mean_squared_error: 14002050076061736.0000 - val_loss: 14986645881402938.0000 - val_mean_squared_error: 14986645881402938.0000\n",
            "Epoch 765/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13981796100741650.0000 - mean_squared_error: 13981796100741650.0000 - val_loss: 14965334435670328.0000 - val_mean_squared_error: 14965334435670328.0000\n",
            "Epoch 766/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13961329278506218.0000 - mean_squared_error: 13961329278506218.0000 - val_loss: 14944000411027722.0000 - val_mean_squared_error: 14944000411027722.0000\n",
            "Epoch 767/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13940938087485910.0000 - mean_squared_error: 13940938087485910.0000 - val_loss: 14922723409962210.0000 - val_mean_squared_error: 14922723409962210.0000\n",
            "Epoch 768/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13920642451894290.0000 - mean_squared_error: 13920642451894290.0000 - val_loss: 14901289278610114.0000 - val_mean_squared_error: 14901289278610114.0000\n",
            "Epoch 769/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13900100217140792.0000 - mean_squared_error: 13900100217140792.0000 - val_loss: 14880063077058918.0000 - val_mean_squared_error: 14880063077058918.0000\n",
            "Epoch 770/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13879825746564818.0000 - mean_squared_error: 13879825746564818.0000 - val_loss: 14858676335939190.0000 - val_mean_squared_error: 14858676335939190.0000\n",
            "Epoch 771/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13859402458713238.0000 - mean_squared_error: 13859402458713238.0000 - val_loss: 14837289643350166.0000 - val_mean_squared_error: 14837289643350166.0000\n",
            "Epoch 772/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13838914105448330.0000 - mean_squared_error: 13838914105448330.0000 - val_loss: 14815855511998070.0000 - val_mean_squared_error: 14815855511998070.0000\n",
            "Epoch 773/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13818419850400214.0000 - mean_squared_error: 13818419850400214.0000 - val_loss: 14794411783699274.0000 - val_mean_squared_error: 14794411783699274.0000\n",
            "Epoch 774/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13797925021272310.0000 - mean_squared_error: 13797925021272310.0000 - val_loss: 14773016476910310.0000 - val_mean_squared_error: 14773016476910310.0000\n",
            "Epoch 775/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13777496264475458.0000 - mean_squared_error: 13777496264475458.0000 - val_loss: 14751672964515088.0000 - val_mean_squared_error: 14751672964515088.0000\n",
            "Epoch 776/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13757111180266854.0000 - mean_squared_error: 13757111180266854.0000 - val_loss: 14730199086516490.0000 - val_mean_squared_error: 14730199086516490.0000\n",
            "Epoch 777/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13736576882394224.0000 - mean_squared_error: 13736576882394224.0000 - val_loss: 14708727404532246.0000 - val_mean_squared_error: 14708727404532246.0000\n",
            "Epoch 778/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13715963466303318.0000 - mean_squared_error: 13715963466303318.0000 - val_loss: 14687290155082422.0000 - val_mean_squared_error: 14687290155082422.0000\n",
            "Epoch 779/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13695417351195706.0000 - mean_squared_error: 13695417351195706.0000 - val_loss: 14665782972888266.0000 - val_mean_squared_error: 14665782972888266.0000\n",
            "Epoch 780/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13674962861044586.0000 - mean_squared_error: 13674962861044586.0000 - val_loss: 14644320936381422.0000 - val_mean_squared_error: 14644320936381422.0000\n",
            "Epoch 781/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13654492061256344.0000 - mean_squared_error: 13654492061256344.0000 - val_loss: 14622810514762778.0000 - val_mean_squared_error: 14622810514762778.0000\n",
            "Epoch 782/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13633867669306650.0000 - mean_squared_error: 13633867669306650.0000 - val_loss: 14601251659501638.0000 - val_mean_squared_error: 14601251659501638.0000\n",
            "Epoch 783/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13613312730380088.0000 - mean_squared_error: 13613312730380088.0000 - val_loss: 14579724082279162.0000 - val_mean_squared_error: 14579724082279162.0000\n",
            "Epoch 784/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13592735025696890.0000 - mean_squared_error: 13592735025696890.0000 - val_loss: 14558220151642170.0000 - val_mean_squared_error: 14558220151642170.0000\n",
            "Epoch 785/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13572167504095630.0000 - mean_squared_error: 13572167504095630.0000 - val_loss: 14536651663036298.0000 - val_mean_squared_error: 14536651663036298.0000\n",
            "Epoch 786/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13551567051121186.0000 - mean_squared_error: 13551567051121186.0000 - val_loss: 14515216633866182.0000 - val_mean_squared_error: 14515216633866182.0000\n",
            "Epoch 787/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13531036318466278.0000 - mean_squared_error: 13531036318466278.0000 - val_loss: 14493560971983414.0000 - val_mean_squared_error: 14493560971983414.0000\n",
            "Epoch 788/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13510370843362298.0000 - mean_squared_error: 13510370843362298.0000 - val_loss: 14472023712885512.0000 - val_mean_squared_error: 14472023712885512.0000\n",
            "Epoch 789/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13489881504441884.0000 - mean_squared_error: 13489881504441884.0000 - val_loss: 14450468157712234.0000 - val_mean_squared_error: 14450468157712234.0000\n",
            "Epoch 790/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13469356991744038.0000 - mean_squared_error: 13469356991744038.0000 - val_loss: 14428855566829186.0000 - val_mean_squared_error: 14428855566829186.0000\n",
            "Epoch 791/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13448655978367524.0000 - mean_squared_error: 13448655978367524.0000 - val_loss: 14407241920403328.0000 - val_mean_squared_error: 14407241920403328.0000\n",
            "Epoch 792/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13427815963264784.0000 - mean_squared_error: 13427815963264784.0000 - val_loss: 14385706857319776.0000 - val_mean_squared_error: 14385706857319776.0000\n",
            "Epoch 793/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13407231800943344.0000 - mean_squared_error: 13407231800943344.0000 - val_loss: 14364027548851530.0000 - val_mean_squared_error: 14364027548851530.0000\n",
            "Epoch 794/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13386660143841396.0000 - mean_squared_error: 13386660143841396.0000 - val_loss: 14342373003174952.0000 - val_mean_squared_error: 14342373003174952.0000\n",
            "Epoch 795/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13365850538261346.0000 - mean_squared_error: 13365850538261346.0000 - val_loss: 14320779879170510.0000 - val_mean_squared_error: 14320779879170510.0000\n",
            "Epoch 796/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13345272360493878.0000 - mean_squared_error: 13345272360493878.0000 - val_loss: 14299224402859626.0000 - val_mean_squared_error: 14299224402859626.0000\n",
            "Epoch 797/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13324716192155708.0000 - mean_squared_error: 13324716192155708.0000 - val_loss: 14277503163863202.0000 - val_mean_squared_error: 14277503163863202.0000\n",
            "Epoch 798/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13304070869074730.0000 - mean_squared_error: 13304070869074730.0000 - val_loss: 14255811006891094.0000 - val_mean_squared_error: 14255811006891094.0000\n",
            "Epoch 799/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13283276130338692.0000 - mean_squared_error: 13283276130338692.0000 - val_loss: 14234114542819016.0000 - val_mean_squared_error: 14234114542819016.0000\n",
            "Epoch 800/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13262600221562390.0000 - mean_squared_error: 13262600221562390.0000 - val_loss: 14212483758988342.0000 - val_mean_squared_error: 14212483758988342.0000\n",
            "Epoch 801/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13241841280801644.0000 - mean_squared_error: 13241841280801644.0000 - val_loss: 14190752874514512.0000 - val_mean_squared_error: 14190752874514512.0000\n",
            "Epoch 802/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13221103351664854.0000 - mean_squared_error: 13221103351664854.0000 - val_loss: 14169016584933538.0000 - val_mean_squared_error: 14169016584933538.0000\n",
            "Epoch 803/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13200338234230844.0000 - mean_squared_error: 13200338234230844.0000 - val_loss: 14147258814449744.0000 - val_mean_squared_error: 14147258814449744.0000\n",
            "Epoch 804/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13179603822471796.0000 - mean_squared_error: 13179603822471796.0000 - val_loss: 14125614126572400.0000 - val_mean_squared_error: 14125614126572400.0000\n",
            "Epoch 805/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13158938922966334.0000 - mean_squared_error: 13158938922966334.0000 - val_loss: 14103865000620240.0000 - val_mean_squared_error: 14103865000620240.0000\n",
            "Epoch 806/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13138101012822812.0000 - mean_squared_error: 13138101012822812.0000 - val_loss: 14082121200912838.0000 - val_mean_squared_error: 14082121200912838.0000\n",
            "Epoch 807/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13117392745993750.0000 - mean_squared_error: 13117392745993750.0000 - val_loss: 14060346262692534.0000 - val_mean_squared_error: 14060346262692534.0000\n",
            "Epoch 808/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13096498531987938.0000 - mean_squared_error: 13096498531987938.0000 - val_loss: 14038536885871472.0000 - val_mean_squared_error: 14038536885871472.0000\n",
            "Epoch 809/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13075672176339178.0000 - mean_squared_error: 13075672176339178.0000 - val_loss: 14016877159542250.0000 - val_mean_squared_error: 14016877159542250.0000\n",
            "Epoch 810/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13054990311105404.0000 - mean_squared_error: 13054990311105404.0000 - val_loss: 13995011796487894.0000 - val_mean_squared_error: 13995011796487894.0000\n",
            "Epoch 811/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13034170273371762.0000 - mean_squared_error: 13034170273371762.0000 - val_loss: 13973250883641018.0000 - val_mean_squared_error: 13973250883641018.0000\n",
            "Epoch 812/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 13013382603562624.0000 - mean_squared_error: 13013382603562624.0000 - val_loss: 13951620275734146.0000 - val_mean_squared_error: 13951620275734146.0000\n",
            "Epoch 813/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12992687128233580.0000 - mean_squared_error: 12992687128233580.0000 - val_loss: 13929760305654258.0000 - val_mean_squared_error: 13929760305654258.0000\n",
            "Epoch 814/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12971779485620684.0000 - mean_squared_error: 12971779485620684.0000 - val_loss: 13907886407262346.0000 - val_mean_squared_error: 13907886407262346.0000\n",
            "Epoch 815/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12950934773087306.0000 - mean_squared_error: 12950934773087306.0000 - val_loss: 13886085668906582.0000 - val_mean_squared_error: 13886085668906582.0000\n",
            "Epoch 816/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12930212128445164.0000 - mean_squared_error: 12930212128445164.0000 - val_loss: 13864305452972230.0000 - val_mean_squared_error: 13864305452972230.0000\n",
            "Epoch 817/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12909435392729748.0000 - mean_squared_error: 12909435392729748.0000 - val_loss: 13842402472556000.0000 - val_mean_squared_error: 13842402472556000.0000\n",
            "Epoch 818/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12888620612837968.0000 - mean_squared_error: 12888620612837968.0000 - val_loss: 13820596456486184.0000 - val_mean_squared_error: 13820596456486184.0000\n",
            "Epoch 819/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12867616082870528.0000 - mean_squared_error: 12867616082870528.0000 - val_loss: 13798714010624046.0000 - val_mean_squared_error: 13798714010624046.0000\n",
            "Epoch 820/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12846736582317034.0000 - mean_squared_error: 12846736582317034.0000 - val_loss: 13776905822805230.0000 - val_mean_squared_error: 13776905822805230.0000\n",
            "Epoch 821/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12825933186822300.0000 - mean_squared_error: 12825933186822300.0000 - val_loss: 13754937234943654.0000 - val_mean_squared_error: 13754937234943654.0000\n",
            "Epoch 822/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12805161803109980.0000 - mean_squared_error: 12805161803109980.0000 - val_loss: 13733144182638118.0000 - val_mean_squared_error: 13733144182638118.0000\n",
            "Epoch 823/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12784180076867416.0000 - mean_squared_error: 12784180076867416.0000 - val_loss: 13711244538707782.0000 - val_mean_squared_error: 13711244538707782.0000\n",
            "Epoch 824/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12763300890690950.0000 - mean_squared_error: 12763300890690950.0000 - val_loss: 13689278134727882.0000 - val_mean_squared_error: 13689278134727882.0000\n",
            "Epoch 825/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12742403468368866.0000 - mean_squared_error: 12742403468368866.0000 - val_loss: 13667550817260792.0000 - val_mean_squared_error: 13667550817260792.0000\n",
            "Epoch 826/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12721589178267378.0000 - mean_squared_error: 12721589178267378.0000 - val_loss: 13645557545469942.0000 - val_mean_squared_error: 13645557545469942.0000\n",
            "Epoch 827/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12700643363904830.0000 - mean_squared_error: 12700643363904830.0000 - val_loss: 13623640703471408.0000 - val_mean_squared_error: 13623640703471408.0000\n",
            "Epoch 828/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12679710069189700.0000 - mean_squared_error: 12679710069189700.0000 - val_loss: 13601814353036650.0000 - val_mean_squared_error: 13601814353036650.0000\n",
            "Epoch 829/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12658786090361910.0000 - mean_squared_error: 12658786090361910.0000 - val_loss: 13579846917779294.0000 - val_mean_squared_error: 13579846917779294.0000\n",
            "Epoch 830/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12637811461142746.0000 - mean_squared_error: 12637811461142746.0000 - val_loss: 13557853694519146.0000 - val_mean_squared_error: 13557853694519146.0000\n",
            "Epoch 831/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12616945852408862.0000 - mean_squared_error: 12616945852408862.0000 - val_loss: 13535889535084302.0000 - val_mean_squared_error: 13535889535084302.0000\n",
            "Epoch 832/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12596013407422942.0000 - mean_squared_error: 12596013407422942.0000 - val_loss: 13513949107163670.0000 - val_mean_squared_error: 13513949107163670.0000\n",
            "Epoch 833/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12575126677716576.0000 - mean_squared_error: 12575126677716576.0000 - val_loss: 13492000040777738.0000 - val_mean_squared_error: 13492000040777738.0000\n",
            "Epoch 834/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12554046729156154.0000 - mean_squared_error: 12554046729156154.0000 - val_loss: 13470014442904442.0000 - val_mean_squared_error: 13470014442904442.0000\n",
            "Epoch 835/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12533111743335620.0000 - mean_squared_error: 12533111743335620.0000 - val_loss: 13448021237843306.0000 - val_mean_squared_error: 13448021237843306.0000\n",
            "Epoch 836/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12512186673300614.0000 - mean_squared_error: 12512186673300614.0000 - val_loss: 13426058261344374.0000 - val_mean_squared_error: 13426058261344374.0000\n",
            "Epoch 837/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12491220473790070.0000 - mean_squared_error: 12491220473790070.0000 - val_loss: 13404069363383210.0000 - val_mean_squared_error: 13404069363383210.0000\n",
            "Epoch 838/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12470262501237744.0000 - mean_squared_error: 12470262501237744.0000 - val_loss: 13382071954349848.0000 - val_mean_squared_error: 13382071954349848.0000\n",
            "Epoch 839/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12449239498962234.0000 - mean_squared_error: 12449239498962234.0000 - val_loss: 13360008871141422.0000 - val_mean_squared_error: 13360008871141422.0000\n",
            "Epoch 840/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12428263022208518.0000 - mean_squared_error: 12428263022208518.0000 - val_loss: 13338058803809726.0000 - val_mean_squared_error: 13338058803809726.0000\n",
            "Epoch 841/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12407297293504148.0000 - mean_squared_error: 12407297293504148.0000 - val_loss: 13316080776726238.0000 - val_mean_squared_error: 13316080776726238.0000\n",
            "Epoch 842/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12386353804316608.0000 - mean_squared_error: 12386353804316608.0000 - val_loss: 13294031743156594.0000 - val_mean_squared_error: 13294031743156594.0000\n",
            "Epoch 843/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12365222082264278.0000 - mean_squared_error: 12365222082264278.0000 - val_loss: 13272016031981522.0000 - val_mean_squared_error: 13272016031981522.0000\n",
            "Epoch 844/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12344185247399612.0000 - mean_squared_error: 12344185247399612.0000 - val_loss: 13249906723277622.0000 - val_mean_squared_error: 13249906723277622.0000\n",
            "Epoch 845/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12323142162962662.0000 - mean_squared_error: 12323142162962662.0000 - val_loss: 13227831865307160.0000 - val_mean_squared_error: 13227831865307160.0000\n",
            "Epoch 846/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12302145685299536.0000 - mean_squared_error: 12302145685299536.0000 - val_loss: 13205806514721022.0000 - val_mean_squared_error: 13205806514721022.0000\n",
            "Epoch 847/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12281288680168812.0000 - mean_squared_error: 12281288680168812.0000 - val_loss: 13183807037066408.0000 - val_mean_squared_error: 13183807037066408.0000\n",
            "Epoch 848/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12260257544716636.0000 - mean_squared_error: 12260257544716636.0000 - val_loss: 13161960467527136.0000 - val_mean_squared_error: 13161960467527136.0000\n",
            "Epoch 849/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12239312455167786.0000 - mean_squared_error: 12239312455167786.0000 - val_loss: 13139785557444226.0000 - val_mean_squared_error: 13139785557444226.0000\n",
            "Epoch 850/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12218292144840484.0000 - mean_squared_error: 12218292144840484.0000 - val_loss: 13117818407304754.0000 - val_mean_squared_error: 13117818407304754.0000\n",
            "Epoch 851/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12197190892300662.0000 - mean_squared_error: 12197190892300662.0000 - val_loss: 13095665056987056.0000 - val_mean_squared_error: 13095665056987056.0000\n",
            "Epoch 852/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12176173401494854.0000 - mean_squared_error: 12176173401494854.0000 - val_loss: 13073547200812928.0000 - val_mean_squared_error: 13073547200812928.0000\n",
            "Epoch 853/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12155046094389458.0000 - mean_squared_error: 12155046094389458.0000 - val_loss: 13051488600628278.0000 - val_mean_squared_error: 13051488600628278.0000\n",
            "Epoch 854/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12133976951590108.0000 - mean_squared_error: 12133976951590108.0000 - val_loss: 13029375075819474.0000 - val_mean_squared_error: 13029375075819474.0000\n",
            "Epoch 855/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12112947045929222.0000 - mean_squared_error: 12112947045929222.0000 - val_loss: 13007416685472056.0000 - val_mean_squared_error: 13007416685472056.0000\n",
            "Epoch 856/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12092052325427088.0000 - mean_squared_error: 12092052325427088.0000 - val_loss: 12985189095310054.0000 - val_mean_squared_error: 12985189095310054.0000\n",
            "Epoch 857/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12070893474307992.0000 - mean_squared_error: 12070893474307992.0000 - val_loss: 12963164951925176.0000 - val_mean_squared_error: 12963164951925176.0000\n",
            "Epoch 858/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12049939981248608.0000 - mean_squared_error: 12049939981248608.0000 - val_loss: 12941027816928922.0000 - val_mean_squared_error: 12941027816928922.0000\n",
            "Epoch 859/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12028762773244892.0000 - mean_squared_error: 12028762773244892.0000 - val_loss: 12918924064990618.0000 - val_mean_squared_error: 12918924064990618.0000\n",
            "Epoch 860/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 12007748458102668.0000 - mean_squared_error: 12007748458102668.0000 - val_loss: 12896766510700694.0000 - val_mean_squared_error: 12896766510700694.0000\n",
            "Epoch 861/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11986524514233110.0000 - mean_squared_error: 11986524514233110.0000 - val_loss: 12874572346061008.0000 - val_mean_squared_error: 12874572346061008.0000\n",
            "Epoch 862/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11965470001355954.0000 - mean_squared_error: 11965470001355954.0000 - val_loss: 12852416963520086.0000 - val_mean_squared_error: 12852416963520086.0000\n",
            "Epoch 863/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11944262704281494.0000 - mean_squared_error: 11944262704281494.0000 - val_loss: 12830298191328922.0000 - val_mean_squared_error: 12830298191328922.0000\n",
            "Epoch 864/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11923338770256226.0000 - mean_squared_error: 11923338770256226.0000 - val_loss: 12808177253455096.0000 - val_mean_squared_error: 12808177253455096.0000\n",
            "Epoch 865/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11902146745526576.0000 - mean_squared_error: 11902146745526576.0000 - val_loss: 12785988536386922.0000 - val_mean_squared_error: 12785988536386922.0000\n",
            "Epoch 866/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11880899182374350.0000 - mean_squared_error: 11880899182374350.0000 - val_loss: 12763825674051258.0000 - val_mean_squared_error: 12763825674051258.0000\n",
            "Epoch 867/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11859937615748436.0000 - mean_squared_error: 11859937615748436.0000 - val_loss: 12741682211864486.0000 - val_mean_squared_error: 12741682211864486.0000\n",
            "Epoch 868/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11838709029122506.0000 - mean_squared_error: 11838709029122506.0000 - val_loss: 12719434323735570.0000 - val_mean_squared_error: 12719434323735570.0000\n",
            "Epoch 869/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11817692216049780.0000 - mean_squared_error: 11817692216049780.0000 - val_loss: 12697491123498474.0000 - val_mean_squared_error: 12697491123498474.0000\n",
            "Epoch 870/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11796703901178548.0000 - mean_squared_error: 11796703901178548.0000 - val_loss: 12675241124283942.0000 - val_mean_squared_error: 12675241124283942.0000\n",
            "Epoch 871/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11775639255337532.0000 - mean_squared_error: 11775639255337532.0000 - val_loss: 12653049246653678.0000 - val_mean_squared_error: 12653049246653678.0000\n",
            "Epoch 872/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11754391605238036.0000 - mean_squared_error: 11754391605238036.0000 - val_loss: 12631038188359842.0000 - val_mean_squared_error: 12631038188359842.0000\n",
            "Epoch 873/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11733387989925494.0000 - mean_squared_error: 11733387989925494.0000 - val_loss: 12608920684033320.0000 - val_mean_squared_error: 12608920684033320.0000\n",
            "Epoch 874/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11712354511453234.0000 - mean_squared_error: 11712354511453234.0000 - val_loss: 12586682562708566.0000 - val_mean_squared_error: 12586682562708566.0000\n",
            "Epoch 875/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11691180067537382.0000 - mean_squared_error: 11691180067537382.0000 - val_loss: 12564428292792088.0000 - val_mean_squared_error: 12564428292792088.0000\n",
            "Epoch 876/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11669995929570524.0000 - mean_squared_error: 11669995929570524.0000 - val_loss: 12542192337149998.0000 - val_mean_squared_error: 12542192337149998.0000\n",
            "Epoch 877/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11648883332879988.0000 - mean_squared_error: 11648883332879988.0000 - val_loss: 12519970461478378.0000 - val_mean_squared_error: 12519970461478378.0000\n",
            "Epoch 878/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11627706178031808.0000 - mean_squared_error: 11627706178031808.0000 - val_loss: 12497812033635786.0000 - val_mean_squared_error: 12497812033635786.0000\n",
            "Epoch 879/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11606556717217800.0000 - mean_squared_error: 11606556717217800.0000 - val_loss: 12475594440798786.0000 - val_mean_squared_error: 12475594440798786.0000\n",
            "Epoch 880/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11585358757292894.0000 - mean_squared_error: 11585358757292894.0000 - val_loss: 12453337010320216.0000 - val_mean_squared_error: 12453337010320216.0000\n",
            "Epoch 881/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11564168804110410.0000 - mean_squared_error: 11564168804110410.0000 - val_loss: 12431074180800838.0000 - val_mean_squared_error: 12431074180800838.0000\n",
            "Epoch 882/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11542856885550942.0000 - mean_squared_error: 11542856885550942.0000 - val_loss: 12408939533003158.0000 - val_mean_squared_error: 12408939533003158.0000\n",
            "Epoch 883/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11521929979371856.0000 - mean_squared_error: 11521929979371856.0000 - val_loss: 12386764022352786.0000 - val_mean_squared_error: 12386764022352786.0000\n",
            "Epoch 884/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11500678264772280.0000 - mean_squared_error: 11500678264772280.0000 - val_loss: 12364423762095318.0000 - val_mean_squared_error: 12364423762095318.0000\n",
            "Epoch 885/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11479500889708308.0000 - mean_squared_error: 11479500889708308.0000 - val_loss: 12342164256929158.0000 - val_mean_squared_error: 12342164256929158.0000\n",
            "Epoch 886/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11458453223264170.0000 - mean_squared_error: 11458453223264170.0000 - val_loss: 12319995194796066.0000 - val_mean_squared_error: 12319995194796066.0000\n",
            "Epoch 887/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11437300765996670.0000 - mean_squared_error: 11437300765996670.0000 - val_loss: 12297886492725966.0000 - val_mean_squared_error: 12297886492725966.0000\n",
            "Epoch 888/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11416187072783368.0000 - mean_squared_error: 11416187072783368.0000 - val_loss: 12275518309114736.0000 - val_mean_squared_error: 12275518309114736.0000\n",
            "Epoch 889/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11394866531636620.0000 - mean_squared_error: 11394866531636620.0000 - val_loss: 12253282505131094.0000 - val_mean_squared_error: 12253282505131094.0000\n",
            "Epoch 890/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11373778933994590.0000 - mean_squared_error: 11373778933994590.0000 - val_loss: 12231126449226654.0000 - val_mean_squared_error: 12231126449226654.0000\n",
            "Epoch 891/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11352718561099290.0000 - mean_squared_error: 11352718561099290.0000 - val_loss: 12208802410356968.0000 - val_mean_squared_error: 12208802410356968.0000\n",
            "Epoch 892/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11331453983619406.0000 - mean_squared_error: 11331453983619406.0000 - val_loss: 12186547309352184.0000 - val_mean_squared_error: 12186547309352184.0000\n",
            "Epoch 893/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11310264584773226.0000 - mean_squared_error: 11310264584773226.0000 - val_loss: 12164267469821082.0000 - val_mean_squared_error: 12164267469821082.0000\n",
            "Epoch 894/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11289002370436592.0000 - mean_squared_error: 11289002370436592.0000 - val_loss: 12141973647380920.0000 - val_mean_squared_error: 12141973647380920.0000\n",
            "Epoch 895/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11267788623317540.0000 - mean_squared_error: 11267788623317540.0000 - val_loss: 12119706710950722.0000 - val_mean_squared_error: 12119706710950722.0000\n",
            "Epoch 896/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11246633359437750.0000 - mean_squared_error: 11246633359437750.0000 - val_loss: 12097384922692426.0000 - val_mean_squared_error: 12097384922692426.0000\n",
            "Epoch 897/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11225462186106080.0000 - mean_squared_error: 11225462186106080.0000 - val_loss: 12075190187816970.0000 - val_mean_squared_error: 12075190187816970.0000\n",
            "Epoch 898/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11204269168127276.0000 - mean_squared_error: 11204269168127276.0000 - val_loss: 12052888843117702.0000 - val_mean_squared_error: 12052888843117702.0000\n",
            "Epoch 899/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11183024936308418.0000 - mean_squared_error: 11183024936308418.0000 - val_loss: 12030618746125410.0000 - val_mean_squared_error: 12030618746125410.0000\n",
            "Epoch 900/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11161719440836088.0000 - mean_squared_error: 11161719440836088.0000 - val_loss: 12008529620127998.0000 - val_mean_squared_error: 12008529620127998.0000\n",
            "Epoch 901/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11140831466910500.0000 - mean_squared_error: 11140831466910500.0000 - val_loss: 11986203603632128.0000 - val_mean_squared_error: 11986203603632128.0000\n",
            "Epoch 902/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11119685692812588.0000 - mean_squared_error: 11119685692812588.0000 - val_loss: 11963934671376732.0000 - val_mean_squared_error: 11963934671376732.0000\n",
            "Epoch 903/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11098283358964746.0000 - mean_squared_error: 11098283358964746.0000 - val_loss: 11941559111098506.0000 - val_mean_squared_error: 11941559111098506.0000\n",
            "Epoch 904/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11077122203932856.0000 - mean_squared_error: 11077122203932856.0000 - val_loss: 11919322494225576.0000 - val_mean_squared_error: 11919322494225576.0000\n",
            "Epoch 905/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11055967363778620.0000 - mean_squared_error: 11055967363778620.0000 - val_loss: 11896927618727196.0000 - val_mean_squared_error: 11896927618727196.0000\n",
            "Epoch 906/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11034797767647638.0000 - mean_squared_error: 11034797767647638.0000 - val_loss: 11874663017837122.0000 - val_mean_squared_error: 11874663017837122.0000\n",
            "Epoch 907/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 11013631557524286.0000 - mean_squared_error: 11013631557524286.0000 - val_loss: 11852459796154820.0000 - val_mean_squared_error: 11852459796154820.0000\n",
            "Epoch 908/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10992331624778786.0000 - mean_squared_error: 10992331624778786.0000 - val_loss: 11830060686352522.0000 - val_mean_squared_error: 11830060686352522.0000\n",
            "Epoch 909/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10971309143427526.0000 - mean_squared_error: 10971309143427526.0000 - val_loss: 11807762763067878.0000 - val_mean_squared_error: 11807762763067878.0000\n",
            "Epoch 910/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10950010731689714.0000 - mean_squared_error: 10950010731689714.0000 - val_loss: 11785512169352220.0000 - val_mean_squared_error: 11785512169352220.0000\n",
            "Epoch 911/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10928858909251188.0000 - mean_squared_error: 10928858909251188.0000 - val_loss: 11763169051849560.0000 - val_mean_squared_error: 11763169051849560.0000\n",
            "Epoch 912/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10907497230275886.0000 - mean_squared_error: 10907497230275886.0000 - val_loss: 11740870085154782.0000 - val_mean_squared_error: 11740870085154782.0000\n",
            "Epoch 913/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10886420316137196.0000 - mean_squared_error: 10886420316137196.0000 - val_loss: 11718586169044552.0000 - val_mean_squared_error: 11718586169044552.0000\n",
            "Epoch 914/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10865223662319740.0000 - mean_squared_error: 10865223662319740.0000 - val_loss: 11696245259688920.0000 - val_mean_squared_error: 11696245259688920.0000\n",
            "Epoch 915/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10843927928861570.0000 - mean_squared_error: 10843927928861570.0000 - val_loss: 11674030263244580.0000 - val_mean_squared_error: 11674030263244580.0000\n",
            "Epoch 916/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10822951765725514.0000 - mean_squared_error: 10822951765725514.0000 - val_loss: 11651767991828294.0000 - val_mean_squared_error: 11651767991828294.0000\n",
            "Epoch 917/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10801483897936262.0000 - mean_squared_error: 10801483897936262.0000 - val_loss: 11629353928502856.0000 - val_mean_squared_error: 11629353928502856.0000\n",
            "Epoch 918/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10780313627489340.0000 - mean_squared_error: 10780313627489340.0000 - val_loss: 11607052856788796.0000 - val_mean_squared_error: 11607052856788796.0000\n",
            "Epoch 919/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10759274068783144.0000 - mean_squared_error: 10759274068783144.0000 - val_loss: 11584731359714726.0000 - val_mean_squared_error: 11584731359714726.0000\n",
            "Epoch 920/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10737880416753036.0000 - mean_squared_error: 10737880416753036.0000 - val_loss: 11562327069259788.0000 - val_mean_squared_error: 11562327069259788.0000\n",
            "Epoch 921/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10716675952868634.0000 - mean_squared_error: 10716675952868634.0000 - val_loss: 11540143393318484.0000 - val_mean_squared_error: 11540143393318484.0000\n",
            "Epoch 922/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10695596382471882.0000 - mean_squared_error: 10695596382471882.0000 - val_loss: 11517906994833720.0000 - val_mean_squared_error: 11517906994833720.0000\n",
            "Epoch 923/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10674400335386900.0000 - mean_squared_error: 10674400335386900.0000 - val_loss: 11495549985417066.0000 - val_mean_squared_error: 11495549985417066.0000\n",
            "Epoch 924/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10653111078551090.0000 - mean_squared_error: 10653111078551090.0000 - val_loss: 11473133944465442.0000 - val_mean_squared_error: 11473133944465442.0000\n",
            "Epoch 925/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10631960317704548.0000 - mean_squared_error: 10631960317704548.0000 - val_loss: 11450873929726890.0000 - val_mean_squared_error: 11450873929726890.0000\n",
            "Epoch 926/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10610649876109610.0000 - mean_squared_error: 10610649876109610.0000 - val_loss: 11428613896789322.0000 - val_mean_squared_error: 11428613896789322.0000\n",
            "Epoch 927/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10589596286620048.0000 - mean_squared_error: 10589596286620048.0000 - val_loss: 11406274267431004.0000 - val_mean_squared_error: 11406274267431004.0000\n",
            "Epoch 928/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10568379991832098.0000 - mean_squared_error: 10568379991832098.0000 - val_loss: 11384077858246262.0000 - val_mean_squared_error: 11384077858246262.0000\n",
            "Epoch 929/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10547183197532154.0000 - mean_squared_error: 10547183197532154.0000 - val_loss: 11361759727989778.0000 - val_mean_squared_error: 11361759727989778.0000\n",
            "Epoch 930/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10525903631709892.0000 - mean_squared_error: 10525903631709892.0000 - val_loss: 11339548256087810.0000 - val_mean_squared_error: 11339548256087810.0000\n",
            "Epoch 931/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10504847505941904.0000 - mean_squared_error: 10504847505941904.0000 - val_loss: 11317103151310882.0000 - val_mean_squared_error: 11317103151310882.0000\n",
            "Epoch 932/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10483597840867920.0000 - mean_squared_error: 10483597840867920.0000 - val_loss: 11294785148447496.0000 - val_mean_squared_error: 11294785148447496.0000\n",
            "Epoch 933/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10462403554749902.0000 - mean_squared_error: 10462403554749902.0000 - val_loss: 11272455243428974.0000 - val_mean_squared_error: 11272455243428974.0000\n",
            "Epoch 934/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10441289410473910.0000 - mean_squared_error: 10441289410473910.0000 - val_loss: 11250125405140170.0000 - val_mean_squared_error: 11250125405140170.0000\n",
            "Epoch 935/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10420141534454234.0000 - mean_squared_error: 10420141534454234.0000 - val_loss: 11227915067643406.0000 - val_mean_squared_error: 11227915067643406.0000\n",
            "Epoch 936/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10398885076862134.0000 - mean_squared_error: 10398885076862134.0000 - val_loss: 11205524948154010.0000 - val_mean_squared_error: 11205524948154010.0000\n",
            "Epoch 937/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10377541879307280.0000 - mean_squared_error: 10377541879307280.0000 - val_loss: 11183168235987916.0000 - val_mean_squared_error: 11183168235987916.0000\n",
            "Epoch 938/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10356428002327694.0000 - mean_squared_error: 10356428002327694.0000 - val_loss: 11161009607956168.0000 - val_mean_squared_error: 11161009607956168.0000\n",
            "Epoch 939/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10335390463531862.0000 - mean_squared_error: 10335390463531862.0000 - val_loss: 11138656171612588.0000 - val_mean_squared_error: 11138656171612588.0000\n",
            "Epoch 940/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10314184804407270.0000 - mean_squared_error: 10314184804407270.0000 - val_loss: 11116315589839206.0000 - val_mean_squared_error: 11116315589839206.0000\n",
            "Epoch 941/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10292892028674986.0000 - mean_squared_error: 10292892028674986.0000 - val_loss: 11093943899884620.0000 - val_mean_squared_error: 11093943899884620.0000\n",
            "Epoch 942/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10271809654703402.0000 - mean_squared_error: 10271809654703402.0000 - val_loss: 11071619509167330.0000 - val_mean_squared_error: 11071619509167330.0000\n",
            "Epoch 943/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10250589717242516.0000 - mean_squared_error: 10250589717242516.0000 - val_loss: 11049289786138948.0000 - val_mean_squared_error: 11049289786138948.0000\n",
            "Epoch 944/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10229276030122432.0000 - mean_squared_error: 10229276030122432.0000 - val_loss: 11026979475392130.0000 - val_mean_squared_error: 11026979475392130.0000\n",
            "Epoch 945/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10208204928161904.0000 - mean_squared_error: 10208204928161904.0000 - val_loss: 11004592716653978.0000 - val_mean_squared_error: 11004592716653978.0000\n",
            "Epoch 946/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10186816698755816.0000 - mean_squared_error: 10186816698755816.0000 - val_loss: 10982268392666408.0000 - val_mean_squared_error: 10982268392666408.0000\n",
            "Epoch 947/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10165810748776204.0000 - mean_squared_error: 10165810748776204.0000 - val_loss: 10960004410542808.0000 - val_mean_squared_error: 10960004410542808.0000\n",
            "Epoch 948/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10144603819234306.0000 - mean_squared_error: 10144603819234306.0000 - val_loss: 10937712468667420.0000 - val_mean_squared_error: 10937712468667420.0000\n",
            "Epoch 949/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10123467293440264.0000 - mean_squared_error: 10123467293440264.0000 - val_loss: 10915424779294962.0000 - val_mean_squared_error: 10915424779294962.0000\n",
            "Epoch 950/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10102158176177532.0000 - mean_squared_error: 10102158176177532.0000 - val_loss: 10893004758825620.0000 - val_mean_squared_error: 10893004758825620.0000\n",
            "Epoch 951/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10081039238031572.0000 - mean_squared_error: 10081039238031572.0000 - val_loss: 10870810794375088.0000 - val_mean_squared_error: 10870810794375088.0000\n",
            "Epoch 952/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10059916729352330.0000 - mean_squared_error: 10059916729352330.0000 - val_loss: 10848458583431782.0000 - val_mean_squared_error: 10848458583431782.0000\n",
            "Epoch 953/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10038718664635080.0000 - mean_squared_error: 10038718664635080.0000 - val_loss: 10826209755020478.0000 - val_mean_squared_error: 10826209755020478.0000\n",
            "Epoch 954/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 10017623765700522.0000 - mean_squared_error: 10017623765700522.0000 - val_loss: 10803819914582630.0000 - val_mean_squared_error: 10803819914582630.0000\n",
            "Epoch 955/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9996459091012792.0000 - mean_squared_error: 9996459091012792.0000 - val_loss: 10781630366426152.0000 - val_mean_squared_error: 10781630366426152.0000\n",
            "Epoch 956/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9975319434357690.0000 - mean_squared_error: 9975319434357690.0000 - val_loss: 10759320207337784.0000 - val_mean_squared_error: 10759320207337784.0000\n",
            "Epoch 957/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9954207335810460.0000 - mean_squared_error: 9954207335810460.0000 - val_loss: 10736965958104914.0000 - val_mean_squared_error: 10736965958104914.0000\n",
            "Epoch 958/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9932834486578986.0000 - mean_squared_error: 9932834486578986.0000 - val_loss: 10714666597098166.0000 - val_mean_squared_error: 10714666597098166.0000\n",
            "Epoch 959/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9911745586626328.0000 - mean_squared_error: 9911745586626328.0000 - val_loss: 10692352167307854.0000 - val_mean_squared_error: 10692352167307854.0000\n",
            "Epoch 960/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9890724985462310.0000 - mean_squared_error: 9890724985462310.0000 - val_loss: 10670036724439098.0000 - val_mean_squared_error: 10670036724439098.0000\n",
            "Epoch 961/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9869470897088376.0000 - mean_squared_error: 9869470897088376.0000 - val_loss: 10647728755298744.0000 - val_mean_squared_error: 10647728755298744.0000\n",
            "Epoch 962/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9848324261870782.0000 - mean_squared_error: 9848324261870782.0000 - val_loss: 10625429539884108.0000 - val_mean_squared_error: 10625429539884108.0000\n",
            "Epoch 963/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9827177379859630.0000 - mean_squared_error: 9827177379859630.0000 - val_loss: 10603136712323372.0000 - val_mean_squared_error: 10603136712323372.0000\n",
            "Epoch 964/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9806023466889814.0000 - mean_squared_error: 9806023466889814.0000 - val_loss: 10580919307542852.0000 - val_mean_squared_error: 10580919307542852.0000\n",
            "Epoch 965/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9785115407385642.0000 - mean_squared_error: 9785115407385642.0000 - val_loss: 10558741649408834.0000 - val_mean_squared_error: 10558741649408834.0000\n",
            "Epoch 966/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9763916164134226.0000 - mean_squared_error: 9763916164134226.0000 - val_loss: 10536349861676490.0000 - val_mean_squared_error: 10536349861676490.0000\n",
            "Epoch 967/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9742724680072312.0000 - mean_squared_error: 9742724680072312.0000 - val_loss: 10514076488861684.0000 - val_mean_squared_error: 10514076488861684.0000\n",
            "Epoch 968/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9721644413338040.0000 - mean_squared_error: 9721644413338040.0000 - val_loss: 10491805275663204.0000 - val_mean_squared_error: 10491805275663204.0000\n",
            "Epoch 969/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9700563722878212.0000 - mean_squared_error: 9700563722878212.0000 - val_loss: 10469486745028412.0000 - val_mean_squared_error: 10469486745028412.0000\n",
            "Epoch 970/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9679479868145270.0000 - mean_squared_error: 9679479868145270.0000 - val_loss: 10447241398695114.0000 - val_mean_squared_error: 10447241398695114.0000\n",
            "Epoch 971/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9658369229856548.0000 - mean_squared_error: 9658369229856548.0000 - val_loss: 10425125289626328.0000 - val_mean_squared_error: 10425125289626328.0000\n",
            "Epoch 972/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9637286860441152.0000 - mean_squared_error: 9637286860441152.0000 - val_loss: 10402946770072316.0000 - val_mean_squared_error: 10402946770072316.0000\n",
            "Epoch 973/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9616268486494084.0000 - mean_squared_error: 9616268486494084.0000 - val_loss: 10380599248408276.0000 - val_mean_squared_error: 10380599248408276.0000\n",
            "Epoch 974/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9595082164594064.0000 - mean_squared_error: 9595082164594064.0000 - val_loss: 10358412126786994.0000 - val_mean_squared_error: 10358412126786994.0000\n",
            "Epoch 975/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9574153903708180.0000 - mean_squared_error: 9574153903708180.0000 - val_loss: 10336066740473926.0000 - val_mean_squared_error: 10336066740473926.0000\n",
            "Epoch 976/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9552824969302324.0000 - mean_squared_error: 9552824969302324.0000 - val_loss: 10313907615002462.0000 - val_mean_squared_error: 10313907615002462.0000\n",
            "Epoch 977/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9531902731698014.0000 - mean_squared_error: 9531902731698014.0000 - val_loss: 10291657039485818.0000 - val_mean_squared_error: 10291657039485818.0000\n",
            "Epoch 978/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9510810503449448.0000 - mean_squared_error: 9510810503449448.0000 - val_loss: 10269372001103062.0000 - val_mean_squared_error: 10269372001103062.0000\n",
            "Epoch 979/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9489806703231578.0000 - mean_squared_error: 9489806703231578.0000 - val_loss: 10247234471794838.0000 - val_mean_squared_error: 10247234471794838.0000\n",
            "Epoch 980/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9468619520971244.0000 - mean_squared_error: 9468619520971244.0000 - val_loss: 10224871966275966.0000 - val_mean_squared_error: 10224871966275966.0000\n",
            "Epoch 981/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9447657070444706.0000 - mean_squared_error: 9447657070444706.0000 - val_loss: 10202692512505902.0000 - val_mean_squared_error: 10202692512505902.0000\n",
            "Epoch 982/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9426539613819466.0000 - mean_squared_error: 9426539613819466.0000 - val_loss: 10180445188546422.0000 - val_mean_squared_error: 10180445188546422.0000\n",
            "Epoch 983/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9405621488934900.0000 - mean_squared_error: 9405621488934900.0000 - val_loss: 10158313088610698.0000 - val_mean_squared_error: 10158313088610698.0000\n",
            "Epoch 984/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9384528573461192.0000 - mean_squared_error: 9384528573461192.0000 - val_loss: 10136024950329228.0000 - val_mean_squared_error: 10136024950329228.0000\n",
            "Epoch 985/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9363435902502950.0000 - mean_squared_error: 9363435902502950.0000 - val_loss: 10113768011224036.0000 - val_mean_squared_error: 10113768011224036.0000\n",
            "Epoch 986/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9342426646249010.0000 - mean_squared_error: 9342426646249010.0000 - val_loss: 10091652102344404.0000 - val_mean_squared_error: 10091652102344404.0000\n",
            "Epoch 987/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9321349202073690.0000 - mean_squared_error: 9321349202073690.0000 - val_loss: 10069428600894204.0000 - val_mean_squared_error: 10069428600894204.0000\n",
            "Epoch 988/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9300500004731816.0000 - mean_squared_error: 9300500004731816.0000 - val_loss: 10047230911712146.0000 - val_mean_squared_error: 10047230911712146.0000\n",
            "Epoch 989/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9279335803128356.0000 - mean_squared_error: 9279335803128356.0000 - val_loss: 10025026822543510.0000 - val_mean_squared_error: 10025026822543510.0000\n",
            "Epoch 990/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9258323649138346.0000 - mean_squared_error: 9258323649138346.0000 - val_loss: 10002764581458916.0000 - val_mean_squared_error: 10002764581458916.0000\n",
            "Epoch 991/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9237391258826692.0000 - mean_squared_error: 9237391258826692.0000 - val_loss: 9980631541240804.0000 - val_mean_squared_error: 9980631541240804.0000\n",
            "Epoch 992/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9216368589152962.0000 - mean_squared_error: 9216368589152962.0000 - val_loss: 9958397332704054.0000 - val_mean_squared_error: 9958397332704054.0000\n",
            "Epoch 993/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9195295550052836.0000 - mean_squared_error: 9195295550052836.0000 - val_loss: 9936304148326528.0000 - val_mean_squared_error: 9936304148326528.0000\n",
            "Epoch 994/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9174344294841510.0000 - mean_squared_error: 9174344294841510.0000 - val_loss: 9914095806654962.0000 - val_mean_squared_error: 9914095806654962.0000\n",
            "Epoch 995/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9153202728383940.0000 - mean_squared_error: 9153202728383940.0000 - val_loss: 9891942413872898.0000 - val_mean_squared_error: 9891942413872898.0000\n",
            "Epoch 996/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9132320231376956.0000 - mean_squared_error: 9132320231376956.0000 - val_loss: 9869717966073972.0000 - val_mean_squared_error: 9869717966073972.0000\n",
            "Epoch 997/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9111394196948658.0000 - mean_squared_error: 9111394196948658.0000 - val_loss: 9847559222781802.0000 - val_mean_squared_error: 9847559222781802.0000\n",
            "Epoch 998/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9090477930989120.0000 - mean_squared_error: 9090477930989120.0000 - val_loss: 9825388625865202.0000 - val_mean_squared_error: 9825388625865202.0000\n",
            "Epoch 999/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9069334083399698.0000 - mean_squared_error: 9069334083399698.0000 - val_loss: 9803197597522256.0000 - val_mean_squared_error: 9803197597522256.0000\n",
            "Epoch 1000/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9048361663172730.0000 - mean_squared_error: 9048361663172730.0000 - val_loss: 9781136837721278.0000 - val_mean_squared_error: 9781136837721278.0000\n",
            "Epoch 1001/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9027442175228352.0000 - mean_squared_error: 9027442175228352.0000 - val_loss: 9758918953700056.0000 - val_mean_squared_error: 9758918953700056.0000\n",
            "Epoch 1002/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 9006605225681301.0000 - mean_squared_error: 9006605225681301.0000 - val_loss: 9736886214314250.0000 - val_mean_squared_error: 9736886214314250.0000\n",
            "Epoch 1003/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8985515002155801.0000 - mean_squared_error: 8985515002155801.0000 - val_loss: 9714650052416668.0000 - val_mean_squared_error: 9714650052416668.0000\n",
            "Epoch 1004/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8964511277115047.0000 - mean_squared_error: 8964511277115047.0000 - val_loss: 9692607703951488.0000 - val_mean_squared_error: 9692607703951488.0000\n",
            "Epoch 1005/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8943760022644785.0000 - mean_squared_error: 8943760022644785.0000 - val_loss: 9670482465044028.0000 - val_mean_squared_error: 9670482465044028.0000\n",
            "Epoch 1006/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8922821911278743.0000 - mean_squared_error: 8922821911278743.0000 - val_loss: 9648371257576338.0000 - val_mean_squared_error: 9648371257576338.0000\n",
            "Epoch 1007/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8901865083089169.0000 - mean_squared_error: 8901865083089169.0000 - val_loss: 9626234152911774.0000 - val_mean_squared_error: 9626234152911774.0000\n",
            "Epoch 1008/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8881056488223665.0000 - mean_squared_error: 8881056488223665.0000 - val_loss: 9604280093929680.0000 - val_mean_squared_error: 9604280093929680.0000\n",
            "Epoch 1009/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8860278855698423.0000 - mean_squared_error: 8860278855698423.0000 - val_loss: 9582089265775888.0000 - val_mean_squared_error: 9582089265775888.0000\n",
            "Epoch 1010/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8839262106032659.0000 - mean_squared_error: 8839262106032659.0000 - val_loss: 9560099718716560.0000 - val_mean_squared_error: 9560099718716560.0000\n",
            "Epoch 1011/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8818565268403167.0000 - mean_squared_error: 8818565268403167.0000 - val_loss: 9537978883970482.0000 - val_mean_squared_error: 9537978883970482.0000\n",
            "Epoch 1012/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8797622338108119.0000 - mean_squared_error: 8797622338108119.0000 - val_loss: 9515973279314498.0000 - val_mean_squared_error: 9515973279314498.0000\n",
            "Epoch 1013/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8776622998399071.0000 - mean_squared_error: 8776622998399071.0000 - val_loss: 9493822337332982.0000 - val_mean_squared_error: 9493822337332982.0000\n",
            "Epoch 1014/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8755754224632712.0000 - mean_squared_error: 8755754224632712.0000 - val_loss: 9471817751821780.0000 - val_mean_squared_error: 9471817751821780.0000\n",
            "Epoch 1015/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8734950986326491.0000 - mean_squared_error: 8734950986326491.0000 - val_loss: 9449727121372548.0000 - val_mean_squared_error: 9449727121372548.0000\n",
            "Epoch 1016/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8714240779320370.0000 - mean_squared_error: 8714240779320370.0000 - val_loss: 9427646227395786.0000 - val_mean_squared_error: 9427646227395786.0000\n",
            "Epoch 1017/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8693234282598104.0000 - mean_squared_error: 8693234282598104.0000 - val_loss: 9405606220537070.0000 - val_mean_squared_error: 9405606220537070.0000\n",
            "Epoch 1018/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8672399944506593.0000 - mean_squared_error: 8672399944506593.0000 - val_loss: 9383522129600188.0000 - val_mean_squared_error: 9383522129600188.0000\n",
            "Epoch 1019/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8651588773116329.0000 - mean_squared_error: 8651588773116329.0000 - val_loss: 9361542434273754.0000 - val_mean_squared_error: 9361542434273754.0000\n",
            "Epoch 1020/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8630774221793352.0000 - mean_squared_error: 8630774221793352.0000 - val_loss: 9339597183614420.0000 - val_mean_squared_error: 9339597183614420.0000\n",
            "Epoch 1021/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8610073090715295.0000 - mean_squared_error: 8610073090715295.0000 - val_loss: 9317507754300110.0000 - val_mean_squared_error: 9317507754300110.0000\n",
            "Epoch 1022/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8589286995069382.0000 - mean_squared_error: 8589286995069382.0000 - val_loss: 9295527039828894.0000 - val_mean_squared_error: 9295527039828894.0000\n",
            "Epoch 1023/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8568394459259773.0000 - mean_squared_error: 8568394459259773.0000 - val_loss: 9273528029282304.0000 - val_mean_squared_error: 9273528029282304.0000\n",
            "Epoch 1024/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8547697610999173.0000 - mean_squared_error: 8547697610999173.0000 - val_loss: 9251652875158430.0000 - val_mean_squared_error: 9251652875158430.0000\n",
            "Epoch 1025/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8527014413080179.0000 - mean_squared_error: 8527014413080179.0000 - val_loss: 9229590453180844.0000 - val_mean_squared_error: 9229590453180844.0000\n",
            "Epoch 1026/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8506164249826282.0000 - mean_squared_error: 8506164249826282.0000 - val_loss: 9207682983674504.0000 - val_mean_squared_error: 9207682983674504.0000\n",
            "Epoch 1027/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8485415363814824.0000 - mean_squared_error: 8485415363814824.0000 - val_loss: 9185705575357492.0000 - val_mean_squared_error: 9185705575357492.0000\n",
            "Epoch 1028/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8464818575155212.0000 - mean_squared_error: 8464818575155212.0000 - val_loss: 9163903660132156.0000 - val_mean_squared_error: 9163903660132156.0000\n",
            "Epoch 1029/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8444231585338949.0000 - mean_squared_error: 8444231585338949.0000 - val_loss: 9141846691792422.0000 - val_mean_squared_error: 9141846691792422.0000\n",
            "Epoch 1030/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8423429027423587.0000 - mean_squared_error: 8423429027423587.0000 - val_loss: 9119967339762660.0000 - val_mean_squared_error: 9119967339762660.0000\n",
            "Epoch 1031/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8402537883529650.0000 - mean_squared_error: 8402537883529650.0000 - val_loss: 9097964179840886.0000 - val_mean_squared_error: 9097964179840886.0000\n",
            "Epoch 1032/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8381919381213328.0000 - mean_squared_error: 8381919381213328.0000 - val_loss: 9076022423392232.0000 - val_mean_squared_error: 9076022423392232.0000\n",
            "Epoch 1033/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8361312179763927.0000 - mean_squared_error: 8361312179763927.0000 - val_loss: 9054159250285886.0000 - val_mean_squared_error: 9054159250285886.0000\n",
            "Epoch 1034/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8340435289906609.0000 - mean_squared_error: 8340435289906609.0000 - val_loss: 9032197098808916.0000 - val_mean_squared_error: 9032197098808916.0000\n",
            "Epoch 1035/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8319821652840546.0000 - mean_squared_error: 8319821652840546.0000 - val_loss: 9010378106842140.0000 - val_mean_squared_error: 9010378106842140.0000\n",
            "Epoch 1036/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8299241963937131.0000 - mean_squared_error: 8299241963937131.0000 - val_loss: 8988529025838941.0000 - val_mean_squared_error: 8988529025838941.0000\n",
            "Epoch 1037/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8278523559588020.0000 - mean_squared_error: 8278523559588020.0000 - val_loss: 8966649843666643.0000 - val_mean_squared_error: 8966649843666643.0000\n",
            "Epoch 1038/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8257948886289094.0000 - mean_squared_error: 8257948886289094.0000 - val_loss: 8944688784130511.0000 - val_mean_squared_error: 8944688784130511.0000\n",
            "Epoch 1039/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8237127221236691.0000 - mean_squared_error: 8237127221236691.0000 - val_loss: 8922892565196545.0000 - val_mean_squared_error: 8922892565196545.0000\n",
            "Epoch 1040/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8216638243773919.0000 - mean_squared_error: 8216638243773919.0000 - val_loss: 8901017665858867.0000 - val_mean_squared_error: 8901017665858867.0000\n",
            "Epoch 1041/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8196012754542094.0000 - mean_squared_error: 8196012754542094.0000 - val_loss: 8879150889347755.0000 - val_mean_squared_error: 8879150889347755.0000\n",
            "Epoch 1042/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8175466718408420.0000 - mean_squared_error: 8175466718408420.0000 - val_loss: 8857304586727355.0000 - val_mean_squared_error: 8857304586727355.0000\n",
            "Epoch 1043/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8154854732201427.0000 - mean_squared_error: 8154854732201427.0000 - val_loss: 8835589650656100.0000 - val_mean_squared_error: 8835589650656100.0000\n",
            "Epoch 1044/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8134297017796530.0000 - mean_squared_error: 8134297017796530.0000 - val_loss: 8813702479116669.0000 - val_mean_squared_error: 8813702479116669.0000\n",
            "Epoch 1045/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8113803479588783.0000 - mean_squared_error: 8113803479588783.0000 - val_loss: 8791832548109804.0000 - val_mean_squared_error: 8791832548109804.0000\n",
            "Epoch 1046/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8093056211973550.0000 - mean_squared_error: 8093056211973550.0000 - val_loss: 8770424987318099.0000 - val_mean_squared_error: 8770424987318099.0000\n",
            "Epoch 1047/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8072776552468069.0000 - mean_squared_error: 8072776552468069.0000 - val_loss: 8748588469700875.0000 - val_mean_squared_error: 8748588469700875.0000\n",
            "Epoch 1048/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8052172689945682.0000 - mean_squared_error: 8052172689945682.0000 - val_loss: 8726705690190148.0000 - val_mean_squared_error: 8726705690190148.0000\n",
            "Epoch 1049/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8031555360847973.0000 - mean_squared_error: 8031555360847973.0000 - val_loss: 8704986040574276.0000 - val_mean_squared_error: 8704986040574276.0000\n",
            "Epoch 1050/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 8011268738916502.0000 - mean_squared_error: 8011268738916502.0000 - val_loss: 8685044810735847.0000 - val_mean_squared_error: 8685044810735847.0000\n",
            "Epoch 1051/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7992252143218775.0000 - mean_squared_error: 7992252143218775.0000 - val_loss: 8663177191003755.0000 - val_mean_squared_error: 8663177191003755.0000\n",
            "Epoch 1052/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7971705192809884.0000 - mean_squared_error: 7971705192809884.0000 - val_loss: 8641378951979239.0000 - val_mean_squared_error: 8641378951979239.0000\n",
            "Epoch 1053/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7951295352549509.0000 - mean_squared_error: 7951295352549509.0000 - val_loss: 8619762132858613.0000 - val_mean_squared_error: 8619762132858613.0000\n",
            "Epoch 1054/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7930777486571738.0000 - mean_squared_error: 7930777486571738.0000 - val_loss: 8598134054614681.0000 - val_mean_squared_error: 8598134054614681.0000\n",
            "Epoch 1055/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7910309005883587.0000 - mean_squared_error: 7910309005883587.0000 - val_loss: 8576317070605781.0000 - val_mean_squared_error: 8576317070605781.0000\n",
            "Epoch 1056/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7889824961254540.0000 - mean_squared_error: 7889824961254540.0000 - val_loss: 8554617925212309.0000 - val_mean_squared_error: 8554617925212309.0000\n",
            "Epoch 1057/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7869287985861633.0000 - mean_squared_error: 7869287985861633.0000 - val_loss: 8532939326505608.0000 - val_mean_squared_error: 8532939326505608.0000\n",
            "Epoch 1058/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7848964245419484.0000 - mean_squared_error: 7848964245419484.0000 - val_loss: 8511254297480637.0000 - val_mean_squared_error: 8511254297480637.0000\n",
            "Epoch 1059/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7828519545758704.0000 - mean_squared_error: 7828519545758704.0000 - val_loss: 8489571907312692.0000 - val_mean_squared_error: 8489571907312692.0000\n",
            "Epoch 1060/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7808004083929881.0000 - mean_squared_error: 7808004083929881.0000 - val_loss: 8467855108875675.0000 - val_mean_squared_error: 8467855108875675.0000\n",
            "Epoch 1061/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7787677807209309.0000 - mean_squared_error: 7787677807209309.0000 - val_loss: 8446204554849493.0000 - val_mean_squared_error: 8446204554849493.0000\n",
            "Epoch 1062/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7767413179424918.0000 - mean_squared_error: 7767413179424918.0000 - val_loss: 8425188564042283.0000 - val_mean_squared_error: 8425188564042283.0000\n",
            "Epoch 1063/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7747539882885235.0000 - mean_squared_error: 7747539882885235.0000 - val_loss: 8403398666232501.0000 - val_mean_squared_error: 8403398666232501.0000\n",
            "Epoch 1064/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7727139489882310.0000 - mean_squared_error: 7727139489882310.0000 - val_loss: 8381821884942603.0000 - val_mean_squared_error: 8381821884942603.0000\n",
            "Epoch 1065/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7706653097297308.0000 - mean_squared_error: 7706653097297308.0000 - val_loss: 8360521740797663.0000 - val_mean_squared_error: 8360521740797663.0000\n",
            "Epoch 1066/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7686705276981138.0000 - mean_squared_error: 7686705276981138.0000 - val_loss: 8338915974544853.0000 - val_mean_squared_error: 8338915974544853.0000\n",
            "Epoch 1067/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7666249891918606.0000 - mean_squared_error: 7666249891918606.0000 - val_loss: 8317236484086467.0000 - val_mean_squared_error: 8317236484086467.0000\n",
            "Epoch 1068/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7645798383033684.0000 - mean_squared_error: 7645798383033684.0000 - val_loss: 8295654406883501.0000 - val_mean_squared_error: 8295654406883501.0000\n",
            "Epoch 1069/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7625538039680404.0000 - mean_squared_error: 7625538039680404.0000 - val_loss: 8274130463397483.0000 - val_mean_squared_error: 8274130463397483.0000\n",
            "Epoch 1070/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7605165447022722.0000 - mean_squared_error: 7605165447022722.0000 - val_loss: 8252501632927640.0000 - val_mean_squared_error: 8252501632927640.0000\n",
            "Epoch 1071/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7584841819725928.0000 - mean_squared_error: 7584841819725928.0000 - val_loss: 8230952993379669.0000 - val_mean_squared_error: 8230952993379669.0000\n",
            "Epoch 1072/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7564593402196796.0000 - mean_squared_error: 7564593402196796.0000 - val_loss: 8209619114329175.0000 - val_mean_squared_error: 8209619114329175.0000\n",
            "Epoch 1073/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7544590543499767.0000 - mean_squared_error: 7544590543499767.0000 - val_loss: 8188156665311348.0000 - val_mean_squared_error: 8188156665311348.0000\n",
            "Epoch 1074/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7524244236254560.0000 - mean_squared_error: 7524244236254560.0000 - val_loss: 8166561824533255.0000 - val_mean_squared_error: 8166561824533255.0000\n",
            "Epoch 1075/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7503940877163582.0000 - mean_squared_error: 7503940877163582.0000 - val_loss: 8145021332077204.0000 - val_mean_squared_error: 8145021332077204.0000\n",
            "Epoch 1076/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7483869009671830.0000 - mean_squared_error: 7483869009671830.0000 - val_loss: 8123547096164664.0000 - val_mean_squared_error: 8123547096164664.0000\n",
            "Epoch 1077/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7463639375030970.0000 - mean_squared_error: 7463639375030970.0000 - val_loss: 8102129895961895.0000 - val_mean_squared_error: 8102129895961895.0000\n",
            "Epoch 1078/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7443294236448185.0000 - mean_squared_error: 7443294236448185.0000 - val_loss: 8080628258400661.0000 - val_mean_squared_error: 8080628258400661.0000\n",
            "Epoch 1079/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7423199974529183.0000 - mean_squared_error: 7423199974529183.0000 - val_loss: 8059211100662259.0000 - val_mean_squared_error: 8059211100662259.0000\n",
            "Epoch 1080/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7403010970840873.0000 - mean_squared_error: 7403010970840873.0000 - val_loss: 8037812748571619.0000 - val_mean_squared_error: 8037812748571619.0000\n",
            "Epoch 1081/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7382782483220541.0000 - mean_squared_error: 7382782483220541.0000 - val_loss: 8016262750163939.0000 - val_mean_squared_error: 8016262750163939.0000\n",
            "Epoch 1082/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7362756224697270.0000 - mean_squared_error: 7362756224697270.0000 - val_loss: 7994972682206399.0000 - val_mean_squared_error: 7994972682206399.0000\n",
            "Epoch 1083/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7342497538277979.0000 - mean_squared_error: 7342497538277979.0000 - val_loss: 7973578164041369.0000 - val_mean_squared_error: 7973578164041369.0000\n",
            "Epoch 1084/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7322576971184716.0000 - mean_squared_error: 7322576971184716.0000 - val_loss: 7952364052701787.0000 - val_mean_squared_error: 7952364052701787.0000\n",
            "Epoch 1085/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7302662493437766.0000 - mean_squared_error: 7302662493437766.0000 - val_loss: 7930916948485901.0000 - val_mean_squared_error: 7930916948485901.0000\n",
            "Epoch 1086/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7282493231335786.0000 - mean_squared_error: 7282493231335786.0000 - val_loss: 7909550532631604.0000 - val_mean_squared_error: 7909550532631604.0000\n",
            "Epoch 1087/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7262188602586866.0000 - mean_squared_error: 7262188602586866.0000 - val_loss: 7888205148771115.0000 - val_mean_squared_error: 7888205148771115.0000\n",
            "Epoch 1088/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7242291898532374.0000 - mean_squared_error: 7242291898532374.0000 - val_loss: 7866881279178301.0000 - val_mean_squared_error: 7866881279178301.0000\n",
            "Epoch 1089/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7222236629236370.0000 - mean_squared_error: 7222236629236370.0000 - val_loss: 7845482657135621.0000 - val_mean_squared_error: 7845482657135621.0000\n",
            "Epoch 1090/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7202077191796142.0000 - mean_squared_error: 7202077191796142.0000 - val_loss: 7824220194049099.0000 - val_mean_squared_error: 7824220194049099.0000\n",
            "Epoch 1091/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7182262739858445.0000 - mean_squared_error: 7182262739858445.0000 - val_loss: 7802870581951031.0000 - val_mean_squared_error: 7802870581951031.0000\n",
            "Epoch 1092/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7162134552557738.0000 - mean_squared_error: 7162134552557738.0000 - val_loss: 7781559782283413.0000 - val_mean_squared_error: 7781559782283413.0000\n",
            "Epoch 1093/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7142024439657948.0000 - mean_squared_error: 7142024439657948.0000 - val_loss: 7760379727365299.0000 - val_mean_squared_error: 7760379727365299.0000\n",
            "Epoch 1094/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7122158233212462.0000 - mean_squared_error: 7122158233212462.0000 - val_loss: 7739058178146767.0000 - val_mean_squared_error: 7739058178146767.0000\n",
            "Epoch 1095/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7102284308962853.0000 - mean_squared_error: 7102284308962853.0000 - val_loss: 7717976631458081.0000 - val_mean_squared_error: 7717976631458081.0000\n",
            "Epoch 1096/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7082357111475859.0000 - mean_squared_error: 7082357111475859.0000 - val_loss: 7696627680590853.0000 - val_mean_squared_error: 7696627680590853.0000\n",
            "Epoch 1097/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7062488653513747.0000 - mean_squared_error: 7062488653513747.0000 - val_loss: 7675421925631851.0000 - val_mean_squared_error: 7675421925631851.0000\n",
            "Epoch 1098/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7042452596147126.0000 - mean_squared_error: 7042452596147126.0000 - val_loss: 7654294747948813.0000 - val_mean_squared_error: 7654294747948813.0000\n",
            "Epoch 1099/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7022778033443262.0000 - mean_squared_error: 7022778033443262.0000 - val_loss: 7633449579153027.0000 - val_mean_squared_error: 7633449579153027.0000\n",
            "Epoch 1100/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 7003033289105744.0000 - mean_squared_error: 7003033289105744.0000 - val_loss: 7612149680694775.0000 - val_mean_squared_error: 7612149680694775.0000\n",
            "Epoch 1101/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6982995277893499.0000 - mean_squared_error: 6982995277893499.0000 - val_loss: 7591010212610973.0000 - val_mean_squared_error: 7591010212610973.0000\n",
            "Epoch 1102/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6963227434628040.0000 - mean_squared_error: 6963227434628040.0000 - val_loss: 7570008492863881.0000 - val_mean_squared_error: 7570008492863881.0000\n",
            "Epoch 1103/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6943455278929894.0000 - mean_squared_error: 6943455278929894.0000 - val_loss: 7548807163298440.0000 - val_mean_squared_error: 7548807163298440.0000\n",
            "Epoch 1104/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6923440727533709.0000 - mean_squared_error: 6923440727533709.0000 - val_loss: 7527641916311355.0000 - val_mean_squared_error: 7527641916311355.0000\n",
            "Epoch 1105/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6903830279708290.0000 - mean_squared_error: 6903830279708290.0000 - val_loss: 7506536389388600.0000 - val_mean_squared_error: 7506536389388600.0000\n",
            "Epoch 1106/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6883950857277863.0000 - mean_squared_error: 6883950857277863.0000 - val_loss: 7485557949213540.0000 - val_mean_squared_error: 7485557949213540.0000\n",
            "Epoch 1107/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6864223526504046.0000 - mean_squared_error: 6864223526504046.0000 - val_loss: 7464476705841755.0000 - val_mean_squared_error: 7464476705841755.0000\n",
            "Epoch 1108/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6844415622568999.0000 - mean_squared_error: 6844415622568999.0000 - val_loss: 7443320710020101.0000 - val_mean_squared_error: 7443320710020101.0000\n",
            "Epoch 1109/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6824760048731109.0000 - mean_squared_error: 6824760048731109.0000 - val_loss: 7422321350078487.0000 - val_mean_squared_error: 7422321350078487.0000\n",
            "Epoch 1110/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6804908088728592.0000 - mean_squared_error: 6804908088728592.0000 - val_loss: 7401351093393373.0000 - val_mean_squared_error: 7401351093393373.0000\n",
            "Epoch 1111/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6785416170154450.0000 - mean_squared_error: 6785416170154450.0000 - val_loss: 7382866221448568.0000 - val_mean_squared_error: 7382866221448568.0000\n",
            "Epoch 1112/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6767809361781489.0000 - mean_squared_error: 6767809361781489.0000 - val_loss: 7361893338039105.0000 - val_mean_squared_error: 7361893338039105.0000\n",
            "Epoch 1113/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6748123476378967.0000 - mean_squared_error: 6748123476378967.0000 - val_loss: 7340803098288083.0000 - val_mean_squared_error: 7340803098288083.0000\n",
            "Epoch 1114/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6728463321293251.0000 - mean_squared_error: 6728463321293251.0000 - val_loss: 7319828049195957.0000 - val_mean_squared_error: 7319828049195957.0000\n",
            "Epoch 1115/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6708826621467409.0000 - mean_squared_error: 6708826621467409.0000 - val_loss: 7299003681873133.0000 - val_mean_squared_error: 7299003681873133.0000\n",
            "Epoch 1116/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6689203931922084.0000 - mean_squared_error: 6689203931922084.0000 - val_loss: 7278023864639349.0000 - val_mean_squared_error: 7278023864639349.0000\n",
            "Epoch 1117/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6669534983012329.0000 - mean_squared_error: 6669534983012329.0000 - val_loss: 7257158676928200.0000 - val_mean_squared_error: 7257158676928200.0000\n",
            "Epoch 1118/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6650052875811057.0000 - mean_squared_error: 6650052875811057.0000 - val_loss: 7236174036955715.0000 - val_mean_squared_error: 7236174036955715.0000\n",
            "Epoch 1119/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6630295950312977.0000 - mean_squared_error: 6630295950312977.0000 - val_loss: 7215281426363687.0000 - val_mean_squared_error: 7215281426363687.0000\n",
            "Epoch 1120/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6610819727049839.0000 - mean_squared_error: 6610819727049839.0000 - val_loss: 7194402346738543.0000 - val_mean_squared_error: 7194402346738543.0000\n",
            "Epoch 1121/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6591297711051939.0000 - mean_squared_error: 6591297711051939.0000 - val_loss: 7173520006456731.0000 - val_mean_squared_error: 7173520006456731.0000\n",
            "Epoch 1122/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6571775468763331.0000 - mean_squared_error: 6571775468763331.0000 - val_loss: 7152687219056779.0000 - val_mean_squared_error: 7152687219056779.0000\n",
            "Epoch 1123/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6552279009947062.0000 - mean_squared_error: 6552279009947062.0000 - val_loss: 7131814639512789.0000 - val_mean_squared_error: 7131814639512789.0000\n",
            "Epoch 1124/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6532818965710306.0000 - mean_squared_error: 6532818965710306.0000 - val_loss: 7111075567935257.0000 - val_mean_squared_error: 7111075567935257.0000\n",
            "Epoch 1125/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6513304537285466.0000 - mean_squared_error: 6513304537285466.0000 - val_loss: 7090345686859776.0000 - val_mean_squared_error: 7090345686859776.0000\n",
            "Epoch 1126/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6493692540355858.0000 - mean_squared_error: 6493692540355858.0000 - val_loss: 7069468330074621.0000 - val_mean_squared_error: 7069468330074621.0000\n",
            "Epoch 1127/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6474213806632699.0000 - mean_squared_error: 6474213806632699.0000 - val_loss: 7048784252884124.0000 - val_mean_squared_error: 7048784252884124.0000\n",
            "Epoch 1128/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6454965414830462.0000 - mean_squared_error: 6454965414830462.0000 - val_loss: 7027960201010876.0000 - val_mean_squared_error: 7027960201010876.0000\n",
            "Epoch 1129/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6435370749642998.0000 - mean_squared_error: 6435370749642998.0000 - val_loss: 7007246046916631.0000 - val_mean_squared_error: 7007246046916631.0000\n",
            "Epoch 1130/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6416148281795591.0000 - mean_squared_error: 6416148281795591.0000 - val_loss: 6986567905637856.0000 - val_mean_squared_error: 6986567905637856.0000\n",
            "Epoch 1131/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6396657951812607.0000 - mean_squared_error: 6396657951812607.0000 - val_loss: 6965897893251987.0000 - val_mean_squared_error: 6965897893251987.0000\n",
            "Epoch 1132/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6377453893625674.0000 - mean_squared_error: 6377453893625674.0000 - val_loss: 6945251539584272.0000 - val_mean_squared_error: 6945251539584272.0000\n",
            "Epoch 1133/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6358008410588596.0000 - mean_squared_error: 6358008410588596.0000 - val_loss: 6924524533952997.0000 - val_mean_squared_error: 6924524533952997.0000\n",
            "Epoch 1134/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6338587630827436.0000 - mean_squared_error: 6338587630827436.0000 - val_loss: 6903894923378133.0000 - val_mean_squared_error: 6903894923378133.0000\n",
            "Epoch 1135/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6319303354862000.0000 - mean_squared_error: 6319303354862000.0000 - val_loss: 6883368719600623.0000 - val_mean_squared_error: 6883368719600623.0000\n",
            "Epoch 1136/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6300026423472887.0000 - mean_squared_error: 6300026423472887.0000 - val_loss: 6862704182084787.0000 - val_mean_squared_error: 6862704182084787.0000\n",
            "Epoch 1137/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6280949478776589.0000 - mean_squared_error: 6280949478776589.0000 - val_loss: 6842119304686251.0000 - val_mean_squared_error: 6842119304686251.0000\n",
            "Epoch 1138/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6261299410333482.0000 - mean_squared_error: 6261299410333482.0000 - val_loss: 6821504923652907.0000 - val_mean_squared_error: 6821504923652907.0000\n",
            "Epoch 1139/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6242264753144039.0000 - mean_squared_error: 6242264753144039.0000 - val_loss: 6800921714497316.0000 - val_mean_squared_error: 6800921714497316.0000\n",
            "Epoch 1140/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6223039186328893.0000 - mean_squared_error: 6223039186328893.0000 - val_loss: 6780417628588113.0000 - val_mean_squared_error: 6780417628588113.0000\n",
            "Epoch 1141/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6203969776809483.0000 - mean_squared_error: 6203969776809483.0000 - val_loss: 6759882941036925.0000 - val_mean_squared_error: 6759882941036925.0000\n",
            "Epoch 1142/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6184683940729069.0000 - mean_squared_error: 6184683940729069.0000 - val_loss: 6739353640393873.0000 - val_mean_squared_error: 6739353640393873.0000\n",
            "Epoch 1143/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6165346233198688.0000 - mean_squared_error: 6165346233198688.0000 - val_loss: 6718842672224221.0000 - val_mean_squared_error: 6718842672224221.0000\n",
            "Epoch 1144/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6146268115283777.0000 - mean_squared_error: 6146268115283777.0000 - val_loss: 6698502331943179.0000 - val_mean_squared_error: 6698502331943179.0000\n",
            "Epoch 1145/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6127308784424493.0000 - mean_squared_error: 6127308784424493.0000 - val_loss: 6678079119418871.0000 - val_mean_squared_error: 6678079119418871.0000\n",
            "Epoch 1146/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6108175369185329.0000 - mean_squared_error: 6108175369185329.0000 - val_loss: 6657541356234324.0000 - val_mean_squared_error: 6657541356234324.0000\n",
            "Epoch 1147/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6089049358891990.0000 - mean_squared_error: 6089049358891990.0000 - val_loss: 6637307613644419.0000 - val_mean_squared_error: 6637307613644419.0000\n",
            "Epoch 1148/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6070082945057556.0000 - mean_squared_error: 6070082945057556.0000 - val_loss: 6616842552487496.0000 - val_mean_squared_error: 6616842552487496.0000\n",
            "Epoch 1149/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6051043874439909.0000 - mean_squared_error: 6051043874439909.0000 - val_loss: 6596523802303355.0000 - val_mean_squared_error: 6596523802303355.0000\n",
            "Epoch 1150/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6031950473549080.0000 - mean_squared_error: 6031950473549080.0000 - val_loss: 6576055553285820.0000 - val_mean_squared_error: 6576055553285820.0000\n",
            "Epoch 1151/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 6013106903676705.0000 - mean_squared_error: 6013106903676705.0000 - val_loss: 6561360019365657.0000 - val_mean_squared_error: 6561360019365657.0000\n",
            "Epoch 1152/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5999257068587208.0000 - mean_squared_error: 5999257068587208.0000 - val_loss: 6541221418187597.0000 - val_mean_squared_error: 6541221418187597.0000\n",
            "Epoch 1153/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5980414796848955.0000 - mean_squared_error: 5980414796848955.0000 - val_loss: 6520921625309669.0000 - val_mean_squared_error: 6520921625309669.0000\n",
            "Epoch 1154/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5961368347863251.0000 - mean_squared_error: 5961368347863251.0000 - val_loss: 6500610615772803.0000 - val_mean_squared_error: 6500610615772803.0000\n",
            "Epoch 1155/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5942406764348296.0000 - mean_squared_error: 5942406764348296.0000 - val_loss: 6480258161014796.0000 - val_mean_squared_error: 6480258161014796.0000\n",
            "Epoch 1156/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5923528361653284.0000 - mean_squared_error: 5923528361653284.0000 - val_loss: 6460023575203909.0000 - val_mean_squared_error: 6460023575203909.0000\n",
            "Epoch 1157/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5904456125398414.0000 - mean_squared_error: 5904456125398414.0000 - val_loss: 6439980628043255.0000 - val_mean_squared_error: 6439980628043255.0000\n",
            "Epoch 1158/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5885762311756214.0000 - mean_squared_error: 5885762311756214.0000 - val_loss: 6419664319560155.0000 - val_mean_squared_error: 6419664319560155.0000\n",
            "Epoch 1159/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5867151936358623.0000 - mean_squared_error: 5867151936358623.0000 - val_loss: 6399575128705012.0000 - val_mean_squared_error: 6399575128705012.0000\n",
            "Epoch 1160/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5848172931116795.0000 - mean_squared_error: 5848172931116795.0000 - val_loss: 6379341213224475.0000 - val_mean_squared_error: 6379341213224475.0000\n",
            "Epoch 1161/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5829099130950125.0000 - mean_squared_error: 5829099130950125.0000 - val_loss: 6359189654348469.0000 - val_mean_squared_error: 6359189654348469.0000\n",
            "Epoch 1162/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5810599763675173.0000 - mean_squared_error: 5810599763675173.0000 - val_loss: 6339070407821763.0000 - val_mean_squared_error: 6339070407821763.0000\n",
            "Epoch 1163/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5791837593912293.0000 - mean_squared_error: 5791837593912293.0000 - val_loss: 6318957139671144.0000 - val_mean_squared_error: 6318957139671144.0000\n",
            "Epoch 1164/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5773012848693254.0000 - mean_squared_error: 5773012848693254.0000 - val_loss: 6298881576844293.0000 - val_mean_squared_error: 6298881576844293.0000\n",
            "Epoch 1165/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5754374743951027.0000 - mean_squared_error: 5754374743951027.0000 - val_loss: 6279008311223523.0000 - val_mean_squared_error: 6279008311223523.0000\n",
            "Epoch 1166/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5735629844042058.0000 - mean_squared_error: 5735629844042058.0000 - val_loss: 6258983332555989.0000 - val_mean_squared_error: 6258983332555989.0000\n",
            "Epoch 1167/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5717158181812070.0000 - mean_squared_error: 5717158181812070.0000 - val_loss: 6238857252299539.0000 - val_mean_squared_error: 6238857252299539.0000\n",
            "Epoch 1168/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5698367002795186.0000 - mean_squared_error: 5698367002795186.0000 - val_loss: 6218887225554677.0000 - val_mean_squared_error: 6218887225554677.0000\n",
            "Epoch 1169/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5679873070673775.0000 - mean_squared_error: 5679873070673775.0000 - val_loss: 6199028085401912.0000 - val_mean_squared_error: 6199028085401912.0000\n",
            "Epoch 1170/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5661233790055159.0000 - mean_squared_error: 5661233790055159.0000 - val_loss: 6180804196416888.0000 - val_mean_squared_error: 6180804196416888.0000\n",
            "Epoch 1171/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5644140439858754.0000 - mean_squared_error: 5644140439858754.0000 - val_loss: 6160739589396445.0000 - val_mean_squared_error: 6160739589396445.0000\n",
            "Epoch 1172/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5625634589886525.0000 - mean_squared_error: 5625634589886525.0000 - val_loss: 6140776660267031.0000 - val_mean_squared_error: 6140776660267031.0000\n",
            "Epoch 1173/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5607162700986145.0000 - mean_squared_error: 5607162700986145.0000 - val_loss: 6120889675622899.0000 - val_mean_squared_error: 6120889675622899.0000\n",
            "Epoch 1174/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5588291206232699.0000 - mean_squared_error: 5588291206232699.0000 - val_loss: 6100988702003363.0000 - val_mean_squared_error: 6100988702003363.0000\n",
            "Epoch 1175/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5569874814749196.0000 - mean_squared_error: 5569874814749196.0000 - val_loss: 6081182454251520.0000 - val_mean_squared_error: 6081182454251520.0000\n",
            "Epoch 1176/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5551583919688992.0000 - mean_squared_error: 5551583919688992.0000 - val_loss: 6061303079828393.0000 - val_mean_squared_error: 6061303079828393.0000\n",
            "Epoch 1177/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5532992961249280.0000 - mean_squared_error: 5532992961249280.0000 - val_loss: 6041522708041243.0000 - val_mean_squared_error: 6041522708041243.0000\n",
            "Epoch 1178/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5514514824675027.0000 - mean_squared_error: 5514514824675027.0000 - val_loss: 6021734368119143.0000 - val_mean_squared_error: 6021734368119143.0000\n",
            "Epoch 1179/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5496171068712522.0000 - mean_squared_error: 5496171068712522.0000 - val_loss: 6002014859901032.0000 - val_mean_squared_error: 6002014859901032.0000\n",
            "Epoch 1180/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5477695868222260.0000 - mean_squared_error: 5477695868222260.0000 - val_loss: 5982134533062841.0000 - val_mean_squared_error: 5982134533062841.0000\n",
            "Epoch 1181/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5459396181995793.0000 - mean_squared_error: 5459396181995793.0000 - val_loss: 5962448990271129.0000 - val_mean_squared_error: 5962448990271129.0000\n",
            "Epoch 1182/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5441024874759697.0000 - mean_squared_error: 5441024874759697.0000 - val_loss: 5942712942182493.0000 - val_mean_squared_error: 5942712942182493.0000\n",
            "Epoch 1183/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5422672724399036.0000 - mean_squared_error: 5422672724399036.0000 - val_loss: 5923202379876896.0000 - val_mean_squared_error: 5923202379876896.0000\n",
            "Epoch 1184/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5404560919071777.0000 - mean_squared_error: 5404560919071777.0000 - val_loss: 5903435172043180.0000 - val_mean_squared_error: 5903435172043180.0000\n",
            "Epoch 1185/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5386094297125635.0000 - mean_squared_error: 5386094297125635.0000 - val_loss: 5883857400779007.0000 - val_mean_squared_error: 5883857400779007.0000\n",
            "Epoch 1186/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5367949181122476.0000 - mean_squared_error: 5367949181122476.0000 - val_loss: 5864246828825328.0000 - val_mean_squared_error: 5864246828825328.0000\n",
            "Epoch 1187/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5349798381273806.0000 - mean_squared_error: 5349798381273806.0000 - val_loss: 5844605594566286.0000 - val_mean_squared_error: 5844605594566286.0000\n",
            "Epoch 1188/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5331528037662489.0000 - mean_squared_error: 5331528037662489.0000 - val_loss: 5824989189828631.0000 - val_mean_squared_error: 5824989189828631.0000\n",
            "Epoch 1189/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5313229169271908.0000 - mean_squared_error: 5313229169271908.0000 - val_loss: 5805522929989366.0000 - val_mean_squared_error: 5805522929989366.0000\n",
            "Epoch 1190/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5295187163238127.0000 - mean_squared_error: 5295187163238127.0000 - val_loss: 5785979736851728.0000 - val_mean_squared_error: 5785979736851728.0000\n",
            "Epoch 1191/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5277155972837162.0000 - mean_squared_error: 5277155972837162.0000 - val_loss: 5766411319880733.0000 - val_mean_squared_error: 5766411319880733.0000\n",
            "Epoch 1192/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5258807954560048.0000 - mean_squared_error: 5258807954560048.0000 - val_loss: 5746923057433583.0000 - val_mean_squared_error: 5746923057433583.0000\n",
            "Epoch 1193/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5240729082504385.0000 - mean_squared_error: 5240729082504385.0000 - val_loss: 5727445071362985.0000 - val_mean_squared_error: 5727445071362985.0000\n",
            "Epoch 1194/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5222764054419198.0000 - mean_squared_error: 5222764054419198.0000 - val_loss: 5707978414178582.0000 - val_mean_squared_error: 5707978414178582.0000\n",
            "Epoch 1195/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5204537754962815.0000 - mean_squared_error: 5204537754962815.0000 - val_loss: 5689626640722418.0000 - val_mean_squared_error: 5689626640722418.0000\n",
            "Epoch 1196/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5187572662572335.0000 - mean_squared_error: 5187572662572335.0000 - val_loss: 5670283867259250.0000 - val_mean_squared_error: 5670283867259250.0000\n",
            "Epoch 1197/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5169607960064805.0000 - mean_squared_error: 5169607960064805.0000 - val_loss: 5650854430091576.0000 - val_mean_squared_error: 5650854430091576.0000\n",
            "Epoch 1198/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5151494627654939.0000 - mean_squared_error: 5151494627654939.0000 - val_loss: 5631446579987635.0000 - val_mean_squared_error: 5631446579987635.0000\n",
            "Epoch 1199/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5133553634224965.0000 - mean_squared_error: 5133553634224965.0000 - val_loss: 5612133959257441.0000 - val_mean_squared_error: 5612133959257441.0000\n",
            "Epoch 1200/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5115610211966686.0000 - mean_squared_error: 5115610211966686.0000 - val_loss: 5592820871419221.0000 - val_mean_squared_error: 5592820871419221.0000\n",
            "Epoch 1201/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5097726201650818.0000 - mean_squared_error: 5097726201650818.0000 - val_loss: 5573460450978845.0000 - val_mean_squared_error: 5573460450978845.0000\n",
            "Epoch 1202/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5079853306537176.0000 - mean_squared_error: 5079853306537176.0000 - val_loss: 5554302379308420.0000 - val_mean_squared_error: 5554302379308420.0000\n",
            "Epoch 1203/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5061942507729655.0000 - mean_squared_error: 5061942507729655.0000 - val_loss: 5535002804238070.0000 - val_mean_squared_error: 5535002804238070.0000\n",
            "Epoch 1204/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5044078513890172.0000 - mean_squared_error: 5044078513890172.0000 - val_loss: 5515814701161432.0000 - val_mean_squared_error: 5515814701161432.0000\n",
            "Epoch 1205/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5026412014887920.0000 - mean_squared_error: 5026412014887920.0000 - val_loss: 5496698684379113.0000 - val_mean_squared_error: 5496698684379113.0000\n",
            "Epoch 1206/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 5008669653443962.0000 - mean_squared_error: 5008669653443962.0000 - val_loss: 5477621413297528.0000 - val_mean_squared_error: 5477621413297528.0000\n",
            "Epoch 1207/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4990872444599393.0000 - mean_squared_error: 4990872444599393.0000 - val_loss: 5458396281293807.0000 - val_mean_squared_error: 5458396281293807.0000\n",
            "Epoch 1208/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4973026403282776.0000 - mean_squared_error: 4973026403282776.0000 - val_loss: 5439465991515350.0000 - val_mean_squared_error: 5439465991515350.0000\n",
            "Epoch 1209/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4955422226108839.0000 - mean_squared_error: 4955422226108839.0000 - val_loss: 5420397462026807.0000 - val_mean_squared_error: 5420397462026807.0000\n",
            "Epoch 1210/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4937799034820049.0000 - mean_squared_error: 4937799034820049.0000 - val_loss: 5401275706488751.0000 - val_mean_squared_error: 5401275706488751.0000\n",
            "Epoch 1211/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4920292840004693.0000 - mean_squared_error: 4920292840004693.0000 - val_loss: 5382228767097110.0000 - val_mean_squared_error: 5382228767097110.0000\n",
            "Epoch 1212/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4902465799134363.0000 - mean_squared_error: 4902465799134363.0000 - val_loss: 5363131286010516.0000 - val_mean_squared_error: 5363131286010516.0000\n",
            "Epoch 1213/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4884935506636516.0000 - mean_squared_error: 4884935506636516.0000 - val_loss: 5344235604690284.0000 - val_mean_squared_error: 5344235604690284.0000\n",
            "Epoch 1214/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4867485112224593.0000 - mean_squared_error: 4867485112224593.0000 - val_loss: 5325238852112824.0000 - val_mean_squared_error: 5325238852112824.0000\n",
            "Epoch 1215/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4849672389177524.0000 - mean_squared_error: 4849672389177524.0000 - val_loss: 5306312563084271.0000 - val_mean_squared_error: 5306312563084271.0000\n",
            "Epoch 1216/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4832254950438457.0000 - mean_squared_error: 4832254950438457.0000 - val_loss: 5287370180061034.0000 - val_mean_squared_error: 5287370180061034.0000\n",
            "Epoch 1217/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4814850440644437.0000 - mean_squared_error: 4814850440644437.0000 - val_loss: 5268537103348846.0000 - val_mean_squared_error: 5268537103348846.0000\n",
            "Epoch 1218/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4797235756519476.0000 - mean_squared_error: 4797235756519476.0000 - val_loss: 5249730384875219.0000 - val_mean_squared_error: 5249730384875219.0000\n",
            "Epoch 1219/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4779951687297930.0000 - mean_squared_error: 4779951687297930.0000 - val_loss: 5230864495340851.0000 - val_mean_squared_error: 5230864495340851.0000\n",
            "Epoch 1220/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4762456026770732.0000 - mean_squared_error: 4762456026770732.0000 - val_loss: 5215210910728470.0000 - val_mean_squared_error: 5215210910728470.0000\n",
            "Epoch 1221/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4747936740991104.0000 - mean_squared_error: 4747936740991104.0000 - val_loss: 5196315032252254.0000 - val_mean_squared_error: 5196315032252254.0000\n",
            "Epoch 1222/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4730383740828027.0000 - mean_squared_error: 4730383740828027.0000 - val_loss: 5177639671228266.0000 - val_mean_squared_error: 5177639671228266.0000\n",
            "Epoch 1223/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4713241761669340.0000 - mean_squared_error: 4713241761669340.0000 - val_loss: 5158884261841347.0000 - val_mean_squared_error: 5158884261841347.0000\n",
            "Epoch 1224/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4695799148848181.0000 - mean_squared_error: 4695799148848181.0000 - val_loss: 5140117553899925.0000 - val_mean_squared_error: 5140117553899925.0000\n",
            "Epoch 1225/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4678666413437177.0000 - mean_squared_error: 4678666413437177.0000 - val_loss: 5121379961347679.0000 - val_mean_squared_error: 5121379961347679.0000\n",
            "Epoch 1226/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4661270154901049.0000 - mean_squared_error: 4661270154901049.0000 - val_loss: 5102826397224659.0000 - val_mean_squared_error: 5102826397224659.0000\n",
            "Epoch 1227/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4643871001666313.0000 - mean_squared_error: 4643871001666313.0000 - val_loss: 5084120070578407.0000 - val_mean_squared_error: 5084120070578407.0000\n",
            "Epoch 1228/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4626995713133161.0000 - mean_squared_error: 4626995713133161.0000 - val_loss: 5065601515291920.0000 - val_mean_squared_error: 5065601515291920.0000\n",
            "Epoch 1229/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4609714648528279.0000 - mean_squared_error: 4609714648528279.0000 - val_loss: 5046955524443304.0000 - val_mean_squared_error: 5046955524443304.0000\n",
            "Epoch 1230/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4592567624529558.0000 - mean_squared_error: 4592567624529558.0000 - val_loss: 5028387564900236.0000 - val_mean_squared_error: 5028387564900236.0000\n",
            "Epoch 1231/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4575298811326481.0000 - mean_squared_error: 4575298811326481.0000 - val_loss: 5009817561001267.0000 - val_mean_squared_error: 5009817561001267.0000\n",
            "Epoch 1232/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4558242173760270.0000 - mean_squared_error: 4558242173760270.0000 - val_loss: 4991352398588587.0000 - val_mean_squared_error: 4991352398588587.0000\n",
            "Epoch 1233/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4541303338733226.0000 - mean_squared_error: 4541303338733226.0000 - val_loss: 4972835672303003.0000 - val_mean_squared_error: 4972835672303003.0000\n",
            "Epoch 1234/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4524176849857048.0000 - mean_squared_error: 4524176849857048.0000 - val_loss: 4954363118057484.0000 - val_mean_squared_error: 4954363118057484.0000\n",
            "Epoch 1235/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4507227312152704.0000 - mean_squared_error: 4507227312152704.0000 - val_loss: 4936034278392086.0000 - val_mean_squared_error: 4936034278392086.0000\n",
            "Epoch 1236/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4490023671623233.5000 - mean_squared_error: 4490023671623233.5000 - val_loss: 4917587618310271.0000 - val_mean_squared_error: 4917587618310271.0000\n",
            "Epoch 1237/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4473048261411024.5000 - mean_squared_error: 4473048261411024.5000 - val_loss: 4899146378501450.0000 - val_mean_squared_error: 4899146378501450.0000\n",
            "Epoch 1238/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4456312041594312.5000 - mean_squared_error: 4456312041594312.5000 - val_loss: 4882505934157743.0000 - val_mean_squared_error: 4882505934157743.0000\n",
            "Epoch 1239/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4440677434615232.0000 - mean_squared_error: 4440677434615232.0000 - val_loss: 4864111593207912.0000 - val_mean_squared_error: 4864111593207912.0000\n",
            "Epoch 1240/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4423733391864404.5000 - mean_squared_error: 4423733391864404.5000 - val_loss: 4845801177010986.0000 - val_mean_squared_error: 4845801177010986.0000\n",
            "Epoch 1241/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4407040842381576.0000 - mean_squared_error: 4407040842381576.0000 - val_loss: 4827724308760287.0000 - val_mean_squared_error: 4827724308760287.0000\n",
            "Epoch 1242/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4390248096612097.5000 - mean_squared_error: 4390248096612097.5000 - val_loss: 4809376360130224.0000 - val_mean_squared_error: 4809376360130224.0000\n",
            "Epoch 1243/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4373567618371775.0000 - mean_squared_error: 4373567618371775.0000 - val_loss: 4791204329235496.0000 - val_mean_squared_error: 4791204329235496.0000\n",
            "Epoch 1244/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4356627921086003.0000 - mean_squared_error: 4356627921086003.0000 - val_loss: 4773003307311521.0000 - val_mean_squared_error: 4773003307311521.0000\n",
            "Epoch 1245/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4339955374410993.5000 - mean_squared_error: 4339955374410993.5000 - val_loss: 4754829784097647.0000 - val_mean_squared_error: 4754829784097647.0000\n",
            "Epoch 1246/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4323169824382338.5000 - mean_squared_error: 4323169824382338.5000 - val_loss: 4736867169256627.0000 - val_mean_squared_error: 4736867169256627.0000\n",
            "Epoch 1247/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4306682340983456.0000 - mean_squared_error: 4306682340983456.0000 - val_loss: 4718702330005585.0000 - val_mean_squared_error: 4718702330005585.0000\n",
            "Epoch 1248/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4289983469409003.0000 - mean_squared_error: 4289983469409003.0000 - val_loss: 4700618728119718.0000 - val_mean_squared_error: 4700618728119718.0000\n",
            "Epoch 1249/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4273259343639472.5000 - mean_squared_error: 4273259343639472.5000 - val_loss: 4682579891258455.0000 - val_mean_squared_error: 4682579891258455.0000\n",
            "Epoch 1250/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4256768112015947.5000 - mean_squared_error: 4256768112015947.5000 - val_loss: 4664543719036153.0000 - val_mean_squared_error: 4664543719036153.0000\n",
            "Epoch 1251/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4240211993429822.0000 - mean_squared_error: 4240211993429822.0000 - val_loss: 4646609265652661.0000 - val_mean_squared_error: 4646609265652661.0000\n",
            "Epoch 1252/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4223624843780919.0000 - mean_squared_error: 4223624843780919.0000 - val_loss: 4628610891265782.0000 - val_mean_squared_error: 4628610891265782.0000\n",
            "Epoch 1253/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4206943716663377.0000 - mean_squared_error: 4206943716663377.0000 - val_loss: 4610682423841300.0000 - val_mean_squared_error: 4610682423841300.0000\n",
            "Epoch 1254/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4190447906449804.5000 - mean_squared_error: 4190447906449804.5000 - val_loss: 4592869207739097.0000 - val_mean_squared_error: 4592869207739097.0000\n",
            "Epoch 1255/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4174140266073747.0000 - mean_squared_error: 4174140266073747.0000 - val_loss: 4574938183353153.0000 - val_mean_squared_error: 4574938183353153.0000\n",
            "Epoch 1256/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4157778592336141.5000 - mean_squared_error: 4157778592336141.5000 - val_loss: 4557087879177071.0000 - val_mean_squared_error: 4557087879177071.0000\n",
            "Epoch 1257/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4141325281871886.5000 - mean_squared_error: 4141325281871886.5000 - val_loss: 4539289831953009.0000 - val_mean_squared_error: 4539289831953009.0000\n",
            "Epoch 1258/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4124983509946582.0000 - mean_squared_error: 4124983509946582.0000 - val_loss: 4521509031327848.0000 - val_mean_squared_error: 4521509031327848.0000\n",
            "Epoch 1259/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4108874333547078.0000 - mean_squared_error: 4108874333547078.0000 - val_loss: 4503916121872627.0000 - val_mean_squared_error: 4503916121872627.0000\n",
            "Epoch 1260/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4092572032454755.0000 - mean_squared_error: 4092572032454755.0000 - val_loss: 4486084285145967.5000 - val_mean_squared_error: 4486084285145967.5000\n",
            "Epoch 1261/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4076110059156886.5000 - mean_squared_error: 4076110059156886.5000 - val_loss: 4468428930324074.5000 - val_mean_squared_error: 4468428930324074.5000\n",
            "Epoch 1262/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4059988140805918.5000 - mean_squared_error: 4059988140805918.5000 - val_loss: 4450799202747016.0000 - val_mean_squared_error: 4450799202747016.0000\n",
            "Epoch 1263/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4043741749655398.5000 - mean_squared_error: 4043741749655398.5000 - val_loss: 4433151191227258.5000 - val_mean_squared_error: 4433151191227258.5000\n",
            "Epoch 1264/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4027633534042205.0000 - mean_squared_error: 4027633534042205.0000 - val_loss: 4415609269342833.5000 - val_mean_squared_error: 4415609269342833.5000\n",
            "Epoch 1265/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 4011552176782224.0000 - mean_squared_error: 4011552176782224.0000 - val_loss: 4398083201832740.0000 - val_mean_squared_error: 4398083201832740.0000\n",
            "Epoch 1266/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3995513414571844.0000 - mean_squared_error: 3995513414571844.0000 - val_loss: 4380612374396372.5000 - val_mean_squared_error: 4380612374396372.5000\n",
            "Epoch 1267/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3979401101046518.5000 - mean_squared_error: 3979401101046518.5000 - val_loss: 4363079947847483.5000 - val_mean_squared_error: 4363079947847483.5000\n",
            "Epoch 1268/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3963369159450751.5000 - mean_squared_error: 3963369159450751.5000 - val_loss: 4345629560936968.5000 - val_mean_squared_error: 4345629560936968.5000\n",
            "Epoch 1269/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3947376107204370.5000 - mean_squared_error: 3947376107204370.5000 - val_loss: 4328134383219914.5000 - val_mean_squared_error: 4328134383219914.5000\n",
            "Epoch 1270/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3931399916083800.0000 - mean_squared_error: 3931399916083800.0000 - val_loss: 4311016292105406.5000 - val_mean_squared_error: 4311016292105406.5000\n",
            "Epoch 1271/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3915579335706151.5000 - mean_squared_error: 3915579335706151.5000 - val_loss: 4293565815716406.5000 - val_mean_squared_error: 4293565815716406.5000\n",
            "Epoch 1272/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3899600338922494.5000 - mean_squared_error: 3899600338922494.5000 - val_loss: 4276267117587300.0000 - val_mean_squared_error: 4276267117587300.0000\n",
            "Epoch 1273/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3883841181475083.0000 - mean_squared_error: 3883841181475083.0000 - val_loss: 4258889651092578.5000 - val_mean_squared_error: 4258889651092578.5000\n",
            "Epoch 1274/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3867857994136788.5000 - mean_squared_error: 3867857994136788.5000 - val_loss: 4241540176197921.5000 - val_mean_squared_error: 4241540176197921.5000\n",
            "Epoch 1275/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3852233006007870.5000 - mean_squared_error: 3852233006007870.5000 - val_loss: 4224366396100677.5000 - val_mean_squared_error: 4224366396100677.5000\n",
            "Epoch 1276/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3836404232084056.0000 - mean_squared_error: 3836404232084056.0000 - val_loss: 4207164959568542.5000 - val_mean_squared_error: 4207164959568542.5000\n",
            "Epoch 1277/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3820520435726043.0000 - mean_squared_error: 3820520435726043.0000 - val_loss: 4189868903329630.0000 - val_mean_squared_error: 4189868903329630.0000\n",
            "Epoch 1278/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3804854260030178.5000 - mean_squared_error: 3804854260030178.5000 - val_loss: 4172752509273174.5000 - val_mean_squared_error: 4172752509273174.5000\n",
            "Epoch 1279/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3789437163961302.0000 - mean_squared_error: 3789437163961302.0000 - val_loss: 4155773352464453.5000 - val_mean_squared_error: 4155773352464453.5000\n",
            "Epoch 1280/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3773505997288159.5000 - mean_squared_error: 3773505997288159.5000 - val_loss: 4138652229697536.0000 - val_mean_squared_error: 4138652229697536.0000\n",
            "Epoch 1281/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3758037976697217.0000 - mean_squared_error: 3758037976697217.0000 - val_loss: 4121496503022146.5000 - val_mean_squared_error: 4121496503022146.5000\n",
            "Epoch 1282/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3742611088998956.0000 - mean_squared_error: 3742611088998956.0000 - val_loss: 4104578305327289.5000 - val_mean_squared_error: 4104578305327289.5000\n",
            "Epoch 1283/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3726672422079706.5000 - mean_squared_error: 3726672422079706.5000 - val_loss: 4087483173785484.5000 - val_mean_squared_error: 4087483173785484.5000\n",
            "Epoch 1284/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3711350662362774.0000 - mean_squared_error: 3711350662362774.0000 - val_loss: 4070545701818252.5000 - val_mean_squared_error: 4070545701818252.5000\n",
            "Epoch 1285/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3695927441637121.5000 - mean_squared_error: 3695927441637121.5000 - val_loss: 4053637336140690.0000 - val_mean_squared_error: 4053637336140690.0000\n",
            "Epoch 1286/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3680530455446500.5000 - mean_squared_error: 3680530455446500.5000 - val_loss: 4036681936628117.5000 - val_mean_squared_error: 4036681936628117.5000\n",
            "Epoch 1287/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3664925052474763.0000 - mean_squared_error: 3664925052474763.0000 - val_loss: 4019916222404943.5000 - val_mean_squared_error: 4019916222404943.5000\n",
            "Epoch 1288/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3649604604180836.0000 - mean_squared_error: 3649604604180836.0000 - val_loss: 4003014183917903.5000 - val_mean_squared_error: 4003014183917903.5000\n",
            "Epoch 1289/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3634045961374614.0000 - mean_squared_error: 3634045961374614.0000 - val_loss: 3986310717905416.5000 - val_mean_squared_error: 3986310717905416.5000\n",
            "Epoch 1290/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3618861210430995.5000 - mean_squared_error: 3618861210430995.5000 - val_loss: 3969495613074924.0000 - val_mean_squared_error: 3969495613074924.0000\n",
            "Epoch 1291/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3603616303367465.0000 - mean_squared_error: 3603616303367465.0000 - val_loss: 3952747849145858.5000 - val_mean_squared_error: 3952747849145858.5000\n",
            "Epoch 1292/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3588522760109385.0000 - mean_squared_error: 3588522760109385.0000 - val_loss: 3936020574273350.5000 - val_mean_squared_error: 3936020574273350.5000\n",
            "Epoch 1293/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3573077171344408.5000 - mean_squared_error: 3573077171344408.5000 - val_loss: 3919474296177658.0000 - val_mean_squared_error: 3919474296177658.0000\n",
            "Epoch 1294/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3558043531527604.5000 - mean_squared_error: 3558043531527604.5000 - val_loss: 3902848486874349.5000 - val_mean_squared_error: 3902848486874349.5000\n",
            "Epoch 1295/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3542688425824308.0000 - mean_squared_error: 3542688425824308.0000 - val_loss: 3886145559249358.5000 - val_mean_squared_error: 3886145559249358.5000\n",
            "Epoch 1296/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3527706399842964.5000 - mean_squared_error: 3527706399842964.5000 - val_loss: 3869611843023056.5000 - val_mean_squared_error: 3869611843023056.5000\n",
            "Epoch 1297/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3512582465286949.5000 - mean_squared_error: 3512582465286949.5000 - val_loss: 3853006624387465.5000 - val_mean_squared_error: 3853006624387465.5000\n",
            "Epoch 1298/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3497580118703618.0000 - mean_squared_error: 3497580118703618.0000 - val_loss: 3836474336783758.5000 - val_mean_squared_error: 3836474336783758.5000\n",
            "Epoch 1299/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3482627513741839.0000 - mean_squared_error: 3482627513741839.0000 - val_loss: 3820077404346426.0000 - val_mean_squared_error: 3820077404346426.0000\n",
            "Epoch 1300/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3467327044240820.5000 - mean_squared_error: 3467327044240820.5000 - val_loss: 3803739641453250.0000 - val_mean_squared_error: 3803739641453250.0000\n",
            "Epoch 1301/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3452507903812082.5000 - mean_squared_error: 3452507903812082.5000 - val_loss: 3787302739431493.5000 - val_mean_squared_error: 3787302739431493.5000\n",
            "Epoch 1302/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3437661725535276.5000 - mean_squared_error: 3437661725535276.5000 - val_loss: 3770979406839808.0000 - val_mean_squared_error: 3770979406839808.0000\n",
            "Epoch 1303/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3422767973813258.0000 - mean_squared_error: 3422767973813258.0000 - val_loss: 3754559815113502.5000 - val_mean_squared_error: 3754559815113502.5000\n",
            "Epoch 1304/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3408026284891986.0000 - mean_squared_error: 3408026284891986.0000 - val_loss: 3738224196670805.5000 - val_mean_squared_error: 3738224196670805.5000\n",
            "Epoch 1305/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3393275276666234.0000 - mean_squared_error: 3393275276666234.0000 - val_loss: 3721977080033025.5000 - val_mean_squared_error: 3721977080033025.5000\n",
            "Epoch 1306/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3378530782651399.0000 - mean_squared_error: 3378530782651399.0000 - val_loss: 3705737842051708.5000 - val_mean_squared_error: 3705737842051708.5000\n",
            "Epoch 1307/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3363605511025514.5000 - mean_squared_error: 3363605511025514.5000 - val_loss: 3689593037237277.5000 - val_mean_squared_error: 3689593037237277.5000\n",
            "Epoch 1308/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3349041722482073.5000 - mean_squared_error: 3349041722482073.5000 - val_loss: 3673395321822908.0000 - val_mean_squared_error: 3673395321822908.0000\n",
            "Epoch 1309/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3334340405569955.5000 - mean_squared_error: 3334340405569955.5000 - val_loss: 3657200087540776.5000 - val_mean_squared_error: 3657200087540776.5000\n",
            "Epoch 1310/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3319667135416960.5000 - mean_squared_error: 3319667135416960.5000 - val_loss: 3641075362305087.5000 - val_mean_squared_error: 3641075362305087.5000\n",
            "Epoch 1311/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3305181707055886.5000 - mean_squared_error: 3305181707055886.5000 - val_loss: 3625039712143256.0000 - val_mean_squared_error: 3625039712143256.0000\n",
            "Epoch 1312/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3290514116192212.5000 - mean_squared_error: 3290514116192212.5000 - val_loss: 3608978057107050.5000 - val_mean_squared_error: 3608978057107050.5000\n",
            "Epoch 1313/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3275934306760110.5000 - mean_squared_error: 3275934306760110.5000 - val_loss: 3593101140261616.0000 - val_mean_squared_error: 3593101140261616.0000\n",
            "Epoch 1314/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3261568339390922.0000 - mean_squared_error: 3261568339390922.0000 - val_loss: 3577146069267288.0000 - val_mean_squared_error: 3577146069267288.0000\n",
            "Epoch 1315/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3246959627585411.5000 - mean_squared_error: 3246959627585411.5000 - val_loss: 3561329001395865.5000 - val_mean_squared_error: 3561329001395865.5000\n",
            "Epoch 1316/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3232785076907771.5000 - mean_squared_error: 3232785076907771.5000 - val_loss: 3545409541322115.5000 - val_mean_squared_error: 3545409541322115.5000\n",
            "Epoch 1317/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3218350941550531.0000 - mean_squared_error: 3218350941550531.0000 - val_loss: 3529622709595813.5000 - val_mean_squared_error: 3529622709595813.5000\n",
            "Epoch 1318/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3203994816118645.0000 - mean_squared_error: 3203994816118645.0000 - val_loss: 3513720544651669.5000 - val_mean_squared_error: 3513720544651669.5000\n",
            "Epoch 1319/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3189834039843833.0000 - mean_squared_error: 3189834039843833.0000 - val_loss: 3498262070151434.0000 - val_mean_squared_error: 3498262070151434.0000\n",
            "Epoch 1320/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3175639031973462.0000 - mean_squared_error: 3175639031973462.0000 - val_loss: 3482402807866130.5000 - val_mean_squared_error: 3482402807866130.5000\n",
            "Epoch 1321/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3161368882013817.0000 - mean_squared_error: 3161368882013817.0000 - val_loss: 3466670248632644.0000 - val_mean_squared_error: 3466670248632644.0000\n",
            "Epoch 1322/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3147127572729189.5000 - mean_squared_error: 3147127572729189.5000 - val_loss: 3451143800815245.5000 - val_mean_squared_error: 3451143800815245.5000\n",
            "Epoch 1323/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3133003599733744.0000 - mean_squared_error: 3133003599733744.0000 - val_loss: 3435460330388763.5000 - val_mean_squared_error: 3435460330388763.5000\n",
            "Epoch 1324/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3118928513315088.0000 - mean_squared_error: 3118928513315088.0000 - val_loss: 3420004450764603.5000 - val_mean_squared_error: 3420004450764603.5000\n",
            "Epoch 1325/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3104824143132055.0000 - mean_squared_error: 3104824143132055.0000 - val_loss: 3404344745217192.0000 - val_mean_squared_error: 3404344745217192.0000\n",
            "Epoch 1326/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3090949528070796.0000 - mean_squared_error: 3090949528070796.0000 - val_loss: 3388922291115349.5000 - val_mean_squared_error: 3388922291115349.5000\n",
            "Epoch 1327/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3076886346024232.5000 - mean_squared_error: 3076886346024232.5000 - val_loss: 3373520592988934.5000 - val_mean_squared_error: 3373520592988934.5000\n",
            "Epoch 1328/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3063029183444120.0000 - mean_squared_error: 3063029183444120.0000 - val_loss: 3358041518721475.5000 - val_mean_squared_error: 3358041518721475.5000\n",
            "Epoch 1329/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3049070838921850.0000 - mean_squared_error: 3049070838921850.0000 - val_loss: 3342555777548565.5000 - val_mean_squared_error: 3342555777548565.5000\n",
            "Epoch 1330/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3035200863579505.0000 - mean_squared_error: 3035200863579505.0000 - val_loss: 3327200004633894.5000 - val_mean_squared_error: 3327200004633894.5000\n",
            "Epoch 1331/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3021368585763496.5000 - mean_squared_error: 3021368585763496.5000 - val_loss: 3311883502158194.5000 - val_mean_squared_error: 3311883502158194.5000\n",
            "Epoch 1332/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 3007414406357142.5000 - mean_squared_error: 3007414406357142.5000 - val_loss: 3296577838711894.5000 - val_mean_squared_error: 3296577838711894.5000\n",
            "Epoch 1333/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2993653612865098.5000 - mean_squared_error: 2993653612865098.5000 - val_loss: 3281336787831513.5000 - val_mean_squared_error: 3281336787831513.5000\n",
            "Epoch 1334/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2979867105002909.0000 - mean_squared_error: 2979867105002909.0000 - val_loss: 3266114337859989.5000 - val_mean_squared_error: 3266114337859989.5000\n",
            "Epoch 1335/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2966418139539343.0000 - mean_squared_error: 2966418139539343.0000 - val_loss: 3251170050717430.0000 - val_mean_squared_error: 3251170050717430.0000\n",
            "Epoch 1336/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2952872234135221.5000 - mean_squared_error: 2952872234135221.5000 - val_loss: 3235941532891332.5000 - val_mean_squared_error: 3235941532891332.5000\n",
            "Epoch 1337/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2938983494509042.5000 - mean_squared_error: 2938983494509042.5000 - val_loss: 3220833821636526.5000 - val_mean_squared_error: 3220833821636526.5000\n",
            "Epoch 1338/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2925490855128340.5000 - mean_squared_error: 2925490855128340.5000 - val_loss: 3205735337281802.0000 - val_mean_squared_error: 3205735337281802.0000\n",
            "Epoch 1339/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2911886537770327.5000 - mean_squared_error: 2911886537770327.5000 - val_loss: 3190873195938532.5000 - val_mean_squared_error: 3190873195938532.5000\n",
            "Epoch 1340/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2898434118430899.5000 - mean_squared_error: 2898434118430899.5000 - val_loss: 3175759240905352.0000 - val_mean_squared_error: 3175759240905352.0000\n",
            "Epoch 1341/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2885072268341057.0000 - mean_squared_error: 2885072268341057.0000 - val_loss: 3160966704724164.5000 - val_mean_squared_error: 3160966704724164.5000\n",
            "Epoch 1342/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2871843138132150.5000 - mean_squared_error: 2871843138132150.5000 - val_loss: 3146080317744538.5000 - val_mean_squared_error: 3146080317744538.5000\n",
            "Epoch 1343/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2858377456391609.5000 - mean_squared_error: 2858377456391609.5000 - val_loss: 3131083508247673.5000 - val_mean_squared_error: 3131083508247673.5000\n",
            "Epoch 1344/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2845063100084867.0000 - mean_squared_error: 2845063100084867.0000 - val_loss: 3117186695685623.5000 - val_mean_squared_error: 3117186695685623.5000\n",
            "Epoch 1345/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2832231720909318.5000 - mean_squared_error: 2832231720909318.5000 - val_loss: 3102287067406752.5000 - val_mean_squared_error: 3102287067406752.5000\n",
            "Epoch 1346/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2819119756037594.0000 - mean_squared_error: 2819119756037594.0000 - val_loss: 3087493474166170.5000 - val_mean_squared_error: 3087493474166170.5000\n",
            "Epoch 1347/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2805885107239940.5000 - mean_squared_error: 2805885107239940.5000 - val_loss: 3072694553164250.5000 - val_mean_squared_error: 3072694553164250.5000\n",
            "Epoch 1348/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2792529279957070.0000 - mean_squared_error: 2792529279957070.0000 - val_loss: 3058026399660598.5000 - val_mean_squared_error: 3058026399660598.5000\n",
            "Epoch 1349/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2779592873012616.5000 - mean_squared_error: 2779592873012616.5000 - val_loss: 3043406444728852.0000 - val_mean_squared_error: 3043406444728852.0000\n",
            "Epoch 1350/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2766407361382136.5000 - mean_squared_error: 2766407361382136.5000 - val_loss: 3028816111725504.5000 - val_mean_squared_error: 3028816111725504.5000\n",
            "Epoch 1351/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2753275371681013.0000 - mean_squared_error: 2753275371681013.0000 - val_loss: 3014456821270794.0000 - val_mean_squared_error: 3014456821270794.0000\n",
            "Epoch 1352/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2740408660376742.5000 - mean_squared_error: 2740408660376742.5000 - val_loss: 2999798595329261.0000 - val_mean_squared_error: 2999798595329261.0000\n",
            "Epoch 1353/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2727411614736048.0000 - mean_squared_error: 2727411614736048.0000 - val_loss: 2985314405799994.0000 - val_mean_squared_error: 2985314405799994.0000\n",
            "Epoch 1354/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2714491274431985.0000 - mean_squared_error: 2714491274431985.0000 - val_loss: 2970901544272797.5000 - val_mean_squared_error: 2970901544272797.5000\n",
            "Epoch 1355/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2701601334538234.0000 - mean_squared_error: 2701601334538234.0000 - val_loss: 2956466988762661.5000 - val_mean_squared_error: 2956466988762661.5000\n",
            "Epoch 1356/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2688826145106687.5000 - mean_squared_error: 2688826145106687.5000 - val_loss: 2942182219478681.5000 - val_mean_squared_error: 2942182219478681.5000\n",
            "Epoch 1357/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2675785531670088.0000 - mean_squared_error: 2675785531670088.0000 - val_loss: 2927911507416405.5000 - val_mean_squared_error: 2927911507416405.5000\n",
            "Epoch 1358/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2663071437313025.5000 - mean_squared_error: 2663071437313025.5000 - val_loss: 2913535208466559.5000 - val_mean_squared_error: 2913535208466559.5000\n",
            "Epoch 1359/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2650365509354839.5000 - mean_squared_error: 2650365509354839.5000 - val_loss: 2899420604512915.5000 - val_mean_squared_error: 2899420604512915.5000\n",
            "Epoch 1360/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2637609730901173.0000 - mean_squared_error: 2637609730901173.0000 - val_loss: 2885421624961336.5000 - val_mean_squared_error: 2885421624961336.5000\n",
            "Epoch 1361/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2625205902654120.5000 - mean_squared_error: 2625205902654120.5000 - val_loss: 2871160370319985.0000 - val_mean_squared_error: 2871160370319985.0000\n",
            "Epoch 1362/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2612400942705361.0000 - mean_squared_error: 2612400942705361.0000 - val_loss: 2857141344554522.0000 - val_mean_squared_error: 2857141344554522.0000\n",
            "Epoch 1363/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2599992839329418.5000 - mean_squared_error: 2599992839329418.5000 - val_loss: 2842960612208755.5000 - val_mean_squared_error: 2842960612208755.5000\n",
            "Epoch 1364/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2587326561604146.0000 - mean_squared_error: 2587326561604146.0000 - val_loss: 2828941019240691.0000 - val_mean_squared_error: 2828941019240691.0000\n",
            "Epoch 1365/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2574906919869942.5000 - mean_squared_error: 2574906919869942.5000 - val_loss: 2814912316907844.0000 - val_mean_squared_error: 2814912316907844.0000\n",
            "Epoch 1366/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2562455924912446.5000 - mean_squared_error: 2562455924912446.5000 - val_loss: 2800912739063680.5000 - val_mean_squared_error: 2800912739063680.5000\n",
            "Epoch 1367/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2550018474365165.5000 - mean_squared_error: 2550018474365165.5000 - val_loss: 2786944995844697.5000 - val_mean_squared_error: 2786944995844697.5000\n",
            "Epoch 1368/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2537579099777328.5000 - mean_squared_error: 2537579099777328.5000 - val_loss: 2773126818947118.5000 - val_mean_squared_error: 2773126818947118.5000\n",
            "Epoch 1369/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2525464729905780.5000 - mean_squared_error: 2525464729905780.5000 - val_loss: 2759252485958777.5000 - val_mean_squared_error: 2759252485958777.5000\n",
            "Epoch 1370/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2512895148175122.5000 - mean_squared_error: 2512895148175122.5000 - val_loss: 2745493381543947.5000 - val_mean_squared_error: 2745493381543947.5000\n",
            "Epoch 1371/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2500627406737599.0000 - mean_squared_error: 2500627406737599.0000 - val_loss: 2731637697236876.5000 - val_mean_squared_error: 2731637697236876.5000\n",
            "Epoch 1372/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2488576959435360.5000 - mean_squared_error: 2488576959435360.5000 - val_loss: 2718095396917132.5000 - val_mean_squared_error: 2718095396917132.5000\n",
            "Epoch 1373/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2476449551839759.0000 - mean_squared_error: 2476449551839759.0000 - val_loss: 2704481281771693.5000 - val_mean_squared_error: 2704481281771693.5000\n",
            "Epoch 1374/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2464594289197195.0000 - mean_squared_error: 2464594289197195.0000 - val_loss: 2690777519041750.0000 - val_mean_squared_error: 2690777519041750.0000\n",
            "Epoch 1375/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2452274944175635.5000 - mean_squared_error: 2452274944175635.5000 - val_loss: 2677233442043267.5000 - val_mean_squared_error: 2677233442043267.5000\n",
            "Epoch 1376/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2440338707427229.5000 - mean_squared_error: 2440338707427229.5000 - val_loss: 2663670959017035.0000 - val_mean_squared_error: 2663670959017035.0000\n",
            "Epoch 1377/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2428170762850472.0000 - mean_squared_error: 2428170762850472.0000 - val_loss: 2650110987454730.0000 - val_mean_squared_error: 2650110987454730.0000\n",
            "Epoch 1378/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2416331797600276.0000 - mean_squared_error: 2416331797600276.0000 - val_loss: 2636865712483634.5000 - val_mean_squared_error: 2636865712483634.5000\n",
            "Epoch 1379/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2404518862141379.0000 - mean_squared_error: 2404518862141379.0000 - val_loss: 2623401307735127.0000 - val_mean_squared_error: 2623401307735127.0000\n",
            "Epoch 1380/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2392625850810275.5000 - mean_squared_error: 2392625850810275.5000 - val_loss: 2610247128686731.0000 - val_mean_squared_error: 2610247128686731.0000\n",
            "Epoch 1381/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2380912488009687.5000 - mean_squared_error: 2380912488009687.5000 - val_loss: 2596843931771944.5000 - val_mean_squared_error: 2596843931771944.5000\n",
            "Epoch 1382/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2369273659806536.0000 - mean_squared_error: 2369273659806536.0000 - val_loss: 2583595056429252.5000 - val_mean_squared_error: 2583595056429252.5000\n",
            "Epoch 1383/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2357250471897044.5000 - mean_squared_error: 2357250471897044.5000 - val_loss: 2570215664583026.5000 - val_mean_squared_error: 2570215664583026.5000\n",
            "Epoch 1384/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2345823112077370.0000 - mean_squared_error: 2345823112077370.0000 - val_loss: 2557108947046469.5000 - val_mean_squared_error: 2557108947046469.5000\n",
            "Epoch 1385/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2334138365084899.5000 - mean_squared_error: 2334138365084899.5000 - val_loss: 2544531728304672.0000 - val_mean_squared_error: 2544531728304672.0000\n",
            "Epoch 1386/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2323143409317873.5000 - mean_squared_error: 2323143409317873.5000 - val_loss: 2531326492680886.0000 - val_mean_squared_error: 2531326492680886.0000\n",
            "Epoch 1387/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2311489382902898.5000 - mean_squared_error: 2311489382902898.5000 - val_loss: 2518234048479324.5000 - val_mean_squared_error: 2518234048479324.5000\n",
            "Epoch 1388/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2299917969872522.5000 - mean_squared_error: 2299917969872522.5000 - val_loss: 2505150502837300.0000 - val_mean_squared_error: 2505150502837300.0000\n",
            "Epoch 1389/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2288308732312047.5000 - mean_squared_error: 2288308732312047.5000 - val_loss: 2492139087470545.5000 - val_mean_squared_error: 2492139087470545.5000\n",
            "Epoch 1390/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2277062942690430.0000 - mean_squared_error: 2277062942690430.0000 - val_loss: 2479179876733645.5000 - val_mean_squared_error: 2479179876733645.5000\n",
            "Epoch 1391/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2265455427559157.5000 - mean_squared_error: 2265455427559157.5000 - val_loss: 2466247952385018.0000 - val_mean_squared_error: 2466247952385018.0000\n",
            "Epoch 1392/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2254370731294303.0000 - mean_squared_error: 2254370731294303.0000 - val_loss: 2453345394420302.0000 - val_mean_squared_error: 2453345394420302.0000\n",
            "Epoch 1393/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2242932518443097.7500 - mean_squared_error: 2242932518443097.7500 - val_loss: 2440561177060485.0000 - val_mean_squared_error: 2440561177060485.0000\n",
            "Epoch 1394/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2231722166288337.5000 - mean_squared_error: 2231722166288337.5000 - val_loss: 2427757723342906.0000 - val_mean_squared_error: 2427757723342906.0000\n",
            "Epoch 1395/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2220587420669346.5000 - mean_squared_error: 2220587420669346.5000 - val_loss: 2415030149655766.0000 - val_mean_squared_error: 2415030149655766.0000\n",
            "Epoch 1396/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2209209184727961.2500 - mean_squared_error: 2209209184727961.2500 - val_loss: 2402317716789954.0000 - val_mean_squared_error: 2402317716789954.0000\n",
            "Epoch 1397/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2198256691975980.7500 - mean_squared_error: 2198256691975980.7500 - val_loss: 2389761327577932.5000 - val_mean_squared_error: 2389761327577932.5000\n",
            "Epoch 1398/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2187074159720109.0000 - mean_squared_error: 2187074159720109.0000 - val_loss: 2377098512048822.0000 - val_mean_squared_error: 2377098512048822.0000\n",
            "Epoch 1399/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2176065868652949.7500 - mean_squared_error: 2176065868652949.7500 - val_loss: 2364677703974264.0000 - val_mean_squared_error: 2364677703974264.0000\n",
            "Epoch 1400/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2165313473840726.2500 - mean_squared_error: 2165313473840726.2500 - val_loss: 2352068041698610.5000 - val_mean_squared_error: 2352068041698610.5000\n",
            "Epoch 1401/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2154177706876082.0000 - mean_squared_error: 2154177706876082.0000 - val_loss: 2339647135804352.5000 - val_mean_squared_error: 2339647135804352.5000\n",
            "Epoch 1402/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2143523061677130.0000 - mean_squared_error: 2143523061677130.0000 - val_loss: 2327421721443241.0000 - val_mean_squared_error: 2327421721443241.0000\n",
            "Epoch 1403/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2132710298882216.0000 - mean_squared_error: 2132710298882216.0000 - val_loss: 2315014798458047.0000 - val_mean_squared_error: 2315014798458047.0000\n",
            "Epoch 1404/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2121847902295551.2500 - mean_squared_error: 2121847902295551.2500 - val_loss: 2302733930184796.5000 - val_mean_squared_error: 2302733930184796.5000\n",
            "Epoch 1405/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2111451253754565.5000 - mean_squared_error: 2111451253754565.5000 - val_loss: 2290562903576923.0000 - val_mean_squared_error: 2290562903576923.0000\n",
            "Epoch 1406/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2100507467879355.7500 - mean_squared_error: 2100507467879355.7500 - val_loss: 2278253219439934.0000 - val_mean_squared_error: 2278253219439934.0000\n",
            "Epoch 1407/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2090086433334557.2500 - mean_squared_error: 2090086433334557.2500 - val_loss: 2268230613729280.0000 - val_mean_squared_error: 2268230613729280.0000\n",
            "Epoch 1408/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2081261890283059.5000 - mean_squared_error: 2081261890283059.5000 - val_loss: 2256249715253479.5000 - val_mean_squared_error: 2256249715253479.5000\n",
            "Epoch 1409/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2070657413658517.0000 - mean_squared_error: 2070657413658517.0000 - val_loss: 2248946777014549.7500 - val_mean_squared_error: 2248946777014549.7500\n",
            "Epoch 1410/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2064660086412289.5000 - mean_squared_error: 2064660086412289.5000 - val_loss: 2237379084875972.7500 - val_mean_squared_error: 2237379084875972.7500\n",
            "Epoch 1411/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2054186996224098.5000 - mean_squared_error: 2054186996224098.5000 - val_loss: 2225335768332022.0000 - val_mean_squared_error: 2225335768332022.0000\n",
            "Epoch 1412/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2043921060562888.7500 - mean_squared_error: 2043921060562888.7500 - val_loss: 2213421033129787.2500 - val_mean_squared_error: 2213421033129787.2500\n",
            "Epoch 1413/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2033560277960347.7500 - mean_squared_error: 2033560277960347.7500 - val_loss: 2201415375653778.0000 - val_mean_squared_error: 2201415375653778.0000\n",
            "Epoch 1414/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2023063655341836.5000 - mean_squared_error: 2023063655341836.5000 - val_loss: 2189549638263478.2500 - val_mean_squared_error: 2189549638263478.2500\n",
            "Epoch 1415/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2012739186797891.0000 - mean_squared_error: 2012739186797891.0000 - val_loss: 2177664274753200.7500 - val_mean_squared_error: 2177664274753200.7500\n",
            "Epoch 1416/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 2002823882706324.2500 - mean_squared_error: 2002823882706324.2500 - val_loss: 2166121930049617.0000 - val_mean_squared_error: 2166121930049617.0000\n",
            "Epoch 1417/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1992555327806086.2500 - mean_squared_error: 1992555327806086.2500 - val_loss: 2154294743478943.0000 - val_mean_squared_error: 2154294743478943.0000\n",
            "Epoch 1418/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1982408342084253.2500 - mean_squared_error: 1982408342084253.2500 - val_loss: 2142750052619142.7500 - val_mean_squared_error: 2142750052619142.7500\n",
            "Epoch 1419/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1972192708835499.0000 - mean_squared_error: 1972192708835499.0000 - val_loss: 2130972762436718.0000 - val_mean_squared_error: 2130972762436718.0000\n",
            "Epoch 1420/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1962423287074590.0000 - mean_squared_error: 1962423287074590.0000 - val_loss: 2119378488363366.7500 - val_mean_squared_error: 2119378488363366.7500\n",
            "Epoch 1421/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1952172062018083.2500 - mean_squared_error: 1952172062018083.2500 - val_loss: 2107829450972397.2500 - val_mean_squared_error: 2107829450972397.2500\n",
            "Epoch 1422/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1942212217763987.7500 - mean_squared_error: 1942212217763987.7500 - val_loss: 2096444525464743.7500 - val_mean_squared_error: 2096444525464743.7500\n",
            "Epoch 1423/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1932421075701928.0000 - mean_squared_error: 1932421075701928.0000 - val_loss: 2084918139400678.0000 - val_mean_squared_error: 2084918139400678.0000\n",
            "Epoch 1424/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1922395053565074.5000 - mean_squared_error: 1922395053565074.5000 - val_loss: 2073547351872853.2500 - val_mean_squared_error: 2073547351872853.2500\n",
            "Epoch 1425/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1912858770560557.7500 - mean_squared_error: 1912858770560557.7500 - val_loss: 2062463906680808.7500 - val_mean_squared_error: 2062463906680808.7500\n",
            "Epoch 1426/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1903000596425263.2500 - mean_squared_error: 1903000596425263.2500 - val_loss: 2051030655966445.2500 - val_mean_squared_error: 2051030655966445.2500\n",
            "Epoch 1427/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1893300621043042.7500 - mean_squared_error: 1893300621043042.7500 - val_loss: 2040043980239704.2500 - val_mean_squared_error: 2040043980239704.2500\n",
            "Epoch 1428/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1883860831757342.2500 - mean_squared_error: 1883860831757342.2500 - val_loss: 2028755230075377.2500 - val_mean_squared_error: 2028755230075377.2500\n",
            "Epoch 1429/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1874238411915565.5000 - mean_squared_error: 1874238411915565.5000 - val_loss: 2017677186957312.0000 - val_mean_squared_error: 2017677186957312.0000\n",
            "Epoch 1430/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1864606129443795.0000 - mean_squared_error: 1864606129443795.0000 - val_loss: 2006468333876611.2500 - val_mean_squared_error: 2006468333876611.2500\n",
            "Epoch 1431/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1855025104190792.7500 - mean_squared_error: 1855025104190792.7500 - val_loss: 1995341482140527.2500 - val_mean_squared_error: 1995341482140527.2500\n",
            "Epoch 1432/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1845657139899089.2500 - mean_squared_error: 1845657139899089.2500 - val_loss: 1984483279698857.2500 - val_mean_squared_error: 1984483279698857.2500\n",
            "Epoch 1433/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1836486218812403.0000 - mean_squared_error: 1836486218812403.0000 - val_loss: 1973547629457523.7500 - val_mean_squared_error: 1973547629457523.7500\n",
            "Epoch 1434/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1827044511466144.0000 - mean_squared_error: 1827044511466144.0000 - val_loss: 1962551412518565.0000 - val_mean_squared_error: 1962551412518565.0000\n",
            "Epoch 1435/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1817619417502929.7500 - mean_squared_error: 1817619417502929.7500 - val_loss: 1951642879187187.0000 - val_mean_squared_error: 1951642879187187.0000\n",
            "Epoch 1436/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1808462496540257.7500 - mean_squared_error: 1808462496540257.7500 - val_loss: 1940782555422951.2500 - val_mean_squared_error: 1940782555422951.2500\n",
            "Epoch 1437/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1798861035451660.0000 - mean_squared_error: 1798861035451660.0000 - val_loss: 1929957546845317.0000 - val_mean_squared_error: 1929957546845317.0000\n",
            "Epoch 1438/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1789677466669664.2500 - mean_squared_error: 1789677466669664.2500 - val_loss: 1919163569482225.2500 - val_mean_squared_error: 1919163569482225.2500\n",
            "Epoch 1439/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1780836298322586.2500 - mean_squared_error: 1780836298322586.2500 - val_loss: 1908469271151795.2500 - val_mean_squared_error: 1908469271151795.2500\n",
            "Epoch 1440/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1771701587071677.0000 - mean_squared_error: 1771701587071677.0000 - val_loss: 1897868970728500.0000 - val_mean_squared_error: 1897868970728500.0000\n",
            "Epoch 1441/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1762725431380376.5000 - mean_squared_error: 1762725431380376.5000 - val_loss: 1887349246818685.7500 - val_mean_squared_error: 1887349246818685.7500\n",
            "Epoch 1442/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1753726996305592.5000 - mean_squared_error: 1753726996305592.5000 - val_loss: 1876827661680547.2500 - val_mean_squared_error: 1876827661680547.2500\n",
            "Epoch 1443/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1744776860438927.7500 - mean_squared_error: 1744776860438927.7500 - val_loss: 1870560627998997.7500 - val_mean_squared_error: 1870560627998997.7500\n",
            "Epoch 1444/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1739558413475898.0000 - mean_squared_error: 1739558413475898.0000 - val_loss: 1860657624691544.2500 - val_mean_squared_error: 1860657624691544.2500\n",
            "Epoch 1445/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1731235032823770.5000 - mean_squared_error: 1731235032823770.5000 - val_loss: 1854459313519899.2500 - val_mean_squared_error: 1854459313519899.2500\n",
            "Epoch 1446/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1725977080856344.2500 - mean_squared_error: 1725977080856344.2500 - val_loss: 1844495907305946.7500 - val_mean_squared_error: 1844495907305946.7500\n",
            "Epoch 1447/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1717322662904132.5000 - mean_squared_error: 1717322662904132.5000 - val_loss: 1834240147581888.2500 - val_mean_squared_error: 1834240147581888.2500\n",
            "Epoch 1448/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1708795240646091.0000 - mean_squared_error: 1708795240646091.0000 - val_loss: 1824320968384188.0000 - val_mean_squared_error: 1824320968384188.0000\n",
            "Epoch 1449/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1700198209125612.2500 - mean_squared_error: 1700198209125612.2500 - val_loss: 1814095552482749.2500 - val_mean_squared_error: 1814095552482749.2500\n",
            "Epoch 1450/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1691625244818111.7500 - mean_squared_error: 1691625244818111.7500 - val_loss: 1803792127645383.2500 - val_mean_squared_error: 1803792127645383.2500\n",
            "Epoch 1451/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1683142669411057.2500 - mean_squared_error: 1683142669411057.2500 - val_loss: 1793777740685265.7500 - val_mean_squared_error: 1793777740685265.7500\n",
            "Epoch 1452/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1674563068065383.5000 - mean_squared_error: 1674563068065383.5000 - val_loss: 1783724539778111.7500 - val_mean_squared_error: 1783724539778111.7500\n",
            "Epoch 1453/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1666065669667636.0000 - mean_squared_error: 1666065669667636.0000 - val_loss: 1773670412996122.0000 - val_mean_squared_error: 1773670412996122.0000\n",
            "Epoch 1454/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1657981426089358.5000 - mean_squared_error: 1657981426089358.5000 - val_loss: 1763767110542376.7500 - val_mean_squared_error: 1763767110542376.7500\n",
            "Epoch 1455/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1649517878845405.5000 - mean_squared_error: 1649517878845405.5000 - val_loss: 1755836183478272.0000 - val_mean_squared_error: 1755836183478272.0000\n",
            "Epoch 1456/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1642917893497608.2500 - mean_squared_error: 1642917893497608.2500 - val_loss: 1745864087614296.2500 - val_mean_squared_error: 1745864087614296.2500\n",
            "Epoch 1457/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1634537551942796.5000 - mean_squared_error: 1634537551942796.5000 - val_loss: 1735993241964520.7500 - val_mean_squared_error: 1735993241964520.7500\n",
            "Epoch 1458/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1626096841076405.7500 - mean_squared_error: 1626096841076405.7500 - val_loss: 1726261697633980.0000 - val_mean_squared_error: 1726261697633980.0000\n",
            "Epoch 1459/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1618127070602340.0000 - mean_squared_error: 1618127070602340.0000 - val_loss: 1716538582480074.7500 - val_mean_squared_error: 1716538582480074.7500\n",
            "Epoch 1460/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1610030961213463.2500 - mean_squared_error: 1610030961213463.2500 - val_loss: 1708010557521272.0000 - val_mean_squared_error: 1708010557521272.0000\n",
            "Epoch 1461/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1602969562820046.0000 - mean_squared_error: 1602969562820046.0000 - val_loss: 1698296838745765.0000 - val_mean_squared_error: 1698296838745765.0000\n",
            "Epoch 1462/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1594763603031354.2500 - mean_squared_error: 1594763603031354.2500 - val_loss: 1688839453081970.2500 - val_mean_squared_error: 1688839453081970.2500\n",
            "Epoch 1463/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1586866172210777.0000 - mean_squared_error: 1586866172210777.0000 - val_loss: 1679327576537192.2500 - val_mean_squared_error: 1679327576537192.2500\n",
            "Epoch 1464/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1579133322984081.5000 - mean_squared_error: 1579133322984081.5000 - val_loss: 1669924790190172.7500 - val_mean_squared_error: 1669924790190172.7500\n",
            "Epoch 1465/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1571261347305492.2500 - mean_squared_error: 1571261347305492.2500 - val_loss: 1660410351375886.7500 - val_mean_squared_error: 1660410351375886.7500\n",
            "Epoch 1466/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1563538067404136.5000 - mean_squared_error: 1563538067404136.5000 - val_loss: 1650989715208481.2500 - val_mean_squared_error: 1650989715208481.2500\n",
            "Epoch 1467/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1555430323953305.0000 - mean_squared_error: 1555430323953305.0000 - val_loss: 1641807899772453.2500 - val_mean_squared_error: 1641807899772453.2500\n",
            "Epoch 1468/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1547803088891249.5000 - mean_squared_error: 1547803088891249.5000 - val_loss: 1632454199957561.7500 - val_mean_squared_error: 1632454199957561.7500\n",
            "Epoch 1469/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1540270401011271.7500 - mean_squared_error: 1540270401011271.7500 - val_loss: 1623357403869299.7500 - val_mean_squared_error: 1623357403869299.7500\n",
            "Epoch 1470/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1532666070289928.0000 - mean_squared_error: 1532666070289928.0000 - val_loss: 1614247972357299.2500 - val_mean_squared_error: 1614247972357299.2500\n",
            "Epoch 1471/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1525412447834071.5000 - mean_squared_error: 1525412447834071.5000 - val_loss: 1605328890019562.2500 - val_mean_squared_error: 1605328890019562.2500\n",
            "Epoch 1472/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1517920732241120.5000 - mean_squared_error: 1517920732241120.5000 - val_loss: 1596244579781892.2500 - val_mean_squared_error: 1596244579781892.2500\n",
            "Epoch 1473/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1510603752563047.0000 - mean_squared_error: 1510603752563047.0000 - val_loss: 1587813408648406.0000 - val_mean_squared_error: 1587813408648406.0000\n",
            "Epoch 1474/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1503450613813416.0000 - mean_squared_error: 1503450613813416.0000 - val_loss: 1578718324215322.0000 - val_mean_squared_error: 1578718324215322.0000\n",
            "Epoch 1475/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1496373997203658.7500 - mean_squared_error: 1496373997203658.7500 - val_loss: 1569902147254191.0000 - val_mean_squared_error: 1569902147254191.0000\n",
            "Epoch 1476/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1489087478874923.0000 - mean_squared_error: 1489087478874923.0000 - val_loss: 1561544369900434.0000 - val_mean_squared_error: 1561544369900434.0000\n",
            "Epoch 1477/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1482406935458272.7500 - mean_squared_error: 1482406935458272.7500 - val_loss: 1552740512913465.7500 - val_mean_squared_error: 1552740512913465.7500\n",
            "Epoch 1478/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1475191209387409.2500 - mean_squared_error: 1475191209387409.2500 - val_loss: 1544111872431075.0000 - val_mean_squared_error: 1544111872431075.0000\n",
            "Epoch 1479/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1468137667975443.0000 - mean_squared_error: 1468137667975443.0000 - val_loss: 1535546830488292.7500 - val_mean_squared_error: 1535546830488292.7500\n",
            "Epoch 1480/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1461199556657175.2500 - mean_squared_error: 1461199556657175.2500 - val_loss: 1526971350652708.2500 - val_mean_squared_error: 1526971350652708.2500\n",
            "Epoch 1481/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1454056573272666.5000 - mean_squared_error: 1454056573272666.5000 - val_loss: 1518406290510911.7500 - val_mean_squared_error: 1518406290510911.7500\n",
            "Epoch 1482/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1447468857266668.5000 - mean_squared_error: 1447468857266668.5000 - val_loss: 1510184580928668.2500 - val_mean_squared_error: 1510184580928668.2500\n",
            "Epoch 1483/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1440602334969786.5000 - mean_squared_error: 1440602334969786.5000 - val_loss: 1501898232619424.7500 - val_mean_squared_error: 1501898232619424.7500\n",
            "Epoch 1484/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1433819441423158.7500 - mean_squared_error: 1433819441423158.7500 - val_loss: 1494195749815568.0000 - val_mean_squared_error: 1494195749815568.0000\n",
            "Epoch 1485/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1427650044486779.2500 - mean_squared_error: 1427650044486779.2500 - val_loss: 1485835667822094.5000 - val_mean_squared_error: 1485835667822094.5000\n",
            "Epoch 1486/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1420870695275344.7500 - mean_squared_error: 1420870695275344.7500 - val_loss: 1480261253351505.0000 - val_mean_squared_error: 1480261253351505.0000\n",
            "Epoch 1487/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1416316896115021.2500 - mean_squared_error: 1416316896115021.2500 - val_loss: 1471929791013650.7500 - val_mean_squared_error: 1471929791013650.7500\n",
            "Epoch 1488/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1409758255617604.7500 - mean_squared_error: 1409758255617604.7500 - val_loss: 1463867229344091.0000 - val_mean_squared_error: 1463867229344091.0000\n",
            "Epoch 1489/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1403310799795143.5000 - mean_squared_error: 1403310799795143.5000 - val_loss: 1455666089766102.0000 - val_mean_squared_error: 1455666089766102.0000\n",
            "Epoch 1490/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1396545858415429.2500 - mean_squared_error: 1396545858415429.2500 - val_loss: 1448218822351183.5000 - val_mean_squared_error: 1448218822351183.5000\n",
            "Epoch 1491/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1390841159394404.0000 - mean_squared_error: 1390841159394404.0000 - val_loss: 1441707347855255.7500 - val_mean_squared_error: 1441707347855255.7500\n",
            "Epoch 1492/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1385329821821904.2500 - mean_squared_error: 1385329821821904.2500 - val_loss: 1433607114037213.2500 - val_mean_squared_error: 1433607114037213.2500\n",
            "Epoch 1493/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1379101183990035.0000 - mean_squared_error: 1379101183990035.0000 - val_loss: 1425606864654035.2500 - val_mean_squared_error: 1425606864654035.2500\n",
            "Epoch 1494/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1372639891022229.7500 - mean_squared_error: 1372639891022229.7500 - val_loss: 1417977299991095.0000 - val_mean_squared_error: 1417977299991095.0000\n",
            "Epoch 1495/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1366921561616656.2500 - mean_squared_error: 1366921561616656.2500 - val_loss: 1410402145261440.7500 - val_mean_squared_error: 1410402145261440.7500\n",
            "Epoch 1496/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1361018619807804.7500 - mean_squared_error: 1361018619807804.7500 - val_loss: 1403073226792636.0000 - val_mean_squared_error: 1403073226792636.0000\n",
            "Epoch 1497/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1354622290925588.2500 - mean_squared_error: 1354622290925588.2500 - val_loss: 1395571457691069.5000 - val_mean_squared_error: 1395571457691069.5000\n",
            "Epoch 1498/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1348806060840609.5000 - mean_squared_error: 1348806060840609.5000 - val_loss: 1388353523823633.2500 - val_mean_squared_error: 1388353523823633.2500\n",
            "Epoch 1499/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1343170230487772.7500 - mean_squared_error: 1343170230487772.7500 - val_loss: 1381927033983600.7500 - val_mean_squared_error: 1381927033983600.7500\n",
            "Epoch 1500/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1338136173268024.5000 - mean_squared_error: 1338136173268024.5000 - val_loss: 1376687752459466.5000 - val_mean_squared_error: 1376687752459466.5000\n",
            "Epoch 1501/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1333933402753942.2500 - mean_squared_error: 1333933402753942.2500 - val_loss: 1369080411067455.7500 - val_mean_squared_error: 1369080411067455.7500\n",
            "Epoch 1502/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1328537862617861.5000 - mean_squared_error: 1328537862617861.5000 - val_loss: 1361913260979772.7500 - val_mean_squared_error: 1361913260979772.7500\n",
            "Epoch 1503/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1322739154353527.2500 - mean_squared_error: 1322739154353527.2500 - val_loss: 1354938955226997.2500 - val_mean_squared_error: 1354938955226997.2500\n",
            "Epoch 1504/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1317222707442446.0000 - mean_squared_error: 1317222707442446.0000 - val_loss: 1347507357731822.7500 - val_mean_squared_error: 1347507357731822.7500\n",
            "Epoch 1505/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1311346349903576.5000 - mean_squared_error: 1311346349903576.5000 - val_loss: 1340162484794107.7500 - val_mean_squared_error: 1340162484794107.7500\n",
            "Epoch 1506/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1305676257817891.2500 - mean_squared_error: 1305676257817891.2500 - val_loss: 1332937770087811.5000 - val_mean_squared_error: 1332937770087811.5000\n",
            "Epoch 1507/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1300231523241920.2500 - mean_squared_error: 1300231523241920.2500 - val_loss: 1328918054821193.7500 - val_mean_squared_error: 1328918054821193.7500\n",
            "Epoch 1508/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1296700487883907.7500 - mean_squared_error: 1296700487883907.7500 - val_loss: 1321632435029356.5000 - val_mean_squared_error: 1321632435029356.5000\n",
            "Epoch 1509/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1291306009529655.2500 - mean_squared_error: 1291306009529655.2500 - val_loss: 1314751207754364.5000 - val_mean_squared_error: 1314751207754364.5000\n",
            "Epoch 1510/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1285996702480323.2500 - mean_squared_error: 1285996702480323.2500 - val_loss: 1307935537308712.5000 - val_mean_squared_error: 1307935537308712.5000\n",
            "Epoch 1511/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1280887833720423.5000 - mean_squared_error: 1280887833720423.5000 - val_loss: 1303550640059131.7500 - val_mean_squared_error: 1303550640059131.7500\n",
            "Epoch 1512/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1277244572978000.7500 - mean_squared_error: 1277244572978000.7500 - val_loss: 1296583254007484.0000 - val_mean_squared_error: 1296583254007484.0000\n",
            "Epoch 1513/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1272021090951759.0000 - mean_squared_error: 1272021090951759.0000 - val_loss: 1289625703101087.0000 - val_mean_squared_error: 1289625703101087.0000\n",
            "Epoch 1514/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1266793002713574.5000 - mean_squared_error: 1266793002713574.5000 - val_loss: 1283138271682698.7500 - val_mean_squared_error: 1283138271682698.7500\n",
            "Epoch 1515/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1261636057654719.5000 - mean_squared_error: 1261636057654719.5000 - val_loss: 1277847720692626.0000 - val_mean_squared_error: 1277847720692626.0000\n",
            "Epoch 1516/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1257918594881046.5000 - mean_squared_error: 1257918594881046.5000 - val_loss: 1271318308888344.5000 - val_mean_squared_error: 1271318308888344.5000\n",
            "Epoch 1517/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1252618987993235.7500 - mean_squared_error: 1252618987993235.7500 - val_loss: 1267364609217877.2500 - val_mean_squared_error: 1267364609217877.2500\n",
            "Epoch 1518/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1249897512703788.5000 - mean_squared_error: 1249897512703788.5000 - val_loss: 1260694137425063.7500 - val_mean_squared_error: 1260694137425063.7500\n",
            "Epoch 1519/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1244637088054739.7500 - mean_squared_error: 1244637088054739.7500 - val_loss: 1254151688017792.7500 - val_mean_squared_error: 1254151688017792.7500\n",
            "Epoch 1520/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1239914813372772.2500 - mean_squared_error: 1239914813372772.2500 - val_loss: 1250194940486418.7500 - val_mean_squared_error: 1250194940486418.7500\n",
            "Epoch 1521/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1237500388888535.5000 - mean_squared_error: 1237500388888535.5000 - val_loss: 1244771106173969.2500 - val_mean_squared_error: 1244771106173969.2500\n",
            "Epoch 1522/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1232719530778612.5000 - mean_squared_error: 1232719530778612.5000 - val_loss: 1238480616048721.0000 - val_mean_squared_error: 1238480616048721.0000\n",
            "Epoch 1523/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1228177872674897.2500 - mean_squared_error: 1228177872674897.2500 - val_loss: 1232362345562297.2500 - val_mean_squared_error: 1232362345562297.2500\n",
            "Epoch 1524/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1223465225124914.7500 - mean_squared_error: 1223465225124914.7500 - val_loss: 1226079396274314.7500 - val_mean_squared_error: 1226079396274314.7500\n",
            "Epoch 1525/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1219005640829649.2500 - mean_squared_error: 1219005640829649.2500 - val_loss: 1220463525208202.7500 - val_mean_squared_error: 1220463525208202.7500\n",
            "Epoch 1526/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1214716953195764.7500 - mean_squared_error: 1214716953195764.7500 - val_loss: 1214134900091840.2500 - val_mean_squared_error: 1214134900091840.2500\n",
            "Epoch 1527/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1210119730708688.5000 - mean_squared_error: 1210119730708688.5000 - val_loss: 1208141499675295.0000 - val_mean_squared_error: 1208141499675295.0000\n",
            "Epoch 1528/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1205575755165991.5000 - mean_squared_error: 1205575755165991.5000 - val_loss: 1202147917173823.7500 - val_mean_squared_error: 1202147917173823.7500\n",
            "Epoch 1529/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1201283508240986.5000 - mean_squared_error: 1201283508240986.5000 - val_loss: 1197988905042938.2500 - val_mean_squared_error: 1197988905042938.2500\n",
            "Epoch 1530/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1198335597197204.7500 - mean_squared_error: 1198335597197204.7500 - val_loss: 1192225532959148.0000 - val_mean_squared_error: 1192225532959148.0000\n",
            "Epoch 1531/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1194086224441755.5000 - mean_squared_error: 1194086224441755.5000 - val_loss: 1186368834341222.7500 - val_mean_squared_error: 1186368834341222.7500\n",
            "Epoch 1532/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1189928221923371.5000 - mean_squared_error: 1189928221923371.5000 - val_loss: 1180866095454913.7500 - val_mean_squared_error: 1180866095454913.7500\n",
            "Epoch 1533/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1185944244601874.7500 - mean_squared_error: 1185944244601874.7500 - val_loss: 1175324201484843.5000 - val_mean_squared_error: 1175324201484843.5000\n",
            "Epoch 1534/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1181801950493538.0000 - mean_squared_error: 1181801950493538.0000 - val_loss: 1169575436574211.0000 - val_mean_squared_error: 1169575436574211.0000\n",
            "Epoch 1535/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1177519046988778.2500 - mean_squared_error: 1177519046988778.2500 - val_loss: 1164072879583255.2500 - val_mean_squared_error: 1164072879583255.2500\n",
            "Epoch 1536/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1173621936586334.7500 - mean_squared_error: 1173621936586334.7500 - val_loss: 1160945307943282.2500 - val_mean_squared_error: 1160945307943282.2500\n",
            "Epoch 1537/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1171405761178414.0000 - mean_squared_error: 1171405761178414.0000 - val_loss: 1155581486917296.5000 - val_mean_squared_error: 1155581486917296.5000\n",
            "Epoch 1538/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1167319160070851.0000 - mean_squared_error: 1167319160070851.0000 - val_loss: 1150128219633398.0000 - val_mean_squared_error: 1150128219633398.0000\n",
            "Epoch 1539/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1163647330850094.7500 - mean_squared_error: 1163647330850094.7500 - val_loss: 1146949350518066.5000 - val_mean_squared_error: 1146949350518066.5000\n",
            "Epoch 1540/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1161509234564645.0000 - mean_squared_error: 1161509234564645.0000 - val_loss: 1143818576325568.2500 - val_mean_squared_error: 1143818576325568.2500\n",
            "Epoch 1541/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1159011871023231.5000 - mean_squared_error: 1159011871023231.5000 - val_loss: 1138438451305339.0000 - val_mean_squared_error: 1138438451305339.0000\n",
            "Epoch 1542/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1155434121969270.0000 - mean_squared_error: 1155434121969270.0000 - val_loss: 1135451694583322.0000 - val_mean_squared_error: 1135451694583322.0000\n",
            "Epoch 1543/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1153327642317709.5000 - mean_squared_error: 1153327642317709.5000 - val_loss: 1130822353960127.0000 - val_mean_squared_error: 1130822353960127.0000\n",
            "Epoch 1544/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1149887910764208.0000 - mean_squared_error: 1149887910764208.0000 - val_loss: 1125648705758063.3750 - val_mean_squared_error: 1125648705758063.3750\n",
            "Epoch 1545/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1146477182674553.0000 - mean_squared_error: 1146477182674553.0000 - val_loss: 1120725826413978.6250 - val_mean_squared_error: 1120725826413978.6250\n",
            "Epoch 1546/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1143021648739610.5000 - mean_squared_error: 1143021648739610.5000 - val_loss: 1115916844082216.5000 - val_mean_squared_error: 1115916844082216.5000\n",
            "Epoch 1547/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1139814798233072.7500 - mean_squared_error: 1139814798233072.7500 - val_loss: 1111140327227392.0000 - val_mean_squared_error: 1111140327227392.0000\n",
            "Epoch 1548/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1136305072039498.7500 - mean_squared_error: 1136305072039498.7500 - val_loss: 1106258399361405.8750 - val_mean_squared_error: 1106258399361405.8750\n",
            "Epoch 1549/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1133150181733690.2500 - mean_squared_error: 1133150181733690.2500 - val_loss: 1103346970917431.0000 - val_mean_squared_error: 1103346970917431.0000\n",
            "Epoch 1550/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1131107309034511.7500 - mean_squared_error: 1131107309034511.7500 - val_loss: 1098493385598640.5000 - val_mean_squared_error: 1098493385598640.5000\n",
            "Epoch 1551/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1127964490683115.5000 - mean_squared_error: 1127964490683115.5000 - val_loss: 1093950804224775.3750 - val_mean_squared_error: 1093950804224775.3750\n",
            "Epoch 1552/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1124659580125485.2500 - mean_squared_error: 1124659580125485.2500 - val_loss: 1089287235900849.8750 - val_mean_squared_error: 1089287235900849.8750\n",
            "Epoch 1553/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1121577571374869.2500 - mean_squared_error: 1121577571374869.2500 - val_loss: 1084542534548023.0000 - val_mean_squared_error: 1084542534548023.0000\n",
            "Epoch 1554/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1118757661228476.6250 - mean_squared_error: 1118757661228476.6250 - val_loss: 1082471536663789.3750 - val_mean_squared_error: 1082471536663789.3750\n",
            "Epoch 1555/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1117137914615388.0000 - mean_squared_error: 1117137914615388.0000 - val_loss: 1079924891175178.1250 - val_mean_squared_error: 1079924891175178.1250\n",
            "Epoch 1556/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1115360867530320.3750 - mean_squared_error: 1115360867530320.3750 - val_loss: 1075482639590903.3750 - val_mean_squared_error: 1075482639590903.3750\n",
            "Epoch 1557/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1112713274579543.6250 - mean_squared_error: 1112713274579543.6250 - val_loss: 1071574086982152.6250 - val_mean_squared_error: 1071574086982152.6250\n",
            "Epoch 1558/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1109966334786564.3750 - mean_squared_error: 1109966334786564.3750 - val_loss: 1067598522262753.6250 - val_mean_squared_error: 1067598522262753.6250\n",
            "Epoch 1559/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1107425530547928.5000 - mean_squared_error: 1107425530547928.5000 - val_loss: 1063446880258591.8750 - val_mean_squared_error: 1063446880258591.8750\n",
            "Epoch 1560/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1104654310255382.8750 - mean_squared_error: 1104654310255382.8750 - val_loss: 1059174792180012.8750 - val_mean_squared_error: 1059174792180012.8750\n",
            "Epoch 1561/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1102170013578647.1250 - mean_squared_error: 1102170013578647.1250 - val_loss: 1057350825554961.3750 - val_mean_squared_error: 1057350825554961.3750\n",
            "Epoch 1562/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1100837983714169.3750 - mean_squared_error: 1100837983714169.3750 - val_loss: 1053876900020501.6250 - val_mean_squared_error: 1053876900020501.6250\n",
            "Epoch 1563/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1098462063658489.5000 - mean_squared_error: 1098462063658489.5000 - val_loss: 1051368761157296.5000 - val_mean_squared_error: 1051368761157296.5000\n",
            "Epoch 1564/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1097050227988708.7500 - mean_squared_error: 1097050227988708.7500 - val_loss: 1047279070089563.1250 - val_mean_squared_error: 1047279070089563.1250\n",
            "Epoch 1565/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1094494576910579.3750 - mean_squared_error: 1094494576910579.3750 - val_loss: 1043679492188287.3750 - val_mean_squared_error: 1043679492188287.3750\n",
            "Epoch 1566/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1092064811620047.8750 - mean_squared_error: 1092064811620047.8750 - val_loss: 1041459041205161.3750 - val_mean_squared_error: 1041459041205161.3750\n",
            "Epoch 1567/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1090711008180232.6250 - mean_squared_error: 1090711008180232.6250 - val_loss: 1037583429972824.3750 - val_mean_squared_error: 1037583429972824.3750\n",
            "Epoch 1568/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1088433113499963.6250 - mean_squared_error: 1088433113499963.6250 - val_loss: 1033873443049541.3750 - val_mean_squared_error: 1033873443049541.3750\n",
            "Epoch 1569/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1086228567716460.0000 - mean_squared_error: 1086228567716460.0000 - val_loss: 1030674776463880.6250 - val_mean_squared_error: 1030674776463880.6250\n",
            "Epoch 1570/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1084137631686853.0000 - mean_squared_error: 1084137631686853.0000 - val_loss: 1026853396219707.3750 - val_mean_squared_error: 1026853396219707.3750\n",
            "Epoch 1571/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1081902716342231.3750 - mean_squared_error: 1081902716342231.3750 - val_loss: 1023348326153406.8750 - val_mean_squared_error: 1023348326153406.8750\n",
            "Epoch 1572/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1079829331131512.2500 - mean_squared_error: 1079829331131512.2500 - val_loss: 1020135732250982.6250 - val_mean_squared_error: 1020135732250982.6250\n",
            "Epoch 1573/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1077969532860865.1250 - mean_squared_error: 1077969532860865.1250 - val_loss: 1016902272906535.0000 - val_mean_squared_error: 1016902272906535.0000\n",
            "Epoch 1574/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1075881626649340.7500 - mean_squared_error: 1075881626649340.7500 - val_loss: 1014820547473708.8750 - val_mean_squared_error: 1014820547473708.8750\n",
            "Epoch 1575/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1074720790073118.1250 - mean_squared_error: 1074720790073118.1250 - val_loss: 1013214861753442.3750 - val_mean_squared_error: 1013214861753442.3750\n",
            "Epoch 1576/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1073699042526342.6250 - mean_squared_error: 1073699042526342.6250 - val_loss: 1009836725324967.6250 - val_mean_squared_error: 1009836725324967.6250\n",
            "Epoch 1577/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1071996143806791.3750 - mean_squared_error: 1071996143806791.3750 - val_loss: 1007111835607086.3750 - val_mean_squared_error: 1007111835607086.3750\n",
            "Epoch 1578/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1070204894891435.2500 - mean_squared_error: 1070204894891435.2500 - val_loss: 1003897702252914.3750 - val_mean_squared_error: 1003897702252914.3750\n",
            "Epoch 1579/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1068522642921052.0000 - mean_squared_error: 1068522642921052.0000 - val_loss: 1000874882733304.6250 - val_mean_squared_error: 1000874882733304.6250\n",
            "Epoch 1580/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1066878970479217.7500 - mean_squared_error: 1066878970479217.7500 - val_loss: 997875737044378.6250 - val_mean_squared_error: 997875737044378.6250\n",
            "Epoch 1581/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1065150215388303.3750 - mean_squared_error: 1065150215388303.3750 - val_loss: 994936240288415.1250 - val_mean_squared_error: 994936240288415.1250\n",
            "Epoch 1582/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1063559493453815.3750 - mean_squared_error: 1063559493453815.3750 - val_loss: 993077606550047.8750 - val_mean_squared_error: 993077606550047.8750\n",
            "Epoch 1583/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1062583068784834.1250 - mean_squared_error: 1062583068784834.1250 - val_loss: 991541585109038.3750 - val_mean_squared_error: 991541585109038.3750\n",
            "Epoch 1584/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1061636441115913.0000 - mean_squared_error: 1061636441115913.0000 - val_loss: 989882124939935.1250 - val_mean_squared_error: 989882124939935.1250\n",
            "Epoch 1585/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1060820440898228.2500 - mean_squared_error: 1060820440898228.2500 - val_loss: 986922437322879.3750 - val_mean_squared_error: 986922437322879.3750\n",
            "Epoch 1586/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1059192124616095.7500 - mean_squared_error: 1059192124616095.7500 - val_loss: 983816366739710.5000 - val_mean_squared_error: 983816366739710.5000\n",
            "Epoch 1587/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1057695188600475.7500 - mean_squared_error: 1057695188600475.7500 - val_loss: 982594516271937.1250 - val_mean_squared_error: 982594516271937.1250\n",
            "Epoch 1588/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1057094696207309.3750 - mean_squared_error: 1057094696207309.3750 - val_loss: 980136432028284.3750 - val_mean_squared_error: 980136432028284.3750\n",
            "Epoch 1589/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1055661937432967.0000 - mean_squared_error: 1055661937432967.0000 - val_loss: 978602927033419.3750 - val_mean_squared_error: 978602927033419.3750\n",
            "Epoch 1590/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1054987782786405.6250 - mean_squared_error: 1054987782786405.6250 - val_loss: 976114588821816.3750 - val_mean_squared_error: 976114588821816.3750\n",
            "Epoch 1591/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1053729231385311.7500 - mean_squared_error: 1053729231385311.7500 - val_loss: 973722503788092.6250 - val_mean_squared_error: 973722503788092.6250\n",
            "Epoch 1592/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1052443660574476.6250 - mean_squared_error: 1052443660574476.6250 - val_loss: 970987874023991.0000 - val_mean_squared_error: 970987874023991.0000\n",
            "Epoch 1593/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1051369162802820.5000 - mean_squared_error: 1051369162802820.5000 - val_loss: 969416716114903.5000 - val_mean_squared_error: 969416716114903.5000\n",
            "Epoch 1594/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1050495978144439.1250 - mean_squared_error: 1050495978144439.1250 - val_loss: 968158166387602.1250 - val_mean_squared_error: 968158166387602.1250\n",
            "Epoch 1595/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1049883449439546.2500 - mean_squared_error: 1049883449439546.2500 - val_loss: 965940609878559.8750 - val_mean_squared_error: 965940609878559.8750\n",
            "Epoch 1596/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1048784092342506.7500 - mean_squared_error: 1048784092342506.7500 - val_loss: 963606503676147.0000 - val_mean_squared_error: 963606503676147.0000\n",
            "Epoch 1597/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1047726068135852.0000 - mean_squared_error: 1047726068135852.0000 - val_loss: 962530352444433.3750 - val_mean_squared_error: 962530352444433.3750\n",
            "Epoch 1598/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1047232326391666.1250 - mean_squared_error: 1047232326391666.1250 - val_loss: 960432312135425.5000 - val_mean_squared_error: 960432312135425.5000\n",
            "Epoch 1599/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1046356301519100.0000 - mean_squared_error: 1046356301519100.0000 - val_loss: 958852772295234.5000 - val_mean_squared_error: 958852772295234.5000\n",
            "Epoch 1600/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1045689998016373.0000 - mean_squared_error: 1045689998016373.0000 - val_loss: 957299051978798.3750 - val_mean_squared_error: 957299051978798.3750\n",
            "Epoch 1601/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1044913857616286.2500 - mean_squared_error: 1044913857616286.2500 - val_loss: 956205451951665.1250 - val_mean_squared_error: 956205451951665.1250\n",
            "Epoch 1602/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1044308673677558.2500 - mean_squared_error: 1044308673677558.2500 - val_loss: 953765176142599.3750 - val_mean_squared_error: 953765176142599.3750\n",
            "Epoch 1603/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1043347789978686.2500 - mean_squared_error: 1043347789978686.2500 - val_loss: 951823909449149.5000 - val_mean_squared_error: 951823909449149.5000\n",
            "Epoch 1604/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1042669930557387.8750 - mean_squared_error: 1042669930557387.8750 - val_loss: 950222766814780.6250 - val_mean_squared_error: 950222766814780.6250\n",
            "Epoch 1605/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1041944332623953.1250 - mean_squared_error: 1041944332623953.1250 - val_loss: 948342775349248.0000 - val_mean_squared_error: 948342775349248.0000\n",
            "Epoch 1606/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1041362825489777.3750 - mean_squared_error: 1041362825489777.3750 - val_loss: 947232682677729.6250 - val_mean_squared_error: 947232682677729.6250\n",
            "Epoch 1607/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1040802497751715.0000 - mean_squared_error: 1040802497751715.0000 - val_loss: 946949350946787.1250 - val_mean_squared_error: 946949350946787.1250\n",
            "Epoch 1608/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1040760147075199.5000 - mean_squared_error: 1040760147075199.5000 - val_loss: 945807943288670.0000 - val_mean_squared_error: 945807943288670.0000\n",
            "Epoch 1609/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1040256371369338.0000 - mean_squared_error: 1040256371369338.0000 - val_loss: 945361368168864.5000 - val_mean_squared_error: 945361368168864.5000\n",
            "Epoch 1610/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1040043814341503.1250 - mean_squared_error: 1040043814341503.1250 - val_loss: 944052638974877.6250 - val_mean_squared_error: 944052638974877.6250\n",
            "Epoch 1611/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1039601578318215.0000 - mean_squared_error: 1039601578318215.0000 - val_loss: 942811512077826.8750 - val_mean_squared_error: 942811512077826.8750\n",
            "Epoch 1612/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1039111257037839.8750 - mean_squared_error: 1039111257037839.8750 - val_loss: 942320135820259.1250 - val_mean_squared_error: 942320135820259.1250\n",
            "Epoch 1613/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1038865026357731.7500 - mean_squared_error: 1038865026357731.7500 - val_loss: 941020557271456.5000 - val_mean_squared_error: 941020557271456.5000\n",
            "Epoch 1614/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1038534410030507.2500 - mean_squared_error: 1038534410030507.2500 - val_loss: 940801541403387.6250 - val_mean_squared_error: 940801541403387.6250\n",
            "Epoch 1615/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1038321559270876.5000 - mean_squared_error: 1038321559270876.5000 - val_loss: 939250598032216.3750 - val_mean_squared_error: 939250598032216.3750\n",
            "Epoch 1616/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1037721452018043.5000 - mean_squared_error: 1037721452018043.5000 - val_loss: 937587559275201.6250 - val_mean_squared_error: 937587559275201.6250\n",
            "Epoch 1617/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1037270017494535.8750 - mean_squared_error: 1037270017494535.8750 - val_loss: 936271138063817.0000 - val_mean_squared_error: 936271138063817.0000\n",
            "Epoch 1618/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1036859944349458.3750 - mean_squared_error: 1036859944349458.3750 - val_loss: 934878211205339.8750 - val_mean_squared_error: 934878211205339.8750\n",
            "Epoch 1619/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1036434608606727.8750 - mean_squared_error: 1036434608606727.8750 - val_loss: 933365567875847.3750 - val_mean_squared_error: 933365567875847.3750\n",
            "Epoch 1620/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1036340048895131.0000 - mean_squared_error: 1036340048895131.0000 - val_loss: 933024868409668.0000 - val_mean_squared_error: 933024868409668.0000\n",
            "Epoch 1621/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1036135651716650.7500 - mean_squared_error: 1036135651716650.7500 - val_loss: 932837165499108.5000 - val_mean_squared_error: 932837165499108.5000\n",
            "Epoch 1622/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1036025039507832.6250 - mean_squared_error: 1036025039507832.6250 - val_loss: 932528114264098.6250 - val_mean_squared_error: 932528114264098.6250\n",
            "Epoch 1623/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1035856466740034.3750 - mean_squared_error: 1035856466740034.3750 - val_loss: 931282181558619.1250 - val_mean_squared_error: 931282181558619.1250\n",
            "Epoch 1624/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1035560166155479.7500 - mean_squared_error: 1035560166155479.7500 - val_loss: 929866582429487.6250 - val_mean_squared_error: 929866582429487.6250\n",
            "Epoch 1625/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1035237000430888.8750 - mean_squared_error: 1035237000430888.8750 - val_loss: 928586773810158.6250 - val_mean_squared_error: 928586773810158.6250\n",
            "Epoch 1626/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1034956096109989.5000 - mean_squared_error: 1034956096109989.5000 - val_loss: 927462990635239.3750 - val_mean_squared_error: 927462990635239.3750\n",
            "Epoch 1627/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1034688434399258.1250 - mean_squared_error: 1034688434399258.1250 - val_loss: 927124852409245.6250 - val_mean_squared_error: 927124852409245.6250\n",
            "Epoch 1628/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1034664123097957.0000 - mean_squared_error: 1034664123097957.0000 - val_loss: 926553425805497.1250 - val_mean_squared_error: 926553425805497.1250\n",
            "Epoch 1629/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1034503755693941.0000 - mean_squared_error: 1034503755693941.0000 - val_loss: 926802160842208.1250 - val_mean_squared_error: 926802160842208.1250\n",
            "Epoch 1630/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1034407544648670.6250 - mean_squared_error: 1034407544648670.6250 - val_loss: 926811381136852.6250 - val_mean_squared_error: 926811381136852.6250\n",
            "Epoch 1631/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1034346685831559.0000 - mean_squared_error: 1034346685831559.0000 - val_loss: 926083561964168.0000 - val_mean_squared_error: 926083561964168.0000\n",
            "Epoch 1632/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1034157118193293.1250 - mean_squared_error: 1034157118193293.1250 - val_loss: 925266437146427.3750 - val_mean_squared_error: 925266437146427.3750\n",
            "Epoch 1633/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1033925686204204.5000 - mean_squared_error: 1033925686204204.5000 - val_loss: 925103092549713.0000 - val_mean_squared_error: 925103092549713.0000\n",
            "Epoch 1634/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1033782109020310.7500 - mean_squared_error: 1033782109020310.7500 - val_loss: 924022082595221.0000 - val_mean_squared_error: 924022082595221.0000\n",
            "Epoch 1635/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1033639838798154.2500 - mean_squared_error: 1033639838798154.2500 - val_loss: 923971688382186.3750 - val_mean_squared_error: 923971688382186.3750\n",
            "Epoch 1636/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1033682228012433.1250 - mean_squared_error: 1033682228012433.1250 - val_loss: 924088499366478.1250 - val_mean_squared_error: 924088499366478.1250\n",
            "Epoch 1637/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1033554283349566.8750 - mean_squared_error: 1033554283349566.8750 - val_loss: 923863405125863.3750 - val_mean_squared_error: 923863405125863.3750\n",
            "Epoch 1638/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1033442436603429.0000 - mean_squared_error: 1033442436603429.0000 - val_loss: 923115038425180.6250 - val_mean_squared_error: 923115038425180.6250\n",
            "Epoch 1639/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1033316969510596.3750 - mean_squared_error: 1033316969510596.3750 - val_loss: 923187272589450.8750 - val_mean_squared_error: 923187272589450.8750\n",
            "Epoch 1640/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1033326783541242.2500 - mean_squared_error: 1033326783541242.2500 - val_loss: 923037188206337.5000 - val_mean_squared_error: 923037188206337.5000\n",
            "Epoch 1641/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1033152743774042.8750 - mean_squared_error: 1033152743774042.8750 - val_loss: 922924727195150.5000 - val_mean_squared_error: 922924727195150.5000\n",
            "Epoch 1642/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1033124359477268.2500 - mean_squared_error: 1033124359477268.2500 - val_loss: 921732524254063.3750 - val_mean_squared_error: 921732524254063.3750\n",
            "Epoch 1643/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1033260365224605.2500 - mean_squared_error: 1033260365224605.2500 - val_loss: 920836120017277.8750 - val_mean_squared_error: 920836120017277.8750\n",
            "Epoch 1644/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1032912760103364.0000 - mean_squared_error: 1032912760103364.0000 - val_loss: 920595819777747.1250 - val_mean_squared_error: 920595819777747.1250\n",
            "Epoch 1645/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1032835169466029.1250 - mean_squared_error: 1032835169466029.1250 - val_loss: 920058515042604.8750 - val_mean_squared_error: 920058515042604.8750\n",
            "Epoch 1646/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1032710717857502.2500 - mean_squared_error: 1032710717857502.2500 - val_loss: 919991290533112.6250 - val_mean_squared_error: 919991290533112.6250\n",
            "Epoch 1647/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1032525421598763.5000 - mean_squared_error: 1032525421598763.5000 - val_loss: 919996313771985.6250 - val_mean_squared_error: 919996313771985.6250\n",
            "Epoch 1648/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1032422161085314.0000 - mean_squared_error: 1032422161085314.0000 - val_loss: 919096473742642.6250 - val_mean_squared_error: 919096473742642.6250\n",
            "Epoch 1649/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1032391305245963.8750 - mean_squared_error: 1032391305245963.8750 - val_loss: 919389514449173.6250 - val_mean_squared_error: 919389514449173.6250\n",
            "Epoch 1650/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1032249046319358.8750 - mean_squared_error: 1032249046319358.8750 - val_loss: 919617170399463.3750 - val_mean_squared_error: 919617170399463.3750\n",
            "Epoch 1651/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1032108975597339.2500 - mean_squared_error: 1032108975597339.2500 - val_loss: 919579840125263.5000 - val_mean_squared_error: 919579840125263.5000\n",
            "Epoch 1652/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1032196108412722.2500 - mean_squared_error: 1032196108412722.2500 - val_loss: 919768791153762.3750 - val_mean_squared_error: 919768791153762.3750\n",
            "Epoch 1653/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1032034925949246.5000 - mean_squared_error: 1032034925949246.5000 - val_loss: 920002955570852.8750 - val_mean_squared_error: 920002955570852.8750\n",
            "Epoch 1654/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031956500556427.7500 - mean_squared_error: 1031956500556427.7500 - val_loss: 919704671812521.3750 - val_mean_squared_error: 919704671812521.3750\n",
            "Epoch 1655/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031938818272509.5000 - mean_squared_error: 1031938818272509.5000 - val_loss: 919457333918910.8750 - val_mean_squared_error: 919457333918910.8750\n",
            "Epoch 1656/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031795016886159.0000 - mean_squared_error: 1031795016886159.0000 - val_loss: 918719306062067.0000 - val_mean_squared_error: 918719306062067.0000\n",
            "Epoch 1657/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031766830688676.0000 - mean_squared_error: 1031766830688676.0000 - val_loss: 918171765305737.3750 - val_mean_squared_error: 918171765305737.3750\n",
            "Epoch 1658/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031792920944396.6250 - mean_squared_error: 1031792920944396.6250 - val_loss: 917597066170344.8750 - val_mean_squared_error: 917597066170344.8750\n",
            "Epoch 1659/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031735671198327.5000 - mean_squared_error: 1031735671198327.5000 - val_loss: 917945568751083.6250 - val_mean_squared_error: 917945568751083.6250\n",
            "Epoch 1660/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031575594203886.3750 - mean_squared_error: 1031575594203886.3750 - val_loss: 917911679293127.6250 - val_mean_squared_error: 917911679293127.6250\n",
            "Epoch 1661/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031654923857798.2500 - mean_squared_error: 1031654923857798.2500 - val_loss: 918072945841771.0000 - val_mean_squared_error: 918072945841771.0000\n",
            "Epoch 1662/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031692509804969.8750 - mean_squared_error: 1031692509804969.8750 - val_loss: 917419155355659.6250 - val_mean_squared_error: 917419155355659.6250\n",
            "Epoch 1663/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031467719172941.8750 - mean_squared_error: 1031467719172941.8750 - val_loss: 916965099575076.1250 - val_mean_squared_error: 916965099575076.1250\n",
            "Epoch 1664/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031339391647836.6250 - mean_squared_error: 1031339391647836.6250 - val_loss: 916413454203539.5000 - val_mean_squared_error: 916413454203539.5000\n",
            "Epoch 1665/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031416691092501.8750 - mean_squared_error: 1031416691092501.8750 - val_loss: 916726622441911.6250 - val_mean_squared_error: 916726622441911.6250\n",
            "Epoch 1666/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031366604339649.1250 - mean_squared_error: 1031366604339649.1250 - val_loss: 916070813592142.1250 - val_mean_squared_error: 916070813592142.1250\n",
            "Epoch 1667/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031290479727246.6250 - mean_squared_error: 1031290479727246.6250 - val_loss: 916433030255494.5000 - val_mean_squared_error: 916433030255494.5000\n",
            "Epoch 1668/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031154574785586.6250 - mean_squared_error: 1031154574785586.6250 - val_loss: 915623229776658.6250 - val_mean_squared_error: 915623229776658.6250\n",
            "Epoch 1669/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031318926291934.6250 - mean_squared_error: 1031318926291934.6250 - val_loss: 915343740887086.3750 - val_mean_squared_error: 915343740887086.3750\n",
            "Epoch 1670/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031177080839462.0000 - mean_squared_error: 1031177080839462.0000 - val_loss: 914797481902357.6250 - val_mean_squared_error: 914797481902357.6250\n",
            "Epoch 1671/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031088513892467.8750 - mean_squared_error: 1031088513892467.8750 - val_loss: 914672168225589.5000 - val_mean_squared_error: 914672168225589.5000\n",
            "Epoch 1672/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031142228937784.3750 - mean_squared_error: 1031142228937784.3750 - val_loss: 914318615436247.5000 - val_mean_squared_error: 914318615436247.5000\n",
            "Epoch 1673/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031035299173632.3750 - mean_squared_error: 1031035299173632.3750 - val_loss: 914536343480817.5000 - val_mean_squared_error: 914536343480817.5000\n",
            "Epoch 1674/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1031027610272833.2500 - mean_squared_error: 1031027610272833.2500 - val_loss: 914160123458207.1250 - val_mean_squared_error: 914160123458207.1250\n",
            "Epoch 1675/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030909967010432.1250 - mean_squared_error: 1030909967010432.1250 - val_loss: 914809287825465.8750 - val_mean_squared_error: 914809287825465.8750\n",
            "Epoch 1676/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030915111564555.8750 - mean_squared_error: 1030915111564555.8750 - val_loss: 914587187218975.8750 - val_mean_squared_error: 914587187218975.8750\n",
            "Epoch 1677/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030952405108820.0000 - mean_squared_error: 1030952405108820.0000 - val_loss: 914079395067082.5000 - val_mean_squared_error: 914079395067082.5000\n",
            "Epoch 1678/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030742417391778.2500 - mean_squared_error: 1030742417391778.2500 - val_loss: 913239463143736.3750 - val_mean_squared_error: 913239463143736.3750\n",
            "Epoch 1679/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030855004898276.3750 - mean_squared_error: 1030855004898276.3750 - val_loss: 912838423700427.8750 - val_mean_squared_error: 912838423700427.8750\n",
            "Epoch 1680/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030779167420688.2500 - mean_squared_error: 1030779167420688.2500 - val_loss: 913203793976834.8750 - val_mean_squared_error: 913203793976834.8750\n",
            "Epoch 1681/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030632556621887.6250 - mean_squared_error: 1030632556621887.6250 - val_loss: 912962515128574.5000 - val_mean_squared_error: 912962515128574.5000\n",
            "Epoch 1682/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030641031370332.0000 - mean_squared_error: 1030641031370332.0000 - val_loss: 913604254440315.0000 - val_mean_squared_error: 913604254440315.0000\n",
            "Epoch 1683/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030554533834792.6250 - mean_squared_error: 1030554533834792.6250 - val_loss: 913772164254054.6250 - val_mean_squared_error: 913772164254054.6250\n",
            "Epoch 1684/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030448439988901.8750 - mean_squared_error: 1030448439988901.8750 - val_loss: 913673523021349.6250 - val_mean_squared_error: 913673523021349.6250\n",
            "Epoch 1685/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030463644987548.5000 - mean_squared_error: 1030463644987548.5000 - val_loss: 913107511471410.6250 - val_mean_squared_error: 913107511471410.6250\n",
            "Epoch 1686/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030644316192605.7500 - mean_squared_error: 1030644316192605.7500 - val_loss: 913327765796227.6250 - val_mean_squared_error: 913327765796227.6250\n",
            "Epoch 1687/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030480501272408.0000 - mean_squared_error: 1030480501272408.0000 - val_loss: 913619130848689.8750 - val_mean_squared_error: 913619130848689.8750\n",
            "Epoch 1688/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030445422225735.3750 - mean_squared_error: 1030445422225735.3750 - val_loss: 913645938606450.3750 - val_mean_squared_error: 913645938606450.3750\n",
            "Epoch 1689/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030326060520797.0000 - mean_squared_error: 1030326060520797.0000 - val_loss: 914140147682564.3750 - val_mean_squared_error: 914140147682564.3750\n",
            "Epoch 1690/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030402239997306.0000 - mean_squared_error: 1030402239997306.0000 - val_loss: 913823151493096.8750 - val_mean_squared_error: 913823151493096.8750\n",
            "Epoch 1691/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030255031198727.2500 - mean_squared_error: 1030255031198727.2500 - val_loss: 913424478899090.1250 - val_mean_squared_error: 913424478899090.1250\n",
            "Epoch 1692/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030306917978372.6250 - mean_squared_error: 1030306917978372.6250 - val_loss: 913486951013335.5000 - val_mean_squared_error: 913486951013335.5000\n",
            "Epoch 1693/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030248750112802.7500 - mean_squared_error: 1030248750112802.7500 - val_loss: 913145991787629.8750 - val_mean_squared_error: 913145991787629.8750\n",
            "Epoch 1694/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030269903120989.3750 - mean_squared_error: 1030269903120989.3750 - val_loss: 912790005928746.0000 - val_mean_squared_error: 912790005928746.0000\n",
            "Epoch 1695/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030286172369400.1250 - mean_squared_error: 1030286172369400.1250 - val_loss: 913064660927389.6250 - val_mean_squared_error: 913064660927389.6250\n",
            "Epoch 1696/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030247806079978.1250 - mean_squared_error: 1030247806079978.1250 - val_loss: 913156356066842.0000 - val_mean_squared_error: 913156356066842.0000\n",
            "Epoch 1697/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030169527434406.6250 - mean_squared_error: 1030169527434406.6250 - val_loss: 912782519356768.8750 - val_mean_squared_error: 912782519356768.8750\n",
            "Epoch 1698/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030193436794428.0000 - mean_squared_error: 1030193436794428.0000 - val_loss: 912281335964712.5000 - val_mean_squared_error: 912281335964712.5000\n",
            "Epoch 1699/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030287856254906.3750 - mean_squared_error: 1030287856254906.3750 - val_loss: 912322338402419.6250 - val_mean_squared_error: 912322338402419.6250\n",
            "Epoch 1700/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030193049803143.0000 - mean_squared_error: 1030193049803143.0000 - val_loss: 912485186692414.3750 - val_mean_squared_error: 912485186692414.3750\n",
            "Epoch 1701/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1030016799430097.0000 - mean_squared_error: 1030016799430097.0000 - val_loss: 912419087097624.6250 - val_mean_squared_error: 912419087097624.6250\n",
            "Epoch 1702/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029932485542954.0000 - mean_squared_error: 1029932485542954.0000 - val_loss: 912783029515651.6250 - val_mean_squared_error: 912783029515651.6250\n",
            "Epoch 1703/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029799332396940.1250 - mean_squared_error: 1029799332396940.1250 - val_loss: 912460966446999.8750 - val_mean_squared_error: 912460966446999.8750\n",
            "Epoch 1704/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029833418146997.0000 - mean_squared_error: 1029833418146997.0000 - val_loss: 912315585578903.8750 - val_mean_squared_error: 912315585578903.8750\n",
            "Epoch 1705/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029841288013919.5000 - mean_squared_error: 1029841288013919.5000 - val_loss: 912034649159784.1250 - val_mean_squared_error: 912034649159784.1250\n",
            "Epoch 1706/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029758650994091.2500 - mean_squared_error: 1029758650994091.2500 - val_loss: 911745527159489.6250 - val_mean_squared_error: 911745527159489.6250\n",
            "Epoch 1707/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029789415899506.8750 - mean_squared_error: 1029789415899506.8750 - val_loss: 911320205675872.8750 - val_mean_squared_error: 911320205675872.8750\n",
            "Epoch 1708/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029752937960495.7500 - mean_squared_error: 1029752937960495.7500 - val_loss: 911184436541173.8750 - val_mean_squared_error: 911184436541173.8750\n",
            "Epoch 1709/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029886864661937.0000 - mean_squared_error: 1029886864661937.0000 - val_loss: 911066296160973.3750 - val_mean_squared_error: 911066296160973.3750\n",
            "Epoch 1710/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029781663354445.5000 - mean_squared_error: 1029781663354445.5000 - val_loss: 911217499878232.3750 - val_mean_squared_error: 911217499878232.3750\n",
            "Epoch 1711/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029896867916798.5000 - mean_squared_error: 1029896867916798.5000 - val_loss: 911040064841577.6250 - val_mean_squared_error: 911040064841577.6250\n",
            "Epoch 1712/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029715304980167.2500 - mean_squared_error: 1029715304980167.2500 - val_loss: 910676746563236.8750 - val_mean_squared_error: 910676746563236.8750\n",
            "Epoch 1713/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029662492250071.3750 - mean_squared_error: 1029662492250071.3750 - val_loss: 910557750829380.0000 - val_mean_squared_error: 910557750829380.0000\n",
            "Epoch 1714/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029669030570821.2500 - mean_squared_error: 1029669030570821.2500 - val_loss: 910982816673722.6250 - val_mean_squared_error: 910982816673722.6250\n",
            "Epoch 1715/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029517015799897.7500 - mean_squared_error: 1029517015799897.7500 - val_loss: 911300505006288.3750 - val_mean_squared_error: 911300505006288.3750\n",
            "Epoch 1716/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029390712931184.6250 - mean_squared_error: 1029390712931184.6250 - val_loss: 910920319020431.1250 - val_mean_squared_error: 910920319020431.1250\n",
            "Epoch 1717/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029358411213799.2500 - mean_squared_error: 1029358411213799.2500 - val_loss: 911065949846533.6250 - val_mean_squared_error: 911065949846533.6250\n",
            "Epoch 1718/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029320485545801.5000 - mean_squared_error: 1029320485545801.5000 - val_loss: 911286008632661.3750 - val_mean_squared_error: 911286008632661.3750\n",
            "Epoch 1719/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029183546064525.1250 - mean_squared_error: 1029183546064525.1250 - val_loss: 911391065722764.3750 - val_mean_squared_error: 911391065722764.3750\n",
            "Epoch 1720/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029077639449517.3750 - mean_squared_error: 1029077639449517.3750 - val_loss: 911688084667397.6250 - val_mean_squared_error: 911688084667397.6250\n",
            "Epoch 1721/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029112404403925.6250 - mean_squared_error: 1029112404403925.6250 - val_loss: 911434645998667.3750 - val_mean_squared_error: 911434645998667.3750\n",
            "Epoch 1722/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1028995976113335.8750 - mean_squared_error: 1028995976113335.8750 - val_loss: 911069405443552.1250 - val_mean_squared_error: 911069405443552.1250\n",
            "Epoch 1723/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029040852401573.5000 - mean_squared_error: 1029040852401573.5000 - val_loss: 910970628322506.5000 - val_mean_squared_error: 910970628322506.5000\n",
            "Epoch 1724/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029058194490062.3750 - mean_squared_error: 1029058194490062.3750 - val_loss: 910537840456443.6250 - val_mean_squared_error: 910537840456443.6250\n",
            "Epoch 1725/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1028969454455354.6250 - mean_squared_error: 1028969454455354.6250 - val_loss: 910169669350602.5000 - val_mean_squared_error: 910169669350602.5000\n",
            "Epoch 1726/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1028958955287819.8750 - mean_squared_error: 1028958955287819.8750 - val_loss: 909406854872162.3750 - val_mean_squared_error: 909406854872162.3750\n",
            "Epoch 1727/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029179693806906.2500 - mean_squared_error: 1029179693806906.2500 - val_loss: 909446492354201.3750 - val_mean_squared_error: 909446492354201.3750\n",
            "Epoch 1728/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029111369010023.8750 - mean_squared_error: 1029111369010023.8750 - val_loss: 909281117955760.5000 - val_mean_squared_error: 909281117955760.5000\n",
            "Epoch 1729/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029121770266960.0000 - mean_squared_error: 1029121770266960.0000 - val_loss: 909435097301084.6250 - val_mean_squared_error: 909435097301084.6250\n",
            "Epoch 1730/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029015506703036.8750 - mean_squared_error: 1029015506703036.8750 - val_loss: 909672650718769.1250 - val_mean_squared_error: 909672650718769.1250\n",
            "Epoch 1731/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1028956726267376.8750 - mean_squared_error: 1028956726267376.8750 - val_loss: 909591404876123.1250 - val_mean_squared_error: 909591404876123.1250\n",
            "Epoch 1732/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1028876097387756.1250 - mean_squared_error: 1028876097387756.1250 - val_loss: 909072642409558.6250 - val_mean_squared_error: 909072642409558.6250\n",
            "Epoch 1733/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029279243423239.8750 - mean_squared_error: 1029279243423239.8750 - val_loss: 908479845193045.3750 - val_mean_squared_error: 908479845193045.3750\n",
            "Epoch 1734/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029146277033506.1250 - mean_squared_error: 1029146277033506.1250 - val_loss: 908092063411506.6250 - val_mean_squared_error: 908092063411506.6250\n",
            "Epoch 1735/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029265709905163.8750 - mean_squared_error: 1029265709905163.8750 - val_loss: 907843883878666.1250 - val_mean_squared_error: 907843883878666.1250\n",
            "Epoch 1736/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029327789353727.6250 - mean_squared_error: 1029327789353727.6250 - val_loss: 908028831375869.1250 - val_mean_squared_error: 908028831375869.1250\n",
            "Epoch 1737/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029177352637774.6250 - mean_squared_error: 1029177352637774.6250 - val_loss: 908038603268882.6250 - val_mean_squared_error: 908038603268882.6250\n",
            "Epoch 1738/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029208450382273.1250 - mean_squared_error: 1029208450382273.1250 - val_loss: 907772147607309.0000 - val_mean_squared_error: 907772147607309.0000\n",
            "Epoch 1739/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029199288100194.7500 - mean_squared_error: 1029199288100194.7500 - val_loss: 907942843161652.1250 - val_mean_squared_error: 907942843161652.1250\n",
            "Epoch 1740/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029061097446763.6250 - mean_squared_error: 1029061097446763.6250 - val_loss: 907749675385480.0000 - val_mean_squared_error: 907749675385480.0000\n",
            "Epoch 1741/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029208417254983.7500 - mean_squared_error: 1029208417254983.7500 - val_loss: 907494526187161.3750 - val_mean_squared_error: 907494526187161.3750\n",
            "Epoch 1742/2000\n",
            "707/707 [==============================] - 1s 2ms/step - loss: 1029153135450248.1250 - mean_squared_error: 1029153135450248.1250 - val_loss: 907419882060528.1250 - val_mean_squared_error: 907419882060528.1250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jPlPEN9brXgd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5l3TPb_ORWHH",
        "colab_type": "code",
        "outputId": "18deb9df-628c-4f86-9f71-96134c228119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        }
      },
      "cell_type": "code",
      "source": [
        "train_mse = history.history['mean_squared_error']\n",
        "validation_mse = history.history['val_mean_squared_error']\n",
        "train_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(train_mse))\n",
        "\n",
        "plt.plot(epochs, train_mse, 'b-', label = 'Training MSE')\n",
        "plt.plot(epochs, validation_mse, 'r-', label = 'Validation MSE')\n",
        "plt.title('Training and validation MSE')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_loss, 'b-', label = 'Training loss')\n",
        "plt.plot(epochs, validation_loss, 'r-', label = 'Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEHCAYAAACzy817AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff9ceb74390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEHCAYAAACzy817AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnHTkSZIkDScdeZIkScNJR54kSdJw3gBHEGJhW3k1SwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff9b4157590>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3T8QnghuRWHA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#y_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XrKmUPC5RWHD",
        "colab_type": "code",
        "outputId": "4f10b885-a16b-46cc-92d9-80c1212dbb10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "y_pred = model.predict([X_test_main, X_test_aux]) \n",
        "\n",
        "print(\"Number of predictions:\", len(y_pred))\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE: \", mse)\n",
        "rmse = math.sqrt(mse)\n",
        "print(\"RMSE: \", rmse) \n",
        "y_pred = np.array([x[0] for x in y_pred]) \n",
        "\n",
        "results = pd.DataFrame({\"y\":y_test[\"precio\"], 'pred': y_pred}, columns = [ \"y\", 'pred']) \n",
        "#result[\"y\"] = y_test[\"precio\"]\n",
        "results['error'] = abs(results['pred'].astype(float) - results['y'].astype(float))\n",
        "print(\"MAPE: \", 100 * np.mean(results['error'] / y_test[\"precio\"]))\n",
        "results.sort_values(by = 'error', ascending = True)\n",
        "\n",
        "results.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Number of predictions:', 177)\n",
            "('MSE: ', 909072641186630.9)\n",
            "('RMSE: ', 30150831.517333496)\n",
            "('MAPE: ', 18.150972997740162)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>pred</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>812</th>\n",
              "      <td>185000000.0</td>\n",
              "      <td>156279584.0</td>\n",
              "      <td>28720416.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>643</th>\n",
              "      <td>170000000.0</td>\n",
              "      <td>173483824.0</td>\n",
              "      <td>3483824.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>145000000.0</td>\n",
              "      <td>141957424.0</td>\n",
              "      <td>3042576.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>120000000.0</td>\n",
              "      <td>135846992.0</td>\n",
              "      <td>15846992.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>195000000.0</td>\n",
              "      <td>163726736.0</td>\n",
              "      <td>31273264.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               y         pred       error\n",
              "812  185000000.0  156279584.0  28720416.0\n",
              "643  170000000.0  173483824.0   3483824.0\n",
              "440  145000000.0  141957424.0   3042576.0\n",
              "254  120000000.0  135846992.0  15846992.0\n",
              "883  195000000.0  163726736.0  31273264.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "8untzcXqYgfM",
        "colab_type": "code",
        "outputId": "48eb115d-8f3b-41f8-f6c7-f43f02002bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([X_train_main, X_train_aux]) \n",
        "\n",
        "print(\"Number of predictions:\", len(y_pred))\n",
        "\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "print(\"MSE: \", mse)\n",
        "rmse = math.sqrt(mse)\n",
        "print(\"RMSE: \", rmse) \n",
        "y_pred = np.array([x[0] for x in y_pred]) \n",
        "\n",
        "results = pd.DataFrame({\"y\":y_train[\"precio\"], 'pred': y_pred}, columns = [ \"y\", 'pred']) \n",
        "#result[\"y\"] = y_test[\"precio\"]\n",
        "results['error'] = abs(results['pred'].astype(float) - results['y'].astype(float))\n",
        "print(\"MAPE: \", 100 * np.mean(results['error'] / y_train[\"precio\"]))\n",
        "results.sort_values(by = 'error', ascending = True)\n",
        "\n",
        "results.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Number of predictions:', 707)\n",
            "('MSE: ', 1028935290068909.1)\n",
            "('RMSE: ', 32077021.215644527)\n",
            "('MAPE: ', 18.45192301745015)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>pred</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>130000000.0</td>\n",
              "      <td>135528816.0</td>\n",
              "      <td>5528816.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>115000000.0</td>\n",
              "      <td>136885744.0</td>\n",
              "      <td>21885744.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>91000000.0</td>\n",
              "      <td>129564544.0</td>\n",
              "      <td>38564544.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>160000000.0</td>\n",
              "      <td>146446656.0</td>\n",
              "      <td>13553344.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>94161000.0</td>\n",
              "      <td>122769808.0</td>\n",
              "      <td>28608808.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               y         pred       error\n",
              "309  130000000.0  135528816.0   5528816.0\n",
              "228  115000000.0  136885744.0  21885744.0\n",
              "110   91000000.0  129564544.0  38564544.0\n",
              "564  160000000.0  146446656.0  13553344.0\n",
              "121   94161000.0  122769808.0  28608808.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "NbFrxe6dRWHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fbbc9f26-2543-4b2c-ef21-c9222a3733c1"
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "LSTM_SIZE = 40\n",
        "DENSE1_SIZE = 256\n",
        "DENSE2_SIZE = 256\n",
        "LEARNING_RATE = 0.01\n",
        "RHO = 0.05\n",
        "EPSILON = None\n",
        "DECAY = 0.0\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(DENSE1_SIZE, input_dim=X_train_aux.shape[1], kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "# Compile model\n",
        "optimizer = RMSprop(lr = LEARNING_RATE, rho = RHO, epsilon = EPSILON, decay = DECAY)\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "model.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 256)               2816      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 3,073\n",
            "Trainable params: 3,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c9MR9oUnxOI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34034
        },
        "outputId": "a7a637b2-2564-47ea-fbf0-6c2111d4fb42"
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "#df_results = pd.read_csv(DF_RESULTS_FILENAME, index_col = 0)\n",
        "    \n",
        "PATIENCE = 10\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = int(math.ceil(y_train.shape[0] / 4))\n",
        "\n",
        "\n",
        "history = model.fit(X_train_aux, \n",
        "                    y_train,\n",
        "                    epochs = EPOCHS, \n",
        "                    batch_size = BATCH_SIZE,\n",
        "                    validation_data = (X_test_aux, y_test),\n",
        "                    verbose = 1,\n",
        "                    callbacks = [EarlyStopping(monitor = 'mean_squared_error', \n",
        "                                               restore_best_weights = True,\n",
        "                                               patience = PATIENCE)])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 707 samples, validate on 177 samples\n",
            "Epoch 1/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 983761560485725.7500 - val_loss: 881085089113961.6250\n",
            "Epoch 2/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 983709796628257.0000 - val_loss: 881256976425284.0000\n",
            "Epoch 3/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 983587700260840.7500 - val_loss: 881239478236269.8750\n",
            "Epoch 4/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 983484705240308.8750 - val_loss: 881300979265466.6250\n",
            "Epoch 5/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 983531906454390.5000 - val_loss: 881113864512737.6250\n",
            "Epoch 6/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 983490697933721.2500 - val_loss: 880978921928437.8750\n",
            "Epoch 7/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 983462421870160.3750 - val_loss: 880820424008466.6250\n",
            "Epoch 8/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 983620131971987.2500 - val_loss: 880509719574169.3750\n",
            "Epoch 9/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 983547903945124.0000 - val_loss: 880608617776122.3750\n",
            "Epoch 10/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 983547656914263.2500 - val_loss: 880318434868692.6250\n",
            "Epoch 11/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 983579592866982.6250 - val_loss: 879956050963392.3750\n",
            "Epoch 12/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 983794130543646.5000 - val_loss: 879456149467344.3750\n",
            "Epoch 13/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 983762189524540.0000 - val_loss: 878810053191992.3750\n",
            "Epoch 14/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 984006227965937.6250 - val_loss: 878597243306539.3750\n",
            "Epoch 15/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 984209791480520.6250 - val_loss: 878797555356828.3750\n",
            "Epoch 16/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 983903768772190.8750 - val_loss: 878817584621695.3750\n",
            "Epoch 17/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 983927009511508.0000 - val_loss: 878752404183745.6250\n",
            "Epoch 18/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 984065010667827.0000 - val_loss: 878556419357794.3750\n",
            "Epoch 19/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 984007945079586.3750 - val_loss: 878379768821864.1250\n",
            "Epoch 20/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 983937758320220.0000 - val_loss: 878404642063539.3750\n",
            "Epoch 21/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 983869384686689.0000 - val_loss: 878429333634979.3750\n",
            "Epoch 22/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 983844350659941.6250 - val_loss: 878324320786489.8750\n",
            "Epoch 23/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 983921820487083.2500 - val_loss: 878347742443531.6250\n",
            "Epoch 24/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 983706465484730.3750 - val_loss: 878718850859563.3750\n",
            "Epoch 25/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 983593174426747.1250 - val_loss: 878683869884346.6250\n",
            "Epoch 26/1000\n",
            "707/707 [==============================] - 0s 13us/step - loss: 983695021809768.2500 - val_loss: 878201413840456.3750\n",
            "Epoch 27/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 983890534847257.7500 - val_loss: 878197765702372.5000\n",
            "Epoch 28/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 983816634983871.5000 - val_loss: 877706831666783.5000\n",
            "Epoch 29/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 984179245058595.5000 - val_loss: 878098347154946.8750\n",
            "Epoch 30/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 984096223420497.1250 - val_loss: 877727008407644.6250\n",
            "Epoch 31/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 984038511316186.6250 - val_loss: 877731546532013.5000\n",
            "Epoch 32/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 983959385219500.7500 - val_loss: 877910829953417.3750\n",
            "Epoch 33/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 983834496762643.8750 - val_loss: 877956099408242.3750\n",
            "Epoch 34/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 983811254267295.7500 - val_loss: 877585616571467.3750\n",
            "Epoch 35/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 984168728140908.7500 - val_loss: 877851797784564.3750\n",
            "Epoch 36/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 983882197401461.0000 - val_loss: 878389886976000.0000\n",
            "Epoch 37/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 983625009656845.0000 - val_loss: 878235030114743.6250\n",
            "Epoch 38/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 983608510012408.7500 - val_loss: 878845241755636.3750\n",
            "Epoch 39/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 983273442312470.1250 - val_loss: 878833671584403.5000\n",
            "Epoch 40/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 983279560562105.7500 - val_loss: 879315487377859.3750\n",
            "Epoch 41/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 983019104416479.7500 - val_loss: 879469179857671.3750\n",
            "Epoch 42/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 982884158220337.2500 - val_loss: 879973909803308.8750\n",
            "Epoch 43/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 982795365884379.0000 - val_loss: 879668547866693.3750\n",
            "Epoch 44/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 982832175286124.3750 - val_loss: 879594296736866.3750\n",
            "Epoch 45/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 982851822521377.3750 - val_loss: 880103686915621.6250\n",
            "Epoch 46/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 982664659174442.0000 - val_loss: 880571905794464.5000\n",
            "Epoch 47/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 982472699964206.0000 - val_loss: 880324197110755.1250\n",
            "Epoch 48/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 982496621402873.8750 - val_loss: 880083849412793.1250\n",
            "Epoch 49/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 982547417568558.7500 - val_loss: 880604606353847.6250\n",
            "Epoch 50/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 982406038176230.6250 - val_loss: 880221148529473.1250\n",
            "Epoch 51/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 982369264749392.7500 - val_loss: 880074332945784.0000\n",
            "Epoch 52/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 982390838445677.3750 - val_loss: 879908908597803.3750\n",
            "Epoch 53/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 982372129215790.7500 - val_loss: 879479697628860.0000\n",
            "Epoch 54/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 982416486086641.6250 - val_loss: 879151658355324.3750\n",
            "Epoch 55/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 982410219428648.2500 - val_loss: 879403954781189.6250\n",
            "Epoch 56/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 982557920248155.6250 - val_loss: 879248246215558.5000\n",
            "Epoch 57/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 982338536910471.3750 - val_loss: 878611618667387.0000\n",
            "Epoch 58/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 982592956865320.2500 - val_loss: 878664378713730.1250\n",
            "Epoch 59/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 982726987267516.6250 - val_loss: 878774110512631.3750\n",
            "Epoch 60/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 982519926379706.7500 - val_loss: 878831771964572.3750\n",
            "Epoch 61/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 982490070244113.0000 - val_loss: 878622265899204.6250\n",
            "Epoch 62/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 982405564261406.5000 - val_loss: 879252278194662.0000\n",
            "Epoch 63/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 982242333506309.3750 - val_loss: 879899606834135.5000\n",
            "Epoch 64/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 982128409565227.5000 - val_loss: 879662739155534.1250\n",
            "Epoch 65/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 982134838062843.3750 - val_loss: 879987589970116.6250\n",
            "Epoch 66/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 982073559079697.0000 - val_loss: 879731927742660.6250\n",
            "Epoch 67/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 982131652527516.8750 - val_loss: 880064793007260.3750\n",
            "Epoch 68/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 981925113631815.0000 - val_loss: 880481996219987.8750\n",
            "Epoch 69/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 981816672755445.5000 - val_loss: 881031282600618.6250\n",
            "Epoch 70/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 981656595049099.7500 - val_loss: 880787211373735.6250\n",
            "Epoch 71/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 981681906481299.6250 - val_loss: 880476751462029.6250\n",
            "Epoch 72/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 981678182461411.0000 - val_loss: 880917802305431.8750\n",
            "Epoch 73/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 981585073706101.3750 - val_loss: 880775327029583.5000\n",
            "Epoch 74/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 981553810230235.7500 - val_loss: 881126974082400.8750\n",
            "Epoch 75/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 981592825491797.8750 - val_loss: 881474057080808.8750\n",
            "Epoch 76/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 981541928781467.7500 - val_loss: 881414518017284.3750\n",
            "Epoch 77/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 981576292601421.5000 - val_loss: 881492096432787.5000\n",
            "Epoch 78/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 981384770239515.6250 - val_loss: 881773463742591.3750\n",
            "Epoch 79/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 981258456668504.7500 - val_loss: 881642338733223.6250\n",
            "Epoch 80/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 981400856647121.0000 - val_loss: 881319427707227.1250\n",
            "Epoch 81/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 981354559978894.2500 - val_loss: 881654474418673.5000\n",
            "Epoch 82/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 981125825538329.0000 - val_loss: 881414899112456.6250\n",
            "Epoch 83/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 981164720820253.0000 - val_loss: 881037743185410.8750\n",
            "Epoch 84/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 981138184864856.3750 - val_loss: 881331703013237.1250\n",
            "Epoch 85/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 981037819714460.1250 - val_loss: 881690741756714.0000\n",
            "Epoch 86/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 980994620495243.3750 - val_loss: 881651059182944.8750\n",
            "Epoch 87/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 980870628373609.6250 - val_loss: 881552040228875.6250\n",
            "Epoch 88/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 980945502074888.6250 - val_loss: 881685255740375.5000\n",
            "Epoch 89/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 980997048279422.3750 - val_loss: 881202808751561.0000\n",
            "Epoch 90/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 981002576455150.0000 - val_loss: 881446375414928.6250\n",
            "Epoch 91/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 980839265088733.6250 - val_loss: 881284025841305.3750\n",
            "Epoch 92/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 980767442467751.6250 - val_loss: 881835322978975.1250\n",
            "Epoch 93/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 980616873788434.7500 - val_loss: 881859986697985.5000\n",
            "Epoch 94/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 980628107645860.7500 - val_loss: 881432932116699.8750\n",
            "Epoch 95/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 980729846458996.6250 - val_loss: 881261727197311.3750\n",
            "Epoch 96/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 980610388694411.3750 - val_loss: 880870187873297.3750\n",
            "Epoch 97/1000\n",
            "707/707 [==============================] - 0s 13us/step - loss: 980638741904689.6250 - val_loss: 880787236030082.1250\n",
            "Epoch 98/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 980726120777997.3750 - val_loss: 880410785691011.6250\n",
            "Epoch 99/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 980707022278731.3750 - val_loss: 880689517923403.3750\n",
            "Epoch 100/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 980576399573524.8750 - val_loss: 880405304716131.6250\n",
            "Epoch 101/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 980626818548476.7500 - val_loss: 880691012022758.0000\n",
            "Epoch 102/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 980498014427040.5000 - val_loss: 881166189755490.3750\n",
            "Epoch 103/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 980378373180935.8750 - val_loss: 881018257085873.8750\n",
            "Epoch 104/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 980311334558179.7500 - val_loss: 880984003173705.6250\n",
            "Epoch 105/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 980480027732758.8750 - val_loss: 880494866986834.5000\n",
            "Epoch 106/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 980428284520520.5000 - val_loss: 880381320249251.3750\n",
            "Epoch 107/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 980447936406882.7500 - val_loss: 880845496041194.3750\n",
            "Epoch 108/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 980302729815974.2500 - val_loss: 880501372156841.3750\n",
            "Epoch 109/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 980277234783604.2500 - val_loss: 880715428236363.3750\n",
            "Epoch 110/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 980162200485076.8750 - val_loss: 880507173516120.3750\n",
            "Epoch 111/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 980163373347737.2500 - val_loss: 880368379521058.6250\n",
            "Epoch 112/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 980170608267038.1250 - val_loss: 880013798200106.0000\n",
            "Epoch 113/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 980103059778280.3750 - val_loss: 880516695978377.3750\n",
            "Epoch 114/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 980138403938188.1250 - val_loss: 879890875649839.6250\n",
            "Epoch 115/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 980091392138163.2500 - val_loss: 879865130647552.0000\n",
            "Epoch 116/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 980018185574837.3750 - val_loss: 880406081106683.6250\n",
            "Epoch 117/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 979836313814034.7500 - val_loss: 880279796709202.5000\n",
            "Epoch 118/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 979813238616243.5000 - val_loss: 879780714556815.1250\n",
            "Epoch 119/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 979923115926048.6250 - val_loss: 879415757739256.6250\n",
            "Epoch 120/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 980068049833804.5000 - val_loss: 879217254091573.5000\n",
            "Epoch 121/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 980189744687083.7500 - val_loss: 878698452638124.1250\n",
            "Epoch 122/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 980107118061061.0000 - val_loss: 878828118094865.3750\n",
            "Epoch 123/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 980212665733820.8750 - val_loss: 878406033488346.3750\n",
            "Epoch 124/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 980152435575841.3750 - val_loss: 878414170423296.0000\n",
            "Epoch 125/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 980098501691082.1250 - val_loss: 878340585619085.6250\n",
            "Epoch 126/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 980063331710474.8750 - val_loss: 878179666759286.6250\n",
            "Epoch 127/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 980268846958699.2500 - val_loss: 877940745435703.0000\n",
            "Epoch 128/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 980228197781393.8750 - val_loss: 878417380612061.3750\n",
            "Epoch 129/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 980061046117354.1250 - val_loss: 878479766002555.0000\n",
            "Epoch 130/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 979995055702780.7500 - val_loss: 878112082289056.5000\n",
            "Epoch 131/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 980416169614537.3750 - val_loss: 877937768409955.6250\n",
            "Epoch 132/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 980235935329000.3750 - val_loss: 877665723192568.6250\n",
            "Epoch 133/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 980261172628212.1250 - val_loss: 877451092567450.6250\n",
            "Epoch 134/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 980551061468636.5000 - val_loss: 876997417482159.0000\n",
            "Epoch 135/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 980363233724963.5000 - val_loss: 876981932076246.0000\n",
            "Epoch 136/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 980230252432695.3750 - val_loss: 876729631233920.6250\n",
            "Epoch 137/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 980184466911898.3750 - val_loss: 877411159428448.8750\n",
            "Epoch 138/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 979995660726683.3750 - val_loss: 877563435501278.6250\n",
            "Epoch 139/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 979878213665161.8750 - val_loss: 878177264273211.3750\n",
            "Epoch 140/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 979666831659431.0000 - val_loss: 878468821653469.3750\n",
            "Epoch 141/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 979492619279121.0000 - val_loss: 879064570247087.0000\n",
            "Epoch 142/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 979327328011375.6250 - val_loss: 879492825752986.6250\n",
            "Epoch 143/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 979326628731317.3750 - val_loss: 879754996565726.6250\n",
            "Epoch 144/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 979225867382338.0000 - val_loss: 879464860476919.3750\n",
            "Epoch 145/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 979404275110774.5000 - val_loss: 879074095825451.3750\n",
            "Epoch 146/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 979335640303213.3750 - val_loss: 879127570363779.6250\n",
            "Epoch 147/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 979356893974696.0000 - val_loss: 879161609578530.6250\n",
            "Epoch 148/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 979327764741054.7500 - val_loss: 879378958995340.3750\n",
            "Epoch 149/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 979170002717659.7500 - val_loss: 880121509994357.1250\n",
            "Epoch 150/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 978978873920290.3750 - val_loss: 880198767788494.8750\n",
            "Epoch 151/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 978964708919194.6250 - val_loss: 879920077629474.6250\n",
            "Epoch 152/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 978952017275647.6250 - val_loss: 880528427834697.6250\n",
            "Epoch 153/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 978886840093312.1250 - val_loss: 880775039533148.6250\n",
            "Epoch 154/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 978720423921539.3750 - val_loss: 880286402856485.6250\n",
            "Epoch 155/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 978818123321813.2500 - val_loss: 880053996919119.5000\n",
            "Epoch 156/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 978968599999338.8750 - val_loss: 879563188777816.3750\n",
            "Epoch 157/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 978926554065408.7500 - val_loss: 879296008870131.0000\n",
            "Epoch 158/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 978897015059538.6250 - val_loss: 878980408776669.3750\n",
            "Epoch 159/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 979170158672205.1250 - val_loss: 879161929397172.6250\n",
            "Epoch 160/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 978964469244680.2500 - val_loss: 879523968104737.3750\n",
            "Epoch 161/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 978806554731341.8750 - val_loss: 879934088382082.1250\n",
            "Epoch 162/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 978722475345540.5000 - val_loss: 880572801005857.3750\n",
            "Epoch 163/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 978691123735898.1250 - val_loss: 880047621120879.3750\n",
            "Epoch 164/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 978669153413887.6250 - val_loss: 880617605660116.6250\n",
            "Epoch 165/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 978582623225661.8750 - val_loss: 880726773538399.5000\n",
            "Epoch 166/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 978526877591415.8750 - val_loss: 881264086906521.3750\n",
            "Epoch 167/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 978389853440964.6250 - val_loss: 880999853021982.3750\n",
            "Epoch 168/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 978288918624589.1250 - val_loss: 881669282437085.3750\n",
            "Epoch 169/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 978241631602285.3750 - val_loss: 882111632152171.0000\n",
            "Epoch 170/1000\n",
            "707/707 [==============================] - 0s 31us/step - loss: 978187787797175.1250 - val_loss: 882098384619230.6250\n",
            "Epoch 171/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 978079647415694.2500 - val_loss: 882117499881275.3750\n",
            "Epoch 172/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 978077295900217.1250 - val_loss: 882525445567505.3750\n",
            "Epoch 173/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 978041705563734.1250 - val_loss: 882433647538754.5000\n",
            "Epoch 174/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 977997666392130.7500 - val_loss: 882289840686907.3750\n",
            "Epoch 175/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 977900459107706.0000 - val_loss: 882433611793865.0000\n",
            "Epoch 176/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 977947720786209.7500 - val_loss: 882556856094048.8750\n",
            "Epoch 177/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 978024755022719.1250 - val_loss: 883182830683222.6250\n",
            "Epoch 178/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 977791952380170.5000 - val_loss: 882686695255994.6250\n",
            "Epoch 179/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 977827636450745.7500 - val_loss: 883153604376032.1250\n",
            "Epoch 180/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 977810354743623.3750 - val_loss: 882871116881966.3750\n",
            "Epoch 181/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 977836161459647.5000 - val_loss: 882241495705357.0000\n",
            "Epoch 182/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 978066694835418.6250 - val_loss: 881665004401033.3750\n",
            "Epoch 183/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 977960479348779.5000 - val_loss: 881898101341097.3750\n",
            "Epoch 184/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 977901241111066.8750 - val_loss: 882115219413605.3750\n",
            "Epoch 185/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 977913986859355.6250 - val_loss: 882349346786934.6250\n",
            "Epoch 186/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 977796204888295.6250 - val_loss: 881743118850661.3750\n",
            "Epoch 187/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 977829484554822.2500 - val_loss: 881602324111869.1250\n",
            "Epoch 188/1000\n",
            "707/707 [==============================] - 0s 25us/step - loss: 977895878856547.5000 - val_loss: 881879609475257.1250\n",
            "Epoch 189/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 977838906515931.0000 - val_loss: 882095993061746.3750\n",
            "Epoch 190/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 977792190915637.5000 - val_loss: 882142086564013.5000\n",
            "Epoch 191/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 977785335038021.6250 - val_loss: 881511359881725.1250\n",
            "Epoch 192/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 977777083969970.5000 - val_loss: 881682072913815.8750\n",
            "Epoch 193/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 977717587880448.7500 - val_loss: 881953385169173.6250\n",
            "Epoch 194/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 977640744814027.1250 - val_loss: 881679571150697.6250\n",
            "Epoch 195/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 977782717626214.3750 - val_loss: 881357754846931.1250\n",
            "Epoch 196/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 977818022797485.7500 - val_loss: 881352878792287.5000\n",
            "Epoch 197/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 977707604558913.2500 - val_loss: 881142187975257.6250\n",
            "Epoch 198/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 977712383146664.7500 - val_loss: 881521692077177.5000\n",
            "Epoch 199/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 977583492932244.3750 - val_loss: 881773284957421.3750\n",
            "Epoch 200/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 977434100532729.5000 - val_loss: 881762036216201.3750\n",
            "Epoch 201/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 977487349422980.8750 - val_loss: 881270323740301.6250\n",
            "Epoch 202/1000\n",
            "707/707 [==============================] - 0s 27us/step - loss: 977517764261224.6250 - val_loss: 881541690850402.3750\n",
            "Epoch 203/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 977395597462723.6250 - val_loss: 881721450865889.6250\n",
            "Epoch 204/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 977361867356423.6250 - val_loss: 880916559836177.3750\n",
            "Epoch 205/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 977509247890097.3750 - val_loss: 880763045270684.3750\n",
            "Epoch 206/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 977550409828482.3750 - val_loss: 880881520978972.8750\n",
            "Epoch 207/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 977350508564207.7500 - val_loss: 880575773387064.3750\n",
            "Epoch 208/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 977371319336172.1250 - val_loss: 881144864871302.5000\n",
            "Epoch 209/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 977193323658059.0000 - val_loss: 881179263712076.6250\n",
            "Epoch 210/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 977241014235292.5000 - val_loss: 880945267302631.3750\n",
            "Epoch 211/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 977186897913140.5000 - val_loss: 881512311368177.5000\n",
            "Epoch 212/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 977013496676815.5000 - val_loss: 881314640460157.8750\n",
            "Epoch 213/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 977077127365280.1250 - val_loss: 881398792671116.3750\n",
            "Epoch 214/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 977028817526054.0000 - val_loss: 881710549730575.8750\n",
            "Epoch 215/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 976876788944183.3750 - val_loss: 880911035475725.0000\n",
            "Epoch 216/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 977033673260523.1250 - val_loss: 880565629910114.3750\n",
            "Epoch 217/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 976952747303155.3750 - val_loss: 880613326902798.5000\n",
            "Epoch 218/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 977067860077288.3750 - val_loss: 880618593008460.6250\n",
            "Epoch 219/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 976897943471099.6250 - val_loss: 880299381207526.0000\n",
            "Epoch 220/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976910666343523.8750 - val_loss: 880375026959724.5000\n",
            "Epoch 221/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 976932184273956.2500 - val_loss: 880032722148866.8750\n",
            "Epoch 222/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 976882246261683.2500 - val_loss: 880216188203679.1250\n",
            "Epoch 223/1000\n",
            "707/707 [==============================] - 0s 26us/step - loss: 976839567681956.0000 - val_loss: 880308699892070.6250\n",
            "Epoch 224/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 976783431354521.6250 - val_loss: 879840465217941.0000\n",
            "Epoch 225/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 976915718112761.5000 - val_loss: 879881031729429.6250\n",
            "Epoch 226/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 976874217212915.0000 - val_loss: 880338149457086.8750\n",
            "Epoch 227/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 976757095539209.3750 - val_loss: 880524833175471.0000\n",
            "Epoch 228/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 976593773767122.3750 - val_loss: 879931066397898.5000\n",
            "Epoch 229/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976696074502792.8750 - val_loss: 879746226952897.6250\n",
            "Epoch 230/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 976647498838427.3750 - val_loss: 879407263989297.1250\n",
            "Epoch 231/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976807017913313.5000 - val_loss: 879129329418147.3750\n",
            "Epoch 232/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 976851104046883.8750 - val_loss: 879240437834422.3750\n",
            "Epoch 233/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 976608013245293.7500 - val_loss: 878820590637310.5000\n",
            "Epoch 234/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 976637845271055.1250 - val_loss: 878773640605441.5000\n",
            "Epoch 235/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976526217696582.0000 - val_loss: 879190241873341.5000\n",
            "Epoch 236/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 976417726227532.7500 - val_loss: 878395654819354.0000\n",
            "Epoch 237/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 976643468936906.1250 - val_loss: 878063641777493.3750\n",
            "Epoch 238/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 976761179877694.5000 - val_loss: 877757215154129.6250\n",
            "Epoch 239/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 976777705838867.1250 - val_loss: 878247862161292.3750\n",
            "Epoch 240/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976742321812307.6250 - val_loss: 877772042300167.3750\n",
            "Epoch 241/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 976764699438611.5000 - val_loss: 878075726364116.6250\n",
            "Epoch 242/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976627529015516.1250 - val_loss: 878393057943876.0000\n",
            "Epoch 243/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 976552454794470.2500 - val_loss: 878183262258262.6250\n",
            "Epoch 244/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 976501774787869.3750 - val_loss: 878728723993478.5000\n",
            "Epoch 245/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 976312314742103.2500 - val_loss: 878738608347749.3750\n",
            "Epoch 246/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 976329736041832.6250 - val_loss: 878263075903083.0000\n",
            "Epoch 247/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 976403572593178.8750 - val_loss: 878265145940211.0000\n",
            "Epoch 248/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 976378969648335.1250 - val_loss: 878537157623900.6250\n",
            "Epoch 249/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 976294012199526.0000 - val_loss: 878648880384266.1250\n",
            "Epoch 250/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976481952424109.7500 - val_loss: 878325663064480.5000\n",
            "Epoch 251/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 976367173106043.5000 - val_loss: 878587819075711.3750\n",
            "Epoch 252/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 976217533912969.2500 - val_loss: 878618563726874.0000\n",
            "Epoch 253/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 976189981737632.1250 - val_loss: 878145322998373.3750\n",
            "Epoch 254/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976247123226757.2500 - val_loss: 877846484309333.3750\n",
            "Epoch 255/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 976408776615058.2500 - val_loss: 877546918800135.3750\n",
            "Epoch 256/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 976614276106463.0000 - val_loss: 876971816188100.6250\n",
            "Epoch 257/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 976665796824815.7500 - val_loss: 877239955862730.5000\n",
            "Epoch 258/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976417915855160.7500 - val_loss: 876885761027934.0000\n",
            "Epoch 259/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 976628051648338.2500 - val_loss: 876316444514547.0000\n",
            "Epoch 260/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 976583842663781.6250 - val_loss: 876260687824606.6250\n",
            "Epoch 261/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 976587018422286.3750 - val_loss: 876379261965745.8750\n",
            "Epoch 262/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976668795651322.6250 - val_loss: 875936931290904.6250\n",
            "Epoch 263/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 976800919051210.5000 - val_loss: 876096499593702.0000\n",
            "Epoch 264/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 976631153938298.7500 - val_loss: 876697240037040.5000\n",
            "Epoch 265/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 976418494396216.1250 - val_loss: 876645355077724.6250\n",
            "Epoch 266/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 976305795405473.5000 - val_loss: 876807323174067.3750\n",
            "Epoch 267/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 976645901419654.6250 - val_loss: 876200587642590.6250\n",
            "Epoch 268/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 976483688474418.2500 - val_loss: 876095536609939.5000\n",
            "Epoch 269/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 976471754154876.2500 - val_loss: 875952547170477.5000\n",
            "Epoch 270/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976431497569171.2500 - val_loss: 875496770602626.1250\n",
            "Epoch 271/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 976850194992300.3750 - val_loss: 875141977137568.5000\n",
            "Epoch 272/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 976742804103874.8750 - val_loss: 875063738915984.6250\n",
            "Epoch 273/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 976846901911934.3750 - val_loss: 875329766557129.0000\n",
            "Epoch 274/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 976691129614150.6250 - val_loss: 875293417166535.6250\n",
            "Epoch 275/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 976617965456602.6250 - val_loss: 875602317537673.3750\n",
            "Epoch 276/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 976603561516627.2500 - val_loss: 876011185376886.6250\n",
            "Epoch 277/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 976531401713945.0000 - val_loss: 876119358144697.1250\n",
            "Epoch 278/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 976365620584714.5000 - val_loss: 876129794387620.8750\n",
            "Epoch 279/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 976367774973836.1250 - val_loss: 876508914789219.6250\n",
            "Epoch 280/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 976256449840123.6250 - val_loss: 876325173951216.1250\n",
            "Epoch 281/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 976326276874147.3750 - val_loss: 876199656554496.0000\n",
            "Epoch 282/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 976423115368311.8750 - val_loss: 876063859748054.0000\n",
            "Epoch 283/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 976371849084626.7500 - val_loss: 876565806615997.5000\n",
            "Epoch 284/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 976287993948742.2500 - val_loss: 876912727588678.8750\n",
            "Epoch 285/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 976090107516577.5000 - val_loss: 876871566972985.8750\n",
            "Epoch 286/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 976076641036175.0000 - val_loss: 876836404626703.8750\n",
            "Epoch 287/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 975950763174447.0000 - val_loss: 877187662560076.6250\n",
            "Epoch 288/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 975787368847426.7500 - val_loss: 877363520807976.5000\n",
            "Epoch 289/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 975540505806283.1250 - val_loss: 878106040106822.8750\n",
            "Epoch 290/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 975389061935306.8750 - val_loss: 878009063823232.6250\n",
            "Epoch 291/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 975355790793836.7500 - val_loss: 877573960873162.5000\n",
            "Epoch 292/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 975506194952024.0000 - val_loss: 878135363531700.6250\n",
            "Epoch 293/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 975411262392311.3750 - val_loss: 877679986486115.6250\n",
            "Epoch 294/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 975489041850449.1250 - val_loss: 877298020963114.0000\n",
            "Epoch 295/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 975654410383562.8750 - val_loss: 877752026874133.6250\n",
            "Epoch 296/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 975402837334801.0000 - val_loss: 877693213555532.6250\n",
            "Epoch 297/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 975434997952714.8750 - val_loss: 877445346536847.1250\n",
            "Epoch 298/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 975445325385154.5000 - val_loss: 877770630727298.1250\n",
            "Epoch 299/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 975318204300871.7500 - val_loss: 878027116768192.3750\n",
            "Epoch 300/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 975156443676023.1250 - val_loss: 877713427150581.8750\n",
            "Epoch 301/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 975242096892828.1250 - val_loss: 878033168009945.0000\n",
            "Epoch 302/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 975105848243676.5000 - val_loss: 878638566464841.6250\n",
            "Epoch 303/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 974913223450195.2500 - val_loss: 878896044652648.1250\n",
            "Epoch 304/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974881533875757.6250 - val_loss: 878844010143882.8750\n",
            "Epoch 305/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 974840046739398.1250 - val_loss: 879121570228258.6250\n",
            "Epoch 306/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 974783927604457.1250 - val_loss: 878918531827052.5000\n",
            "Epoch 307/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 974703990779063.8750 - val_loss: 878987397267641.1250\n",
            "Epoch 308/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 974684365090787.0000 - val_loss: 879093538024014.1250\n",
            "Epoch 309/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 974546759563527.6250 - val_loss: 878884214286463.3750\n",
            "Epoch 310/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974562909532339.5000 - val_loss: 878610403407791.0000\n",
            "Epoch 311/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 974484747354343.6250 - val_loss: 878917489425506.3750\n",
            "Epoch 312/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 974473127174526.3750 - val_loss: 878678243314393.0000\n",
            "Epoch 313/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 974489055325762.0000 - val_loss: 879273789840898.8750\n",
            "Epoch 314/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974448198367263.8750 - val_loss: 879605307082555.3750\n",
            "Epoch 315/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 974367771953282.3750 - val_loss: 879100305563138.8750\n",
            "Epoch 316/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974347050596522.8750 - val_loss: 879137665234492.6250\n",
            "Epoch 317/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 974425547559474.0000 - val_loss: 878680372579773.5000\n",
            "Epoch 318/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 974400128012711.0000 - val_loss: 878452965100526.6250\n",
            "Epoch 319/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 974495276421867.5000 - val_loss: 878525655755249.5000\n",
            "Epoch 320/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 974423563908781.1250 - val_loss: 878140651244249.0000\n",
            "Epoch 321/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 974529816699216.0000 - val_loss: 877666509815622.8750\n",
            "Epoch 322/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 974510997930957.3750 - val_loss: 877768835664415.8750\n",
            "Epoch 323/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 974549913858111.6250 - val_loss: 877492854057179.8750\n",
            "Epoch 324/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 974488902123913.8750 - val_loss: 878204061834014.3750\n",
            "Epoch 325/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974388859228953.7500 - val_loss: 878503632027740.6250\n",
            "Epoch 326/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 974208490179895.3750 - val_loss: 878133749850250.8750\n",
            "Epoch 327/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974282111332670.5000 - val_loss: 877989619958500.5000\n",
            "Epoch 328/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 974334491889275.8750 - val_loss: 878174347185134.6250\n",
            "Epoch 329/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974272519084005.8750 - val_loss: 878606381390159.5000\n",
            "Epoch 330/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974153919354182.0000 - val_loss: 878323919472165.6250\n",
            "Epoch 331/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974501151484926.5000 - val_loss: 878080160193680.6250\n",
            "Epoch 332/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 974251147758439.8750 - val_loss: 877702475827281.0000\n",
            "Epoch 333/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 974222093132390.0000 - val_loss: 876922307118351.8750\n",
            "Epoch 334/1000\n",
            "707/707 [==============================] - 0s 25us/step - loss: 974454403231946.8750 - val_loss: 876464886546246.8750\n",
            "Epoch 335/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 974462155682087.5000 - val_loss: 876009704035206.5000\n",
            "Epoch 336/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974539633197797.5000 - val_loss: 875986996819794.5000\n",
            "Epoch 337/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974487797770196.5000 - val_loss: 876761848139104.8750\n",
            "Epoch 338/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 974317938923192.6250 - val_loss: 876438192419764.6250\n",
            "Epoch 339/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 974400863077835.1250 - val_loss: 877068773723211.3750\n",
            "Epoch 340/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 974290465864175.3750 - val_loss: 877383608704237.3750\n",
            "Epoch 341/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 974117035297384.8750 - val_loss: 877712619831481.1250\n",
            "Epoch 342/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 974117417596032.8750 - val_loss: 877489115587531.8750\n",
            "Epoch 343/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 974014178101563.6250 - val_loss: 877756463137045.6250\n",
            "Epoch 344/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 974057941718666.2500 - val_loss: 878019784588664.0000\n",
            "Epoch 345/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 973926563730248.1250 - val_loss: 877857872035747.3750\n",
            "Epoch 346/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 974008991829836.5000 - val_loss: 877625987224362.0000\n",
            "Epoch 347/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 974053642479943.3750 - val_loss: 877781307079315.5000\n",
            "Epoch 348/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 973974156064660.7500 - val_loss: 877991336116038.8750\n",
            "Epoch 349/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 973808103154023.1250 - val_loss: 878664392004579.1250\n",
            "Epoch 350/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 973800369296455.0000 - val_loss: 878815600908438.3750\n",
            "Epoch 351/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 973736551388972.5000 - val_loss: 878496509902570.3750\n",
            "Epoch 352/1000\n",
            "707/707 [==============================] - 0s 26us/step - loss: 973743146567161.5000 - val_loss: 878808592669285.3750\n",
            "Epoch 353/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 973698216945412.0000 - val_loss: 879027796306139.8750\n",
            "Epoch 354/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 973539929738203.7500 - val_loss: 879043669845125.0000\n",
            "Epoch 355/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 973637161547738.3750 - val_loss: 879277570977815.1250\n",
            "Epoch 356/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 973459193633900.7500 - val_loss: 878845449019716.0000\n",
            "Epoch 357/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 973470738209460.2500 - val_loss: 879477963260459.3750\n",
            "Epoch 358/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 973474220288605.3750 - val_loss: 879248249099142.5000\n",
            "Epoch 359/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 973489112274709.2500 - val_loss: 879433114982180.1250\n",
            "Epoch 360/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 973460487828817.5000 - val_loss: 879536709566464.0000\n",
            "Epoch 361/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 973379144861525.1250 - val_loss: 879717443874931.6250\n",
            "Epoch 362/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 973317456818054.2500 - val_loss: 879770687462914.8750\n",
            "Epoch 363/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 973259483326142.3750 - val_loss: 879518223140482.1250\n",
            "Epoch 364/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 973319939703641.3750 - val_loss: 879657745309372.0000\n",
            "Epoch 365/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 973226677319341.1250 - val_loss: 879247591970781.3750\n",
            "Epoch 366/1000\n",
            "707/707 [==============================] - 0s 26us/step - loss: 973278277011632.6250 - val_loss: 879472171713067.3750\n",
            "Epoch 367/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 973229917623853.6250 - val_loss: 879100834316473.1250\n",
            "Epoch 368/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 973192720518918.8750 - val_loss: 879587050103663.3750\n",
            "Epoch 369/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 973024651115060.8750 - val_loss: 878927707851943.6250\n",
            "Epoch 370/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 973030144360007.7500 - val_loss: 878391745812445.3750\n",
            "Epoch 371/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 973030801637700.5000 - val_loss: 877965463991683.6250\n",
            "Epoch 372/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 973080095234021.8750 - val_loss: 878333936681608.0000\n",
            "Epoch 373/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 972936410505088.5000 - val_loss: 877885151803773.8750\n",
            "Epoch 374/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 972944938741290.7500 - val_loss: 877710867092266.0000\n",
            "Epoch 375/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 972986290046272.1250 - val_loss: 877839497771852.6250\n",
            "Epoch 376/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 972996621892519.6250 - val_loss: 878210348722488.3750\n",
            "Epoch 377/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 972869461772140.3750 - val_loss: 878463013077084.6250\n",
            "Epoch 378/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 972928358960138.1250 - val_loss: 878388168765740.8750\n",
            "Epoch 379/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 973018703247901.7500 - val_loss: 878066753976239.0000\n",
            "Epoch 380/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 972917994484934.5000 - val_loss: 877791507108279.6250\n",
            "Epoch 381/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 973012384620880.0000 - val_loss: 877663997430489.0000\n",
            "Epoch 382/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 972987936159312.3750 - val_loss: 878115227723810.6250\n",
            "Epoch 383/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 972884203605720.5000 - val_loss: 878402135709198.5000\n",
            "Epoch 384/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 972763893169388.1250 - val_loss: 877953883395413.3750\n",
            "Epoch 385/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 972856958071380.7500 - val_loss: 877879662969017.1250\n",
            "Epoch 386/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 972762421900092.3750 - val_loss: 877764948060009.6250\n",
            "Epoch 387/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 972717041690256.0000 - val_loss: 877688677048458.8750\n",
            "Epoch 388/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 973021719729640.0000 - val_loss: 877269090346950.1250\n",
            "Epoch 389/1000\n",
            "707/707 [==============================] - 0s 28us/step - loss: 972847349899785.3750 - val_loss: 876824273714644.6250\n",
            "Epoch 390/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 972843253909796.6250 - val_loss: 877009329658006.3750\n",
            "Epoch 391/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 972785582241661.6250 - val_loss: 876574693533082.6250\n",
            "Epoch 392/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 972829716571166.5000 - val_loss: 876719736096201.0000\n",
            "Epoch 393/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 972808357490357.7500 - val_loss: 876571257777551.1250\n",
            "Epoch 394/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 972828659108225.2500 - val_loss: 876676662574270.8750\n",
            "Epoch 395/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 972694659697604.6250 - val_loss: 876881454708469.8750\n",
            "Epoch 396/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 972538294051152.0000 - val_loss: 877449936497600.3750\n",
            "Epoch 397/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 972394166232859.2500 - val_loss: 877919134420598.6250\n",
            "Epoch 398/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 972355405405964.6250 - val_loss: 878282506511030.3750\n",
            "Epoch 399/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 972241418485064.8750 - val_loss: 878014368449252.5000\n",
            "Epoch 400/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 972232208956258.1250 - val_loss: 877882551606324.1250\n",
            "Epoch 401/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 972163606374240.6250 - val_loss: 878324264980919.6250\n",
            "Epoch 402/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 972014069125890.5000 - val_loss: 878778061738053.3750\n",
            "Epoch 403/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 971961950597600.7500 - val_loss: 879335528031920.5000\n",
            "Epoch 404/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 971877566753975.8750 - val_loss: 879576296886434.0000\n",
            "Epoch 405/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 971788201762039.7500 - val_loss: 879223271527117.3750\n",
            "Epoch 406/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 971939088116873.5000 - val_loss: 878674737975180.3750\n",
            "Epoch 407/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 971852168279586.1250 - val_loss: 878873868096668.3750\n",
            "Epoch 408/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 971812802713550.7500 - val_loss: 878951288698521.3750\n",
            "Epoch 409/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 971679991376616.3750 - val_loss: 879555291255131.1250\n",
            "Epoch 410/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 971685266541485.3750 - val_loss: 879780311551143.6250\n",
            "Epoch 411/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 971538442408636.8750 - val_loss: 879816104778063.5000\n",
            "Epoch 412/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 971497122474913.8750 - val_loss: 880038406912567.0000\n",
            "Epoch 413/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 971482216855838.8750 - val_loss: 880354077884878.8750\n",
            "Epoch 414/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 971295784634822.8750 - val_loss: 880254891786610.3750\n",
            "Epoch 415/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 971270635327007.2500 - val_loss: 879920506043120.1250\n",
            "Epoch 416/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 971204181889748.2500 - val_loss: 880141008560544.5000\n",
            "Epoch 417/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 971220787584224.5000 - val_loss: 880257377027991.8750\n",
            "Epoch 418/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 971174247634500.8750 - val_loss: 880196688617796.0000\n",
            "Epoch 419/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 971084892609227.5000 - val_loss: 880692288835098.0000\n",
            "Epoch 420/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 971008253194952.6250 - val_loss: 880199816597018.0000\n",
            "Epoch 421/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 970967724566809.0000 - val_loss: 880326308890242.1250\n",
            "Epoch 422/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 970833954816579.3750 - val_loss: 880069750636821.6250\n",
            "Epoch 423/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 970898730342397.1250 - val_loss: 880308464640046.3750\n",
            "Epoch 424/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 970891812339248.5000 - val_loss: 879906061090445.6250\n",
            "Epoch 425/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 970775967347609.2500 - val_loss: 879319829471833.6250\n",
            "Epoch 426/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 970788193405614.5000 - val_loss: 879646975858468.1250\n",
            "Epoch 427/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 970749533384397.0000 - val_loss: 879204996672818.6250\n",
            "Epoch 428/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 970754187056639.2500 - val_loss: 878736855073138.3750\n",
            "Epoch 429/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 970800263509074.6250 - val_loss: 879228343713606.8750\n",
            "Epoch 430/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 970738296683802.5000 - val_loss: 878641044885295.6250\n",
            "Epoch 431/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 970676704984740.3750 - val_loss: 878912394893092.1250\n",
            "Epoch 432/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 970726000764235.7500 - val_loss: 878229825441861.3750\n",
            "Epoch 433/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 970677807962109.1250 - val_loss: 877987478221286.0000\n",
            "Epoch 434/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 970855948536517.7500 - val_loss: 877712491096561.5000\n",
            "Epoch 435/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 970746743217098.5000 - val_loss: 877466464710864.3750\n",
            "Epoch 436/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 970866678123808.2500 - val_loss: 877607486601135.0000\n",
            "Epoch 437/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 970625950845151.0000 - val_loss: 877495469975864.3750\n",
            "Epoch 438/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 970620060737176.8750 - val_loss: 877257907532724.6250\n",
            "Epoch 439/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 970703256602035.8750 - val_loss: 876707009970638.8750\n",
            "Epoch 440/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 970757766417534.0000 - val_loss: 876696600784826.6250\n",
            "Epoch 441/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 970785489117728.6250 - val_loss: 877170559355423.8750\n",
            "Epoch 442/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 970607888024548.3750 - val_loss: 877690129772011.6250\n",
            "Epoch 443/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 970417872645813.7500 - val_loss: 876958315398878.6250\n",
            "Epoch 444/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 970531387241809.5000 - val_loss: 877423346664442.3750\n",
            "Epoch 445/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 970451686021209.7500 - val_loss: 876767760919951.1250\n",
            "Epoch 446/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 970537287791049.7500 - val_loss: 876754586000898.8750\n",
            "Epoch 447/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 970494918177874.6250 - val_loss: 876460436810318.1250\n",
            "Epoch 448/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 970504472790521.5000 - val_loss: 876230749363992.6250\n",
            "Epoch 449/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 970464990187386.7500 - val_loss: 876050828150679.8750\n",
            "Epoch 450/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 970459983790195.8750 - val_loss: 876301521940688.3750\n",
            "Epoch 451/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 970299762658823.8750 - val_loss: 876759482954491.6250\n",
            "Epoch 452/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 970389304962440.5000 - val_loss: 877049900975468.5000\n",
            "Epoch 453/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 970194601028143.0000 - val_loss: 876707381670096.3750\n",
            "Epoch 454/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 970348518790979.7500 - val_loss: 876742745436275.6250\n",
            "Epoch 455/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 970181003035249.7500 - val_loss: 876256613478886.0000\n",
            "Epoch 456/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 970434225887090.1250 - val_loss: 876456138217437.3750\n",
            "Epoch 457/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 970382218095545.0000 - val_loss: 875993538869167.0000\n",
            "Epoch 458/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 970441398146930.1250 - val_loss: 876266488015345.5000\n",
            "Epoch 459/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 970317065260343.3750 - val_loss: 876791177260060.8750\n",
            "Epoch 460/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 970069814278708.8750 - val_loss: 877417618058268.8750\n",
            "Epoch 461/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 970028636108901.3750 - val_loss: 877220888873689.0000\n",
            "Epoch 462/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 969984093858119.3750 - val_loss: 877512306646716.0000\n",
            "Epoch 463/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 969917724710353.0000 - val_loss: 877283550095950.1250\n",
            "Epoch 464/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 970025173595264.8750 - val_loss: 876849246034903.5000\n",
            "Epoch 465/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 969936163891133.2500 - val_loss: 876767913311515.5000\n",
            "Epoch 466/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 970143143764211.3750 - val_loss: 876850768111095.3750\n",
            "Epoch 467/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 969955563312430.7500 - val_loss: 876700207723352.3750\n",
            "Epoch 468/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 969965228673687.3750 - val_loss: 877222256301212.3750\n",
            "Epoch 469/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 969875506044661.5000 - val_loss: 877004916060923.6250\n",
            "Epoch 470/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 969927997966860.2500 - val_loss: 876740263074775.5000\n",
            "Epoch 471/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 970053219879783.8750 - val_loss: 876188165886947.1250\n",
            "Epoch 472/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 970114354512428.1250 - val_loss: 875877552883145.0000\n",
            "Epoch 473/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 970098506402988.3750 - val_loss: 875657685189626.3750\n",
            "Epoch 474/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 970186554941127.2500 - val_loss: 875341227451339.8750\n",
            "Epoch 475/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 970145678523906.1250 - val_loss: 874908863854233.3750\n",
            "Epoch 476/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 970113799452356.3750 - val_loss: 874394453718588.6250\n",
            "Epoch 477/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 970374263844209.3750 - val_loss: 874630804693593.6250\n",
            "Epoch 478/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 970177167246354.7500 - val_loss: 875120093086899.3750\n",
            "Epoch 479/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 969865521180666.2500 - val_loss: 875257085945335.3750\n",
            "Epoch 480/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 969846762354766.2500 - val_loss: 875419877490780.6250\n",
            "Epoch 481/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 969849159099909.0000 - val_loss: 875494591794991.6250\n",
            "Epoch 482/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 969924244141903.3750 - val_loss: 875035257685726.6250\n",
            "Epoch 483/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 969794338751669.0000 - val_loss: 875673555525122.8750\n",
            "Epoch 484/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 969691879652843.1250 - val_loss: 876222617744493.8750\n",
            "Epoch 485/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 969664552581708.1250 - val_loss: 876453465003256.6250\n",
            "Epoch 486/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 969469080312616.2500 - val_loss: 876106693772559.8750\n",
            "Epoch 487/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 969576285726190.0000 - val_loss: 876495843562189.3750\n",
            "Epoch 488/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 969567677377001.5000 - val_loss: 876480248580084.3750\n",
            "Epoch 489/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 969483142135020.1250 - val_loss: 876147945910572.8750\n",
            "Epoch 490/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 969433888310429.8750 - val_loss: 875720519423965.3750\n",
            "Epoch 491/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 969442535197381.7500 - val_loss: 875261847096487.6250\n",
            "Epoch 492/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 969530849038596.6250 - val_loss: 875262609735587.3750\n",
            "Epoch 493/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 969526954992183.7500 - val_loss: 874964347523419.1250\n",
            "Epoch 494/1000\n",
            "707/707 [==============================] - 0s 25us/step - loss: 969590751530666.1250 - val_loss: 875197880577793.5000\n",
            "Epoch 495/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 969587674489585.2500 - val_loss: 874695195288709.0000\n",
            "Epoch 496/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 969528072326293.1250 - val_loss: 874619291733437.5000\n",
            "Epoch 497/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 969511050333796.6250 - val_loss: 874450985640907.8750\n",
            "Epoch 498/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 969528193824660.7500 - val_loss: 874390655697821.6250\n",
            "Epoch 499/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 969438499078561.1250 - val_loss: 875131110782987.6250\n",
            "Epoch 500/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 969319343066562.5000 - val_loss: 875812009695660.1250\n",
            "Epoch 501/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 969398572057178.5000 - val_loss: 875513889820278.6250\n",
            "Epoch 502/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 969333949970510.2500 - val_loss: 875384825302739.1250\n",
            "Epoch 503/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 969289833687784.3750 - val_loss: 875042632162263.5000\n",
            "Epoch 504/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 969351535482877.1250 - val_loss: 875418033916447.8750\n",
            "Epoch 505/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 969143087425423.0000 - val_loss: 875454395651505.8750\n",
            "Epoch 506/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 969178919334832.3750 - val_loss: 875348465039834.3750\n",
            "Epoch 507/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 969141680369913.1250 - val_loss: 875028009648498.3750\n",
            "Epoch 508/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 969062395281222.6250 - val_loss: 874772240795081.0000\n",
            "Epoch 509/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 969024386225478.0000 - val_loss: 875004273008408.6250\n",
            "Epoch 510/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 969039294075187.0000 - val_loss: 874710929085688.6250\n",
            "Epoch 511/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 968971377389423.2500 - val_loss: 874786509832099.3750\n",
            "Epoch 512/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 968931661518914.7500 - val_loss: 874556159453218.6250\n",
            "Epoch 513/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 968996278812092.6250 - val_loss: 874770367731769.8750\n",
            "Epoch 514/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 968847334675109.8750 - val_loss: 875341067038465.5000\n",
            "Epoch 515/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 968728201871197.7500 - val_loss: 874878865898779.5000\n",
            "Epoch 516/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 968830798984575.8750 - val_loss: 874560442341156.1250\n",
            "Epoch 517/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 968876347488635.5000 - val_loss: 874992844888121.8750\n",
            "Epoch 518/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 968767469763935.8750 - val_loss: 875685989746676.3750\n",
            "Epoch 519/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 968552019746062.7500 - val_loss: 875296759429964.6250\n",
            "Epoch 520/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 968800236544799.5000 - val_loss: 875468780839050.8750\n",
            "Epoch 521/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 968578047923711.2500 - val_loss: 875878020413266.5000\n",
            "Epoch 522/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 968405675057163.5000 - val_loss: 875031650588729.8750\n",
            "Epoch 523/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 968590762727884.6250 - val_loss: 875188003674632.6250\n",
            "Epoch 524/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 968566512128307.0000 - val_loss: 874923919341024.1250\n",
            "Epoch 525/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 968461747692875.7500 - val_loss: 874728025824123.0000\n",
            "Epoch 526/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 968440112677883.6250 - val_loss: 875149139788424.0000\n",
            "Epoch 527/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 968387363829351.5000 - val_loss: 874498142742840.3750\n",
            "Epoch 528/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 968704872001437.6250 - val_loss: 874004403544295.3750\n",
            "Epoch 529/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 968659087145084.6250 - val_loss: 874367674732983.6250\n",
            "Epoch 530/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 968464777653339.2500 - val_loss: 874323886947148.6250\n",
            "Epoch 531/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 968438175111141.8750 - val_loss: 874497839864328.6250\n",
            "Epoch 532/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 968326929592082.3750 - val_loss: 874253541762921.6250\n",
            "Epoch 533/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 968297177252164.5000 - val_loss: 874207030531968.6250\n",
            "Epoch 534/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 968325086708639.0000 - val_loss: 873961405816045.3750\n",
            "Epoch 535/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 968269128547170.1250 - val_loss: 874572142929769.6250\n",
            "Epoch 536/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 968264571219336.5000 - val_loss: 874622764553464.6250\n",
            "Epoch 537/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 968124299218185.0000 - val_loss: 874351492897844.1250\n",
            "Epoch 538/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 968257892178797.7500 - val_loss: 874715335739658.1250\n",
            "Epoch 539/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 968059476184607.2500 - val_loss: 874242618209112.3750\n",
            "Epoch 540/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 968085557897473.7500 - val_loss: 874264660569579.6250\n",
            "Epoch 541/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967956654014487.2500 - val_loss: 874985467271781.3750\n",
            "Epoch 542/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 967899350946771.1250 - val_loss: 875398588383324.6250\n",
            "Epoch 543/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 967767704309325.5000 - val_loss: 875623113624836.3750\n",
            "Epoch 544/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967742404789660.8750 - val_loss: 875349300420191.5000\n",
            "Epoch 545/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967734327426307.2500 - val_loss: 874995771645905.6250\n",
            "Epoch 546/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 967721194354511.3750 - val_loss: 874966633161398.3750\n",
            "Epoch 547/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967690634192829.2500 - val_loss: 875064797062462.3750\n",
            "Epoch 548/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 967594477157380.3750 - val_loss: 875395218766576.1250\n",
            "Epoch 549/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 967661996932656.5000 - val_loss: 875756436206609.3750\n",
            "Epoch 550/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967597023022785.5000 - val_loss: 875535140157081.3750\n",
            "Epoch 551/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967811830428198.3750 - val_loss: 874710167237464.3750\n",
            "Epoch 552/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 967691697398466.8750 - val_loss: 874327037137520.8750\n",
            "Epoch 553/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 967789989577885.8750 - val_loss: 873935638926955.0000\n",
            "Epoch 554/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967749840727061.8750 - val_loss: 874595386160052.6250\n",
            "Epoch 555/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 967777044781099.5000 - val_loss: 874412584290755.3750\n",
            "Epoch 556/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 967744869592873.6250 - val_loss: 874718533807595.6250\n",
            "Epoch 557/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967639769313529.1250 - val_loss: 874247048787794.5000\n",
            "Epoch 558/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 967598693933832.2500 - val_loss: 874126109719742.8750\n",
            "Epoch 559/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967612750986476.1250 - val_loss: 873736880325718.6250\n",
            "Epoch 560/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967671854436937.2500 - val_loss: 873713988291381.5000\n",
            "Epoch 561/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 967763559126735.8750 - val_loss: 873452159834262.3750\n",
            "Epoch 562/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967714505489690.5000 - val_loss: 873516808910767.0000\n",
            "Epoch 563/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 967793353326638.3750 - val_loss: 873189012030088.0000\n",
            "Epoch 564/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967798546005506.1250 - val_loss: 873444744095963.8750\n",
            "Epoch 565/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967763447025507.5000 - val_loss: 873919866186040.3750\n",
            "Epoch 566/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 967579511975629.0000 - val_loss: 873838349234662.0000\n",
            "Epoch 567/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967579026931364.3750 - val_loss: 873635519559321.3750\n",
            "Epoch 568/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 967628156125207.2500 - val_loss: 874066946495181.3750\n",
            "Epoch 569/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967500151804744.1250 - val_loss: 873696985730771.1250\n",
            "Epoch 570/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967417665423907.5000 - val_loss: 874529374115435.0000\n",
            "Epoch 571/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 967359892404302.2500 - val_loss: 875158511163172.1250\n",
            "Epoch 572/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967262400666570.5000 - val_loss: 875158075727918.3750\n",
            "Epoch 573/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 967252081753254.6250 - val_loss: 874873040350422.0000\n",
            "Epoch 574/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 967231731725881.1250 - val_loss: 874850618320282.6250\n",
            "Epoch 575/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967287544682562.7500 - val_loss: 874495416868817.6250\n",
            "Epoch 576/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967250010395927.6250 - val_loss: 874812527105735.6250\n",
            "Epoch 577/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967176708152637.1250 - val_loss: 875288215011420.6250\n",
            "Epoch 578/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967072103658416.3750 - val_loss: 875497033407910.3750\n",
            "Epoch 579/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 966916813462358.5000 - val_loss: 875148064372284.6250\n",
            "Epoch 580/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967070572731523.7500 - val_loss: 874971864723294.0000\n",
            "Epoch 581/1000\n",
            "707/707 [==============================] - 0s 26us/step - loss: 967012008857211.8750 - val_loss: 875564505105124.5000\n",
            "Epoch 582/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966962557597774.2500 - val_loss: 875487117933296.1250\n",
            "Epoch 583/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 967124169790535.0000 - val_loss: 874930624897162.8750\n",
            "Epoch 584/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966988650131589.2500 - val_loss: 874744379451704.3750\n",
            "Epoch 585/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966976154024477.7500 - val_loss: 874682279810759.6250\n",
            "Epoch 586/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967071619183675.3750 - val_loss: 874403494546784.8750\n",
            "Epoch 587/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 967072681250265.6250 - val_loss: 874145966624189.5000\n",
            "Epoch 588/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967092797203440.1250 - val_loss: 874464546749908.6250\n",
            "Epoch 589/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 967069742888180.8750 - val_loss: 873925659568440.3750\n",
            "Epoch 590/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 967137693508059.0000 - val_loss: 874000090933375.3750\n",
            "Epoch 591/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 967092247708088.2500 - val_loss: 874238450977034.1250\n",
            "Epoch 592/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 967036773356916.2500 - val_loss: 874658288404468.3750\n",
            "Epoch 593/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966888771828948.8750 - val_loss: 874825206360098.6250\n",
            "Epoch 594/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 967013508792528.6250 - val_loss: 874398577011185.5000\n",
            "Epoch 595/1000\n",
            "707/707 [==============================] - 0s 26us/step - loss: 966968966541746.5000 - val_loss: 874468631260003.6250\n",
            "Epoch 596/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 966898969433738.2500 - val_loss: 874279172577060.1250\n",
            "Epoch 597/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 967029791282362.7500 - val_loss: 874602143360040.5000\n",
            "Epoch 598/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 966889820321893.3750 - val_loss: 875015479026821.0000\n",
            "Epoch 599/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 966767197957906.3750 - val_loss: 875222376678671.8750\n",
            "Epoch 600/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966717374651245.7500 - val_loss: 875165134281687.5000\n",
            "Epoch 601/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966755290305120.2500 - val_loss: 875016314505667.3750\n",
            "Epoch 602/1000\n",
            "707/707 [==============================] - 0s 25us/step - loss: 966723918335009.3750 - val_loss: 875140124383012.1250\n",
            "Epoch 603/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966713067296811.5000 - val_loss: 874616281972273.1250\n",
            "Epoch 604/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966754737012944.6250 - val_loss: 874880566056647.6250\n",
            "Epoch 605/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966697662680143.6250 - val_loss: 874966752299181.5000\n",
            "Epoch 606/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 966631518684039.7500 - val_loss: 874547245019899.6250\n",
            "Epoch 607/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966644383557681.2500 - val_loss: 874480260301077.6250\n",
            "Epoch 608/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966633589756604.8750 - val_loss: 874661415521725.5000\n",
            "Epoch 609/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 966916685224628.2500 - val_loss: 873943004462456.0000\n",
            "Epoch 610/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 966805669757507.3750 - val_loss: 874393272628056.3750\n",
            "Epoch 611/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 966718255609331.7500 - val_loss: 873805907249973.5000\n",
            "Epoch 612/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966857029443062.6250 - val_loss: 873525902770546.3750\n",
            "Epoch 613/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966838279385453.1250 - val_loss: 873824962204087.6250\n",
            "Epoch 614/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 966661607042880.8750 - val_loss: 873459847312216.3750\n",
            "Epoch 615/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966816843846101.2500 - val_loss: 873766671308857.8750\n",
            "Epoch 616/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 966690389009507.8750 - val_loss: 873293642777779.3750\n",
            "Epoch 617/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 966730730359308.2500 - val_loss: 873469166621759.6250\n",
            "Epoch 618/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 966585651341685.7500 - val_loss: 873338829304756.6250\n",
            "Epoch 619/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966525410932281.1250 - val_loss: 873350780740000.5000\n",
            "Epoch 620/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966591732050224.1250 - val_loss: 873578126055574.3750\n",
            "Epoch 621/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 966558719258896.2500 - val_loss: 873435978576728.3750\n",
            "Epoch 622/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 966578459184115.0000 - val_loss: 873132087898875.6250\n",
            "Epoch 623/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 966658166977966.1250 - val_loss: 873389073445535.1250\n",
            "Epoch 624/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 966494569615783.0000 - val_loss: 873419989695864.0000\n",
            "Epoch 625/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966567259336443.3750 - val_loss: 873859774207502.5000\n",
            "Epoch 626/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 966574384883483.2500 - val_loss: 874052691819803.5000\n",
            "Epoch 627/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966385707078379.5000 - val_loss: 873730514697777.1250\n",
            "Epoch 628/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966416706532596.8750 - val_loss: 873987321810272.8750\n",
            "Epoch 629/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 966338224163687.8750 - val_loss: 873695375070641.8750\n",
            "Epoch 630/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 966304244890813.6250 - val_loss: 873308344128760.6250\n",
            "Epoch 631/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 966377960513315.8750 - val_loss: 873662007645062.5000\n",
            "Epoch 632/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 966279634257401.5000 - val_loss: 874285055156548.0000\n",
            "Epoch 633/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966162262230614.1250 - val_loss: 873923213724191.8750\n",
            "Epoch 634/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966168852994995.2500 - val_loss: 873517654735415.0000\n",
            "Epoch 635/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 966165643444756.8750 - val_loss: 873483677322963.1250\n",
            "Epoch 636/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 966249930469370.2500 - val_loss: 873828159272323.6250\n",
            "Epoch 637/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 966123004826602.1250 - val_loss: 873822716700799.3750\n",
            "Epoch 638/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966134729988603.0000 - val_loss: 874475047015210.0000\n",
            "Epoch 639/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 965910325398654.0000 - val_loss: 874251551779683.6250\n",
            "Epoch 640/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965981751393910.1250 - val_loss: 874162211578272.5000\n",
            "Epoch 641/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 965943475990962.5000 - val_loss: 874395288700546.1250\n",
            "Epoch 642/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 965852556199602.8750 - val_loss: 874073448960069.3750\n",
            "Epoch 643/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 965934537555388.6250 - val_loss: 873587892221408.1250\n",
            "Epoch 644/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966035876733519.0000 - val_loss: 873499198615945.3750\n",
            "Epoch 645/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 966189386788649.6250 - val_loss: 872853435041317.6250\n",
            "Epoch 646/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966228832372750.3750 - val_loss: 873076604745091.6250\n",
            "Epoch 647/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 966130149832365.1250 - val_loss: 872840262235708.6250\n",
            "Epoch 648/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966165432139637.0000 - val_loss: 872675630768174.3750\n",
            "Epoch 649/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 966202196513422.6250 - val_loss: 872499019170254.8750\n",
            "Epoch 650/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 966217044752995.1250 - val_loss: 873035430502353.6250\n",
            "Epoch 651/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 966001266464093.0000 - val_loss: 873367284365045.8750\n",
            "Epoch 652/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965983365756009.6250 - val_loss: 873689940567821.0000\n",
            "Epoch 653/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 965910681825505.8750 - val_loss: 873338489847530.3750\n",
            "Epoch 654/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 966005463319084.1250 - val_loss: 873620464836746.8750\n",
            "Epoch 655/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 965897035802789.1250 - val_loss: 874067262746739.6250\n",
            "Epoch 656/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965976345855597.3750 - val_loss: 873823608590960.8750\n",
            "Epoch 657/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 965955286439122.0000 - val_loss: 873836021370764.3750\n",
            "Epoch 658/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 965821513461592.0000 - val_loss: 873511958230773.8750\n",
            "Epoch 659/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965947651927826.3750 - val_loss: 873087144937738.1250\n",
            "Epoch 660/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 965937426321460.1250 - val_loss: 872923144264200.6250\n",
            "Epoch 661/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 965964655814218.6250 - val_loss: 873194729030835.3750\n",
            "Epoch 662/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 965907624243147.8750 - val_loss: 873549885552003.6250\n",
            "Epoch 663/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 965852738684455.8750 - val_loss: 873133632971168.5000\n",
            "Epoch 664/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965869893375950.7500 - val_loss: 873663215543151.3750\n",
            "Epoch 665/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965795292215443.6250 - val_loss: 873719267828591.3750\n",
            "Epoch 666/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965605066302818.7500 - val_loss: 873687911166715.6250\n",
            "Epoch 667/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 965692194206061.1250 - val_loss: 873944100890843.8750\n",
            "Epoch 668/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 965537401393945.7500 - val_loss: 873801137418448.3750\n",
            "Epoch 669/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 965570963823006.2500 - val_loss: 873278782882995.3750\n",
            "Epoch 670/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 965569653895000.0000 - val_loss: 872957848907058.6250\n",
            "Epoch 671/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 965819381544922.3750 - val_loss: 873235453914326.0000\n",
            "Epoch 672/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 965531850247433.0000 - val_loss: 873137713523926.0000\n",
            "Epoch 673/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 965560798752252.3750 - val_loss: 873522438453167.0000\n",
            "Epoch 674/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965440278731235.7500 - val_loss: 873067860635763.6250\n",
            "Epoch 675/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 965515859068919.3750 - val_loss: 872978045249478.1250\n",
            "Epoch 676/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965497346799277.1250 - val_loss: 872970315936600.3750\n",
            "Epoch 677/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 965557181518038.3750 - val_loss: 872920667505473.1250\n",
            "Epoch 678/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965503779283558.0000 - val_loss: 872969612161417.3750\n",
            "Epoch 679/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 965403972325613.6250 - val_loss: 873447085774257.8750\n",
            "Epoch 680/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 965298030720499.7500 - val_loss: 873504288915548.6250\n",
            "Epoch 681/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 965201334725885.5000 - val_loss: 874266039121931.6250\n",
            "Epoch 682/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 965069295140887.2500 - val_loss: 873788735844190.0000\n",
            "Epoch 683/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965104973516226.5000 - val_loss: 874294769721482.8750\n",
            "Epoch 684/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 965152065144475.7500 - val_loss: 874416736457699.1250\n",
            "Epoch 685/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 964951794164465.2500 - val_loss: 874106946416478.0000\n",
            "Epoch 686/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 965056590920360.7500 - val_loss: 874000800611241.3750\n",
            "Epoch 687/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 965005821332443.7500 - val_loss: 874286214420260.1250\n",
            "Epoch 688/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 965021603044924.0000 - val_loss: 874104503488396.3750\n",
            "Epoch 689/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 964974697745812.0000 - val_loss: 873665368956141.3750\n",
            "Epoch 690/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 965055685282918.7500 - val_loss: 874026660584407.5000\n",
            "Epoch 691/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 965104536501785.3750 - val_loss: 874217253620718.6250\n",
            "Epoch 692/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 964951384392236.1250 - val_loss: 874025589345540.3750\n",
            "Epoch 693/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 964888603527900.8750 - val_loss: 874386902704359.3750\n",
            "Epoch 694/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 964811825956693.1250 - val_loss: 874847628005908.3750\n",
            "Epoch 695/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 964689238897236.7500 - val_loss: 874511455642201.6250\n",
            "Epoch 696/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 964858313795007.5000 - val_loss: 874279447071449.0000\n",
            "Epoch 697/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 964773750076846.1250 - val_loss: 873822991966069.1250\n",
            "Epoch 698/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 964775130696969.0000 - val_loss: 873344650729900.1250\n",
            "Epoch 699/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 964741922820078.7500 - val_loss: 873149352791578.0000\n",
            "Epoch 700/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 964856227535146.3750 - val_loss: 873553084430069.8750\n",
            "Epoch 701/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 964684721293674.0000 - val_loss: 873409520757511.3750\n",
            "Epoch 702/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 964755026181726.8750 - val_loss: 873351635233173.0000\n",
            "Epoch 703/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 964754125242854.6250 - val_loss: 873015586623650.0000\n",
            "Epoch 704/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 964824657892886.5000 - val_loss: 872581843393773.3750\n",
            "Epoch 705/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 964921979699014.6250 - val_loss: 872254234494038.6250\n",
            "Epoch 706/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 964857863396762.0000 - val_loss: 872533239676094.8750\n",
            "Epoch 707/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 964801583027317.3750 - val_loss: 872723844925798.6250\n",
            "Epoch 708/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 964797546481354.1250 - val_loss: 872465538117840.3750\n",
            "Epoch 709/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 964817305627994.1250 - val_loss: 872798089457594.6250\n",
            "Epoch 710/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 964732802089492.8750 - val_loss: 873256378536468.3750\n",
            "Epoch 711/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 964680754182129.6250 - val_loss: 873547531212302.5000\n",
            "Epoch 712/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 964498870698632.8750 - val_loss: 873419914950019.6250\n",
            "Epoch 713/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 964531566051745.1250 - val_loss: 873620677435530.8750\n",
            "Epoch 714/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 964380140927587.1250 - val_loss: 874059682018413.8750\n",
            "Epoch 715/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 964221910945635.5000 - val_loss: 873470968039782.6250\n",
            "Epoch 716/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 964301333479354.3750 - val_loss: 873930159707107.1250\n",
            "Epoch 717/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 964277812392046.1250 - val_loss: 874177337739530.1250\n",
            "Epoch 718/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 964255193145355.5000 - val_loss: 874111477196371.8750\n",
            "Epoch 719/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 964312281171936.1250 - val_loss: 873419805471576.3750\n",
            "Epoch 720/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 964276030874770.2500 - val_loss: 873037715333906.6250\n",
            "Epoch 721/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 964203534697212.7500 - val_loss: 873449905580992.3750\n",
            "Epoch 722/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 964158124017863.8750 - val_loss: 872828037981872.5000\n",
            "Epoch 723/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 964208583618832.2500 - val_loss: 872963300515145.6250\n",
            "Epoch 724/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 964133913095097.0000 - val_loss: 873108427219082.8750\n",
            "Epoch 725/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 964223347284150.5000 - val_loss: 872767313938605.5000\n",
            "Epoch 726/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 964269668133400.0000 - val_loss: 872957915675283.5000\n",
            "Epoch 727/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 964181501917447.6250 - val_loss: 873267397504769.5000\n",
            "Epoch 728/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 964156598121763.1250 - val_loss: 873304417105746.5000\n",
            "Epoch 729/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 964076509103053.3750 - val_loss: 873283618431947.8750\n",
            "Epoch 730/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 964049758484720.5000 - val_loss: 873211904808647.6250\n",
            "Epoch 731/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 964030444325851.7500 - val_loss: 873107266952706.8750\n",
            "Epoch 732/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 963950771771273.2500 - val_loss: 873646593367554.8750\n",
            "Epoch 733/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 963882691792415.2500 - val_loss: 873410220196210.3750\n",
            "Epoch 734/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963872349131151.6250 - val_loss: 873517575696777.3750\n",
            "Epoch 735/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 963816050109809.3750 - val_loss: 873476988957991.0000\n",
            "Epoch 736/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 963890502506006.5000 - val_loss: 873982871243481.0000\n",
            "Epoch 737/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 963732647080741.3750 - val_loss: 873846836060761.6250\n",
            "Epoch 738/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 963694997228276.1250 - val_loss: 874217183648264.6250\n",
            "Epoch 739/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 963630872928962.8750 - val_loss: 874141981171202.8750\n",
            "Epoch 740/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 963607380460215.1250 - val_loss: 874091557552128.0000\n",
            "Epoch 741/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 963520916716409.3750 - val_loss: 874096926958817.6250\n",
            "Epoch 742/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 963564227740227.3750 - val_loss: 874315645914372.3750\n",
            "Epoch 743/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963490611422470.1250 - val_loss: 873823988838238.0000\n",
            "Epoch 744/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963603876845959.0000 - val_loss: 873211833549170.3750\n",
            "Epoch 745/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 963605334826370.7500 - val_loss: 873562250077317.0000\n",
            "Epoch 746/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 963547040763863.3750 - val_loss: 873771938815583.5000\n",
            "Epoch 747/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 963480680064030.5000 - val_loss: 873737016545812.3750\n",
            "Epoch 748/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 963464514041772.0000 - val_loss: 873475890544269.6250\n",
            "Epoch 749/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 963618595329071.7500 - val_loss: 873154279661429.1250\n",
            "Epoch 750/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 963652331723861.5000 - val_loss: 873180507189363.6250\n",
            "Epoch 751/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963501899611557.5000 - val_loss: 872526352027624.8750\n",
            "Epoch 752/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 963556637568717.0000 - val_loss: 872544344162581.6250\n",
            "Epoch 753/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 963620756718587.6250 - val_loss: 872530874497405.8750\n",
            "Epoch 754/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963464791779446.7500 - val_loss: 872938055750256.8750\n",
            "Epoch 755/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 963356883194070.3750 - val_loss: 873339722608570.6250\n",
            "Epoch 756/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963366404394666.1250 - val_loss: 873548016754826.8750\n",
            "Epoch 757/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963335047659311.3750 - val_loss: 873204990524421.6250\n",
            "Epoch 758/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 963428532300196.0000 - val_loss: 873251944457349.0000\n",
            "Epoch 759/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 963366403160698.3750 - val_loss: 873026280374920.0000\n",
            "Epoch 760/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 963322483494130.0000 - val_loss: 873296302396016.8750\n",
            "Epoch 761/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963189779061521.0000 - val_loss: 873155681232097.6250\n",
            "Epoch 762/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 963220137659309.3750 - val_loss: 873311744462269.5000\n",
            "Epoch 763/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 963134467570367.8750 - val_loss: 873520449153429.0000\n",
            "Epoch 764/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 963176019110354.3750 - val_loss: 873995516038496.8750\n",
            "Epoch 765/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 963068784983299.2500 - val_loss: 873787561727132.3750\n",
            "Epoch 766/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 963199623300647.8750 - val_loss: 873817159155434.3750\n",
            "Epoch 767/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 963204073178362.6250 - val_loss: 873262826281388.1250\n",
            "Epoch 768/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 963306173435793.8750 - val_loss: 872648991533461.0000\n",
            "Epoch 769/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 963311294158914.7500 - val_loss: 872487324148128.5000\n",
            "Epoch 770/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 963208367955817.2500 - val_loss: 872304761925099.6250\n",
            "Epoch 771/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 963290373658737.0000 - val_loss: 872648641693406.6250\n",
            "Epoch 772/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963154577021481.2500 - val_loss: 872627146693313.6250\n",
            "Epoch 773/1000\n",
            "707/707 [==============================] - 0s 13us/step - loss: 963195191647688.2500 - val_loss: 872978341257447.3750\n",
            "Epoch 774/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 963154049832470.5000 - val_loss: 873337868113052.3750\n",
            "Epoch 775/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 962990474444406.1250 - val_loss: 872504042094406.8750\n",
            "Epoch 776/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 963211318372818.3750 - val_loss: 872125963959579.5000\n",
            "Epoch 777/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 963235938498290.6250 - val_loss: 872268659702974.8750\n",
            "Epoch 778/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 963169517239115.0000 - val_loss: 872139540520265.6250\n",
            "Epoch 779/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 963172007386127.8750 - val_loss: 871924521060062.6250\n",
            "Epoch 780/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 963213066762804.8750 - val_loss: 871725666088323.6250\n",
            "Epoch 781/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963211020322135.2500 - val_loss: 871343657943225.1250\n",
            "Epoch 782/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 963280724695013.8750 - val_loss: 871633818583225.1250\n",
            "Epoch 783/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963123931336338.8750 - val_loss: 871356827637910.3750\n",
            "Epoch 784/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 963190803515823.6250 - val_loss: 871188694324935.6250\n",
            "Epoch 785/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 963172593805593.0000 - val_loss: 870789349346379.3750\n",
            "Epoch 786/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 963308581897698.2500 - val_loss: 870681394184747.3750\n",
            "Epoch 787/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 963314714231177.8750 - val_loss: 870877368556040.6250\n",
            "Epoch 788/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 963446744146140.1250 - val_loss: 870574643716975.3750\n",
            "Epoch 789/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 963352599047722.7500 - val_loss: 871160066154820.0000\n",
            "Epoch 790/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 963285124739413.8750 - val_loss: 871397112106892.3750\n",
            "Epoch 791/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 963204377327694.2500 - val_loss: 871076328965206.6250\n",
            "Epoch 792/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 963430732749538.6250 - val_loss: 870977205239437.6250\n",
            "Epoch 793/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 963219404801089.2500 - val_loss: 871107927718547.5000\n",
            "Epoch 794/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 963278264637831.0000 - val_loss: 871117293629000.3750\n",
            "Epoch 795/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 963303172562561.6250 - val_loss: 870909306294156.3750\n",
            "Epoch 796/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 963331574704409.0000 - val_loss: 871404400300286.5000\n",
            "Epoch 797/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 963116330094713.7500 - val_loss: 870823284039726.3750\n",
            "Epoch 798/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963262846281406.3750 - val_loss: 871217457530313.0000\n",
            "Epoch 799/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 963220335972172.5000 - val_loss: 871381622321545.3750\n",
            "Epoch 800/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 963113362781846.0000 - val_loss: 871939326885795.3750\n",
            "Epoch 801/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 962985789211064.2500 - val_loss: 872349442524524.5000\n",
            "Epoch 802/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 962843581921265.6250 - val_loss: 871844801917414.0000\n",
            "Epoch 803/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 962892063092174.0000 - val_loss: 872516439418081.6250\n",
            "Epoch 804/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 962754847107190.7500 - val_loss: 872704594821027.3750\n",
            "Epoch 805/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 962654138154382.2500 - val_loss: 873205504314073.0000\n",
            "Epoch 806/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 962612684999597.3750 - val_loss: 873601655685582.8750\n",
            "Epoch 807/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 962457860175510.0000 - val_loss: 874086734465382.6250\n",
            "Epoch 808/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 962350169693941.5000 - val_loss: 873760617759275.3750\n",
            "Epoch 809/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 962323878396390.6250 - val_loss: 873248649732327.3750\n",
            "Epoch 810/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 962435075648325.2500 - val_loss: 872840707913091.6250\n",
            "Epoch 811/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 962566831895333.3750 - val_loss: 872999707944717.0000\n",
            "Epoch 812/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 962390194436081.6250 - val_loss: 873268107296675.3750\n",
            "Epoch 813/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 962318433940632.1250 - val_loss: 873395515797249.5000\n",
            "Epoch 814/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 962363630146886.0000 - val_loss: 873035026816885.1250\n",
            "Epoch 815/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 962323605612384.6250 - val_loss: 873382120834227.3750\n",
            "Epoch 816/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 962217696321802.5000 - val_loss: 873174163236435.8750\n",
            "Epoch 817/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 962249690401524.1250 - val_loss: 873426026091676.3750\n",
            "Epoch 818/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 962288648093742.3750 - val_loss: 873646557107633.8750\n",
            "Epoch 819/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 962188605898821.6250 - val_loss: 873608237754865.5000\n",
            "Epoch 820/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 962263282461879.8750 - val_loss: 873706748611659.3750\n",
            "Epoch 821/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 962062227722477.6250 - val_loss: 874047428423332.8750\n",
            "Epoch 822/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 962209680846680.0000 - val_loss: 873408873424745.6250\n",
            "Epoch 823/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 962068897887940.3750 - val_loss: 873268171490853.6250\n",
            "Epoch 824/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 962090262497873.8750 - val_loss: 873745356409838.6250\n",
            "Epoch 825/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 961955985800451.2500 - val_loss: 873281531993788.0000\n",
            "Epoch 826/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 962092233690238.0000 - val_loss: 873067723425595.3750\n",
            "Epoch 827/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 962091182492056.5000 - val_loss: 872739375187956.3750\n",
            "Epoch 828/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 962202276897521.2500 - val_loss: 873000828516271.0000\n",
            "Epoch 829/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 961985379886295.7500 - val_loss: 873395402954624.6250\n",
            "Epoch 830/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 962094548756204.8750 - val_loss: 873212898111140.8750\n",
            "Epoch 831/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 962011790332929.5000 - val_loss: 873142317904820.6250\n",
            "Epoch 832/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 961972219026494.2500 - val_loss: 872763375366444.8750\n",
            "Epoch 833/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 962182906498197.1250 - val_loss: 872382769830223.5000\n",
            "Epoch 834/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 962070759091059.5000 - val_loss: 872425581027466.8750\n",
            "Epoch 835/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 962057277992884.6250 - val_loss: 872014969062764.5000\n",
            "Epoch 836/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 962060058691853.3750 - val_loss: 871290910598277.0000\n",
            "Epoch 837/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 962190624729461.7500 - val_loss: 871436509490945.5000\n",
            "Epoch 838/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 962175069236500.5000 - val_loss: 871082016009707.6250\n",
            "Epoch 839/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 962105496435438.3750 - val_loss: 871580129981364.6250\n",
            "Epoch 840/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961995779458391.2500 - val_loss: 871299847063540.3750\n",
            "Epoch 841/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 961931615980600.3750 - val_loss: 871371497656759.6250\n",
            "Epoch 842/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 961849302972239.3750 - val_loss: 871281286501902.5000\n",
            "Epoch 843/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 961942484436728.3750 - val_loss: 871021445385106.1250\n",
            "Epoch 844/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 962202309360366.3750 - val_loss: 870538705817669.3750\n",
            "Epoch 845/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 962088194961101.0000 - val_loss: 870383699656518.8750\n",
            "Epoch 846/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 962135594416855.1250 - val_loss: 870283151966022.8750\n",
            "Epoch 847/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 962093158169419.0000 - val_loss: 870379588863155.3750\n",
            "Epoch 848/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 962165709116162.5000 - val_loss: 870329418678827.3750\n",
            "Epoch 849/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 962033356388105.7500 - val_loss: 871154066729457.5000\n",
            "Epoch 850/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961923961820740.8750 - val_loss: 871545742606798.8750\n",
            "Epoch 851/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 961735038693347.0000 - val_loss: 872106233509251.6250\n",
            "Epoch 852/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 961618683028881.1250 - val_loss: 872741141326136.3750\n",
            "Epoch 853/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 961534352435712.7500 - val_loss: 872415791336800.8750\n",
            "Epoch 854/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 961676460865706.8750 - val_loss: 872029375205538.0000\n",
            "Epoch 855/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 961626717393203.0000 - val_loss: 872521720972467.3750\n",
            "Epoch 856/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961482429254017.2500 - val_loss: 871950546723047.3750\n",
            "Epoch 857/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961667439374608.2500 - val_loss: 872168976922543.0000\n",
            "Epoch 858/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961583690858287.3750 - val_loss: 872252131071317.3750\n",
            "Epoch 859/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 961756396113045.1250 - val_loss: 871563076861026.3750\n",
            "Epoch 860/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 961700604110086.1250 - val_loss: 872060393954171.0000\n",
            "Epoch 861/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 961575466723956.6250 - val_loss: 872634931216384.0000\n",
            "Epoch 862/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961527440032879.6250 - val_loss: 872448219377502.0000\n",
            "Epoch 863/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 961488911500422.6250 - val_loss: 872136783520715.8750\n",
            "Epoch 864/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961525188231492.5000 - val_loss: 872509161078784.0000\n",
            "Epoch 865/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 961550260179019.3750 - val_loss: 872314352596633.3750\n",
            "Epoch 866/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 961588099279430.2500 - val_loss: 871924545836373.3750\n",
            "Epoch 867/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 961492062650761.8750 - val_loss: 872034821064229.6250\n",
            "Epoch 868/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 961698216524781.2500 - val_loss: 871947583374700.5000\n",
            "Epoch 869/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 961489674068790.6250 - val_loss: 871639078696601.3750\n",
            "Epoch 870/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 961613515266670.8750 - val_loss: 871228356678071.6250\n",
            "Epoch 871/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 961541901281167.0000 - val_loss: 871084117779589.0000\n",
            "Epoch 872/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961529089468140.8750 - val_loss: 871631630788642.6250\n",
            "Epoch 873/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961425156157480.6250 - val_loss: 871191590991698.5000\n",
            "Epoch 874/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961498331112246.6250 - val_loss: 871448306158297.0000\n",
            "Epoch 875/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 961464297046456.2500 - val_loss: 871170037976324.3750\n",
            "Epoch 876/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 961594631193039.5000 - val_loss: 871409529223920.1250\n",
            "Epoch 877/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961423928217142.2500 - val_loss: 871110376149431.6250\n",
            "Epoch 878/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 961595203232033.7500 - val_loss: 871300544503576.6250\n",
            "Epoch 879/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 961452246876322.2500 - val_loss: 871589064946335.1250\n",
            "Epoch 880/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961313429296059.8750 - val_loss: 871863642340728.0000\n",
            "Epoch 881/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 961239749197592.3750 - val_loss: 872419717008736.8750\n",
            "Epoch 882/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 961159943967745.5000 - val_loss: 872083078246793.3750\n",
            "Epoch 883/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 961083834281607.3750 - val_loss: 872116559198497.3750\n",
            "Epoch 884/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 961076252522435.2500 - val_loss: 872554334360824.6250\n",
            "Epoch 885/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 960925920195411.6250 - val_loss: 873022193469243.3750\n",
            "Epoch 886/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 960852058323995.6250 - val_loss: 872752296795928.6250\n",
            "Epoch 887/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 960825555733189.7500 - val_loss: 872268292695450.6250\n",
            "Epoch 888/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 960895764798897.0000 - val_loss: 871843206455712.5000\n",
            "Epoch 889/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 960990043901471.2500 - val_loss: 872048473289004.8750\n",
            "Epoch 890/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 960858246862335.2500 - val_loss: 872603685702453.5000\n",
            "Epoch 891/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 960723326342215.0000 - val_loss: 873050093745817.3750\n",
            "Epoch 892/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 960781582721244.1250 - val_loss: 872949342633798.8750\n",
            "Epoch 893/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 960670288507917.0000 - val_loss: 873025426172031.3750\n",
            "Epoch 894/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 960659748524524.5000 - val_loss: 873273543614510.3750\n",
            "Epoch 895/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 960613859350432.5000 - val_loss: 872848806857895.6250\n",
            "Epoch 896/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 960477988200505.8750 - val_loss: 872641923462161.3750\n",
            "Epoch 897/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 960616295487624.1250 - val_loss: 872061368717751.6250\n",
            "Epoch 898/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 960571210765614.7500 - val_loss: 871989536650164.6250\n",
            "Epoch 899/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 960508832269701.6250 - val_loss: 871898580776045.8750\n",
            "Epoch 900/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 960604602029103.7500 - val_loss: 872149561080560.1250\n",
            "Epoch 901/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 960386891548338.8750 - val_loss: 871802888366392.3750\n",
            "Epoch 902/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 960457953356983.8750 - val_loss: 872245091190494.6250\n",
            "Epoch 903/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 960324708232909.0000 - val_loss: 872464707096182.6250\n",
            "Epoch 904/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 960190904667215.6250 - val_loss: 873041615911849.3750\n",
            "Epoch 905/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 960090554680385.2500 - val_loss: 872811810615134.0000\n",
            "Epoch 906/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 960048789901271.3750 - val_loss: 872834438352410.0000\n",
            "Epoch 907/1000\n",
            "707/707 [==============================] - 0s 27us/step - loss: 960068618529790.5000 - val_loss: 872429869108299.3750\n",
            "Epoch 908/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 960009410951431.6250 - val_loss: 872274536680060.3750\n",
            "Epoch 909/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 960070518316650.3750 - val_loss: 872515647678406.1250\n",
            "Epoch 910/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 960082195355390.2500 - val_loss: 872062268395219.1250\n",
            "Epoch 911/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 960102837975512.1250 - val_loss: 872546328578221.5000\n",
            "Epoch 912/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 960045097015339.5000 - val_loss: 872457848890778.6250\n",
            "Epoch 913/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 960070199218807.5000 - val_loss: 872013587338766.5000\n",
            "Epoch 914/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 960039302041536.3750 - val_loss: 872190009331781.3750\n",
            "Epoch 915/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959959104457390.5000 - val_loss: 871684788430049.6250\n",
            "Epoch 916/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 960017664772180.0000 - val_loss: 871404759374992.6250\n",
            "Epoch 917/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 960081528965319.8750 - val_loss: 871981194380930.1250\n",
            "Epoch 918/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 959872402083196.8750 - val_loss: 871384108467471.8750\n",
            "Epoch 919/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959936995314002.8750 - val_loss: 870724308238706.3750\n",
            "Epoch 920/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 960114294559675.8750 - val_loss: 870522665595828.6250\n",
            "Epoch 921/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 960151895955175.0000 - val_loss: 870793265496341.6250\n",
            "Epoch 922/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 959989045262159.3750 - val_loss: 870642640872210.6250\n",
            "Epoch 923/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 960036848320303.3750 - val_loss: 870477248541343.1250\n",
            "Epoch 924/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959989153685214.2500 - val_loss: 871143522457657.8750\n",
            "Epoch 925/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 960092860491593.5000 - val_loss: 871105153231623.3750\n",
            "Epoch 926/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959764658541013.2500 - val_loss: 870578156296990.3750\n",
            "Epoch 927/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 959953686365828.5000 - val_loss: 870238145479396.5000\n",
            "Epoch 928/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 959983226819237.8750 - val_loss: 869762380820318.0000\n",
            "Epoch 929/1000\n",
            "707/707 [==============================] - 0s 25us/step - loss: 960210526914620.7500 - val_loss: 870032399457239.5000\n",
            "Epoch 930/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 959998060939371.2500 - val_loss: 870163394763828.1250\n",
            "Epoch 931/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 960228015465595.1250 - val_loss: 869543585019545.3750\n",
            "Epoch 932/1000\n",
            "707/707 [==============================] - 0s 22us/step - loss: 960197863747253.7500 - val_loss: 869888387984968.3750\n",
            "Epoch 933/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 959993545827474.2500 - val_loss: 870108524682662.3750\n",
            "Epoch 934/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 959982232241194.0000 - val_loss: 870421453482111.3750\n",
            "Epoch 935/1000\n",
            "707/707 [==============================] - 0s 23us/step - loss: 959890401662949.8750 - val_loss: 870441540643776.3750\n",
            "Epoch 936/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 959841739312346.6250 - val_loss: 870296012695864.3750\n",
            "Epoch 937/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 959793913188496.7500 - val_loss: 870801927461292.1250\n",
            "Epoch 938/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 959718131619142.0000 - val_loss: 870770380616906.5000\n",
            "Epoch 939/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959721473773457.8750 - val_loss: 870310669216519.3750\n",
            "Epoch 940/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 959891728771584.7500 - val_loss: 870633231007466.3750\n",
            "Epoch 941/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959767797778817.2500 - val_loss: 870257179964063.1250\n",
            "Epoch 942/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959762224705646.1250 - val_loss: 870490255924461.3750\n",
            "Epoch 943/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959760374228554.6250 - val_loss: 870170265441806.5000\n",
            "Epoch 944/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959792892032685.1250 - val_loss: 870585723947737.0000\n",
            "Epoch 945/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959741000649390.5000 - val_loss: 870487316188327.6250\n",
            "Epoch 946/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959628370998146.0000 - val_loss: 870158816156724.1250\n",
            "Epoch 947/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959639085564251.6250 - val_loss: 869780078685305.5000\n",
            "Epoch 948/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 959735504366984.5000 - val_loss: 869868288958695.3750\n",
            "Epoch 949/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 959890210896274.6250 - val_loss: 869976899532163.6250\n",
            "Epoch 950/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 959730162330553.0000 - val_loss: 869765112556295.3750\n",
            "Epoch 951/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 959727935113601.2500 - val_loss: 869108254270782.3750\n",
            "Epoch 952/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 960059224238036.5000 - val_loss: 869400298669420.5000\n",
            "Epoch 953/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 959958572925762.3750 - val_loss: 869258167541250.8750\n",
            "Epoch 954/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959882762192053.0000 - val_loss: 869421724795990.6250\n",
            "Epoch 955/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 959925303801354.8750 - val_loss: 869839367810076.8750\n",
            "Epoch 956/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 959706309353367.7500 - val_loss: 870358948356234.8750\n",
            "Epoch 957/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959597271687457.7500 - val_loss: 870448603301506.1250\n",
            "Epoch 958/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 959724851333157.6250 - val_loss: 870603965946654.3750\n",
            "Epoch 959/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959548745227558.0000 - val_loss: 870656886039314.6250\n",
            "Epoch 960/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 959600503544036.7500 - val_loss: 870426165589379.6250\n",
            "Epoch 961/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 959565705177577.5000 - val_loss: 870159342272326.8750\n",
            "Epoch 962/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 959915351186633.3750 - val_loss: 870122938862297.0000\n",
            "Epoch 963/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 959589087633350.1250 - val_loss: 870196921522604.1250\n",
            "Epoch 964/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 959526553182891.6250 - val_loss: 869608297213512.3750\n",
            "Epoch 965/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959651385731515.1250 - val_loss: 870024863486669.3750\n",
            "Epoch 966/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 959735431562884.5000 - val_loss: 869750213610201.0000\n",
            "Epoch 967/1000\n",
            "707/707 [==============================] - 0s 14us/step - loss: 959628310486263.7500 - val_loss: 869873994488791.5000\n",
            "Epoch 968/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 959600510568161.1250 - val_loss: 870169977273720.0000\n",
            "Epoch 969/1000\n",
            "707/707 [==============================] - 0s 24us/step - loss: 959523423935480.7500 - val_loss: 870482505075046.6250\n",
            "Epoch 970/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959479007407033.0000 - val_loss: 870295148110888.5000\n",
            "Epoch 971/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959401986127185.5000 - val_loss: 870215971594471.3750\n",
            "Epoch 972/1000\n",
            "707/707 [==============================] - 0s 15us/step - loss: 959620073988524.7500 - val_loss: 869846943422151.6250\n",
            "Epoch 973/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 959535966648606.8750 - val_loss: 870142754356877.6250\n",
            "Epoch 974/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 959417398290041.0000 - val_loss: 870145173463178.8750\n",
            "Epoch 975/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 959365799546955.3750 - val_loss: 869867685538752.3750\n",
            "Epoch 976/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959328300024989.8750 - val_loss: 870207994022339.3750\n",
            "Epoch 977/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 959223850203886.3750 - val_loss: 870371178439442.6250\n",
            "Epoch 978/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 959065708521822.5000 - val_loss: 870494402932944.3750\n",
            "Epoch 979/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 959074132748777.5000 - val_loss: 870607339157885.8750\n",
            "Epoch 980/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 959059415119950.2500 - val_loss: 870347675163792.6250\n",
            "Epoch 981/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959167677664243.0000 - val_loss: 870502050609071.0000\n",
            "Epoch 982/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 959079146834536.8750 - val_loss: 870761880491071.6250\n",
            "Epoch 983/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 958929371786354.5000 - val_loss: 870276626661283.3750\n",
            "Epoch 984/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 958989135290935.7500 - val_loss: 870244278815171.3750\n",
            "Epoch 985/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 959038064249773.3750 - val_loss: 870451134902387.6250\n",
            "Epoch 986/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 958948130588524.3750 - val_loss: 870374895688385.6250\n",
            "Epoch 987/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 959045773985644.3750 - val_loss: 870658868979098.6250\n",
            "Epoch 988/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 958876797283233.8750 - val_loss: 870361548992812.8750\n",
            "Epoch 989/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 958932283831703.1250 - val_loss: 870083345179781.0000\n",
            "Epoch 990/1000\n",
            "707/707 [==============================] - 0s 16us/step - loss: 958978920315676.6250 - val_loss: 869782363783445.6250\n",
            "Epoch 991/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959106176234671.2500 - val_loss: 869913291693108.1250\n",
            "Epoch 992/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 958932127355094.3750 - val_loss: 869991399146305.1250\n",
            "Epoch 993/1000\n",
            "707/707 [==============================] - 0s 18us/step - loss: 959009511516394.7500 - val_loss: 869508366796603.3750\n",
            "Epoch 994/1000\n",
            "707/707 [==============================] - 0s 19us/step - loss: 959110790325023.5000 - val_loss: 869755645384947.0000\n",
            "Epoch 995/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 958949038741362.1250 - val_loss: 869508027928830.5000\n",
            "Epoch 996/1000\n",
            "707/707 [==============================] - 0s 27us/step - loss: 958995915801595.6250 - val_loss: 869746244239082.3750\n",
            "Epoch 997/1000\n",
            "707/707 [==============================] - 0s 25us/step - loss: 958919884211381.0000 - val_loss: 870234988807254.6250\n",
            "Epoch 998/1000\n",
            "707/707 [==============================] - 0s 17us/step - loss: 958804373530094.0000 - val_loss: 870181197650070.3750\n",
            "Epoch 999/1000\n",
            "707/707 [==============================] - 0s 20us/step - loss: 958754892821540.2500 - val_loss: 870082226120368.5000\n",
            "Epoch 1000/1000\n",
            "707/707 [==============================] - 0s 21us/step - loss: 958829149325349.6250 - val_loss: 869678437102701.8750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j2P_0gOvxtsw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "89dbfba5-52cd-4a3b-870f-e7f86869c1b9"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(train_loss))\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_loss, 'b-', label = 'Training loss')\n",
        "plt.plot(epochs, validation_loss, 'r-', label = 'Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEHCAYAAABV4gY/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCFsSIK7EELYkAR3IYSwof8HeQtNvf8hpucAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff9b4014910>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3mj-3gRgyU2z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "d661a07e-4e38-4910-ca4f-b983e7f2e37a"
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_aux) \n",
        "\n",
        "print(\"Number of predictions:\", len(y_pred))\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE: \", mse)\n",
        "rmse = math.sqrt(mse)\n",
        "print(\"RMSE: \", rmse) \n",
        "y_pred = np.array([x[0] for x in y_pred]) \n",
        "\n",
        "results = pd.DataFrame({\"y\":y_test[\"precio\"], 'pred': y_pred}, columns = [ \"y\", 'pred']) \n",
        "#result[\"y\"] = y_test[\"precio\"]\n",
        "results['error'] = abs(results['pred'].astype(float) - results['y'].astype(float))\n",
        "print(\"MAPE: \", 100 * np.mean(results['error'] / y_test[\"precio\"]))\n",
        "results.sort_values(by = 'error', ascending = True)\n",
        "\n",
        "results.head()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Number of predictions:', 177)\n",
            "('MSE: ', 869678476230696.1)\n",
            "('RMSE: ', 29490311.56550734)\n",
            "('MAPE: ', 17.96730892057084)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>pred</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>812</th>\n",
              "      <td>185000000.0</td>\n",
              "      <td>155342560.0</td>\n",
              "      <td>29657440.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>643</th>\n",
              "      <td>170000000.0</td>\n",
              "      <td>169581968.0</td>\n",
              "      <td>418032.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>145000000.0</td>\n",
              "      <td>143326720.0</td>\n",
              "      <td>1673280.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>120000000.0</td>\n",
              "      <td>136333120.0</td>\n",
              "      <td>16333120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>195000000.0</td>\n",
              "      <td>161378208.0</td>\n",
              "      <td>33621792.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               y         pred       error\n",
              "812  185000000.0  155342560.0  29657440.0\n",
              "643  170000000.0  169581968.0    418032.0\n",
              "440  145000000.0  143326720.0   1673280.0\n",
              "254  120000000.0  136333120.0  16333120.0\n",
              "883  195000000.0  161378208.0  33621792.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "gTP41PPPyg3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "195c9d3f-e230-4f26-f42e-7dc384cc4029"
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_train_aux) \n",
        "\n",
        "print(\"Number of predictions:\", len(y_pred))\n",
        "\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "print(\"MSE: \", mse)\n",
        "rmse = math.sqrt(mse)\n",
        "print(\"RMSE: \", rmse) \n",
        "y_pred = np.array([x[0] for x in y_pred]) \n",
        "\n",
        "results = pd.DataFrame({\"y\":y_train[\"precio\"], 'pred': y_pred}, columns = [ \"y\", 'pred']) \n",
        "#result[\"y\"] = y_test[\"precio\"]\n",
        "results['error'] = abs(results['pred'].astype(float) - results['y'].astype(float))\n",
        "print(\"MAPE: \", 100 * np.mean(results['error'] / y_train[\"precio\"]))\n",
        "results.sort_values(by = 'error', ascending = True)\n",
        "\n",
        "results.head()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Number of predictions:', 707)\n",
            "('MSE: ', 958737339194117.4)\n",
            "('RMSE: ', 30963483.96408449)\n",
            "('MAPE: ', 18.278026723127123)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>pred</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>130000000.0</td>\n",
              "      <td>137377600.0</td>\n",
              "      <td>7377600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>115000000.0</td>\n",
              "      <td>137780128.0</td>\n",
              "      <td>22780128.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>91000000.0</td>\n",
              "      <td>129905208.0</td>\n",
              "      <td>38905208.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>160000000.0</td>\n",
              "      <td>148531456.0</td>\n",
              "      <td>11468544.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>94161000.0</td>\n",
              "      <td>124001856.0</td>\n",
              "      <td>29840856.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               y         pred       error\n",
              "309  130000000.0  137377600.0   7377600.0\n",
              "228  115000000.0  137780128.0  22780128.0\n",
              "110   91000000.0  129905208.0  38905208.0\n",
              "564  160000000.0  148531456.0  11468544.0\n",
              "121   94161000.0  124001856.0  29840856.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "cj_I74OiRWHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%notebook ./filename.ipynb\n",
        "!./dropbox_uploader.sh upload filename.ipynb /"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}